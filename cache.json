{"2024-12-19T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2412.15210v1","updated":"2024-12-19T18:59:46Z","published":"2024-12-19T18:59:46Z","title":"Tokenisation is NP-Complete","summary":"  In this work, we prove the NP-completeness of two variants of tokenisation,\ndefined as the problem of compressing a dataset to at most $\\delta$ symbols by\neither finding a vocabulary directly (direct tokenisation), or selecting a\nsequence of merge operations (bottom-up tokenisation).\n","authors":["Philip Whittington","Gregor Bachmann","Tiago Pimentel"],"pdf_url":"https://arxiv.org/pdf/2412.15210v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15204v1","updated":"2024-12-19T18:59:17Z","published":"2024-12-19T18:59:17Z","title":"LongBench v2: Towards Deeper Understanding and Reasoning on Realistic\n  Long-context Multitasks","summary":"  This paper introduces LongBench v2, a benchmark designed to assess the\nability of LLMs to handle long-context problems requiring deep understanding\nand reasoning across real-world multitasks. LongBench v2 consists of 503\nchallenging multiple-choice questions, with contexts ranging from 8k to 2M\nwords, across six major task categories: single-document QA, multi-document QA,\nlong in-context learning, long-dialogue history understanding, code repository\nunderstanding, and long structured data understanding. To ensure the breadth\nand the practicality, we collect data from nearly 100 highly educated\nindividuals with diverse professional backgrounds. We employ both automated and\nmanual review processes to maintain high quality and difficulty, resulting in\nhuman experts achieving only 53.7% accuracy under a 15-minute time constraint.\nOur evaluation reveals that the best-performing model, when directly answers\nthe questions, achieves only 50.1% accuracy. In contrast, the o1-preview model,\nwhich includes longer reasoning, achieves 57.7%, surpassing the human baseline\nby 4%. These results highlight the importance of enhanced reasoning ability and\nscaling inference-time compute to tackle the long-context challenges in\nLongBench v2. The project is available at https://longbench2.github.io.\n","authors":["Yushi Bai","Shangqing Tu","Jiajie Zhang","Hao Peng","Xiaozhi Wang","Xin Lv","Shulin Cao","Jiazheng Xu","Lei Hou","Yuxiao Dong","Jie Tang","Juanzi Li"],"pdf_url":"https://arxiv.org/pdf/2412.15204v1.pdf","comment":"25 pages, 13 figures"},{"id":"http://arxiv.org/abs/2412.15194v1","updated":"2024-12-19T18:58:04Z","published":"2024-12-19T18:58:04Z","title":"MMLU-CF: A Contamination-free Multi-task Language Understanding\n  Benchmark","summary":"  Multiple-choice question (MCQ) datasets like Massive Multitask Language\nUnderstanding (MMLU) are widely used to evaluate the commonsense,\nunderstanding, and problem-solving abilities of large language models (LLMs).\nHowever, the open-source nature of these benchmarks and the broad sources of\ntraining data for LLMs have inevitably led to benchmark contamination,\nresulting in unreliable evaluation results. To alleviate this issue, we propose\na contamination-free and more challenging MCQ benchmark called MMLU-CF. This\nbenchmark reassesses LLMs' understanding of world knowledge by averting both\nunintentional and malicious data leakage. To avoid unintentional data leakage,\nwe source data from a broader domain and design three decontamination rules. To\nprevent malicious data leakage, we divide the benchmark into validation and\ntest sets with similar difficulty and subject distributions. The test set\nremains closed-source to ensure reliable results, while the validation set is\npublicly available to promote transparency and facilitate independent\nverification. Our evaluation of mainstream LLMs reveals that the powerful\nGPT-4o achieves merely a 5-shot score of 73.4% and a 0-shot score of 71.9% on\nthe test set, which indicates the effectiveness of our approach in creating a\nmore rigorous and contamination-free evaluation standard. The GitHub repository\nis available at https://github.com/microsoft/MMLU-CF and the dataset refers to\nhttps://huggingface.co/datasets/microsoft/MMLU-CF.\n","authors":["Qihao Zhao","Yangyu Huang","Tengchao Lv","Lei Cui","Qinzheng Sun","Shaoguang Mao","Xin Zhang","Ying Xin","Qiufeng Yin","Scarlett Li","Furu Wei"],"pdf_url":"https://arxiv.org/pdf/2412.15194v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15189v1","updated":"2024-12-19T18:57:11Z","published":"2024-12-19T18:57:11Z","title":"Face the Facts! Evaluating RAG-based Fact-checking Pipelines in\n  Realistic Settings","summary":"  Natural Language Processing and Generation systems have recently shown the\npotential to complement and streamline the costly and time-consuming job of\nprofessional fact-checkers. In this work, we lift several constraints of\ncurrent state-of-the-art pipelines for automated fact-checking based on the\nRetrieval-Augmented Generation (RAG) paradigm. Our goal is to benchmark, under\nmore realistic scenarios, RAG-based methods for the generation of verdicts -\ni.e., short texts discussing the veracity of a claim - evaluating them on\nstylistically complex claims and heterogeneous, yet reliable, knowledge bases.\nOur findings show a complex landscape, where, for example, LLM-based retrievers\noutperform other retrieval techniques, though they still struggle with\nheterogeneous knowledge bases; larger models excel in verdict faithfulness,\nwhile smaller models provide better context adherence, with human evaluations\nfavouring zero-shot and one-shot approaches for informativeness, and fine-tuned\nmodels for emotional alignment.\n","authors":["Daniel Russo","Stefano Menini","Jacopo Staiano","Marco Guerini"],"pdf_url":"https://arxiv.org/pdf/2412.15189v1.pdf","comment":"Code and data at https://github.com/drusso98/face-the-facts"},{"id":"http://arxiv.org/abs/2412.15188v1","updated":"2024-12-19T18:56:24Z","published":"2024-12-19T18:56:24Z","title":"LlamaFusion: Adapting Pretrained Language Models for Multimodal\n  Generation","summary":"  We present LlamaFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLlamaFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LlamaFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLlamaFusion improves image understanding by 20% and image generation by 3.6%\nusing only 50% of the FLOPs while maintaining Llama-3's language capabilities.\nWe also demonstrate that this framework can adapt existing vision-language\nmodels with multimodal generation ability. Overall, this framework not only\nleverages existing computational investments in text-only LLMs but also enables\nthe parallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.\n","authors":["Weijia Shi","Xiaochuang Han","Chunting Zhou","Weixin Liang","Xi Victoria Lin","Luke Zettlemoyer","Lili Yu"],"pdf_url":"https://arxiv.org/pdf/2412.15188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15177v1","updated":"2024-12-19T18:51:30Z","published":"2024-12-19T18:51:30Z","title":"Critical-Questions-of-Thought: Steering LLM reasoning with Argumentative\n  Querying","summary":"  Studies have underscored how, regardless of the recent breakthrough and swift\nadvances in AI research, even state-of-the-art Large Language models (LLMs)\ncontinue to struggle when performing logical and mathematical reasoning. The\nresults seem to suggest that LLMs still work as (highly advanced) data pattern\nidentifiers, scoring poorly when attempting to generalise and solve reasoning\nproblems the models have never previously seen or that are not close to samples\npresented in their training data. To address this compelling concern, this\npaper makes use of the notion of critical questions from the literature on\nargumentation theory, focusing in particular on Toulmin's model of\nargumentation. We show that employing these critical questions can improve the\nreasoning capabilities of LLMs. By probing the rationale behind the models'\nreasoning process, the LLM can assess whether some logical mistake is occurring\nand correct it before providing the final reply to the user prompt. The\nunderlying idea is drawn from the gold standard of any valid argumentative\nprocedure: the conclusion is valid if it is entailed by accepted premises. Or,\nto paraphrase such Aristotelian principle in a real-world approximation,\ncharacterised by incomplete information and presumptive logic, the conclusion\nis valid if not proved otherwise. This approach successfully steers the models'\noutput through a reasoning pipeline, resulting in better performance against\nthe baseline and its Chain-of-Thought (CoT) implementation. To this end, an\nextensive evaluation of the proposed approach on the MT-Bench Reasoning and\nMath tasks across a range of LLMs is provided.\n","authors":["Federico Castagna","Isabel Sassoon","Simon Parsons"],"pdf_url":"https://arxiv.org/pdf/2412.15177v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.05199v2","updated":"2024-12-19T18:46:21Z","published":"2024-11-07T21:51:07Z","title":"CodeLutra: Boosting LLM Code Generation via Preference-Guided Refinement","summary":"  Large Language Models (LLMs) have revolutionized code generation but require\nsignificant resources and often over-generalize, limiting their task-specific\nefficiency. Fine-tuning smaller, open-source LLMs provides a cost-effective\nalternative. However, standard supervised approaches rely only on correct\nexamples, missing valuable insights from failures. We introduce CodeLutra, a\nframework that leverages both correct and incorrect code attempts. Instead of\nusing only correct solutions, CodeLutra applies iterative preference-based\nrefinement, comparing successful and failed outputs to better approximate\ndesired results. This approach narrows the performance gap with\nstate-of-the-art larger models without requiring massive datasets or auxiliary\nmodels. For instance, on a challenging data science coding task, using only 500\nsamples improved Llama-3-8B's accuracy from 28.2% to 48.6%, approaching GPT-4's\nlevel. By learning from both successes and mistakes, CodeLutra provides a\nscalable and efficient path to high-quality code generation, making smaller\nopen-source models more competitive with leading closed-source alternatives.\n","authors":["Leitian Tao","Xiang Chen","Tong Yu","Tung Mai","Ryan Rossi","Yixuan Li","Saayan Mitra"],"pdf_url":"https://arxiv.org/pdf/2411.05199v2.pdf","comment":"16 pages, 7 figures"},{"id":"http://arxiv.org/abs/2412.15156v1","updated":"2024-12-19T18:32:21Z","published":"2024-12-19T18:32:21Z","title":"Prompt-A-Video: Prompt Your Video Diffusion Model via Preference-Aligned\n  LLM","summary":"  Text-to-video models have made remarkable advancements through optimization\non high-quality text-video pairs, where the textual prompts play a pivotal role\nin determining quality of output videos. However, achieving the desired output\noften entails multiple revisions and iterative inference to refine\nuser-provided prompts. Current automatic methods for refining prompts encounter\nchallenges such as Modality-Inconsistency, Cost-Discrepancy, and Model-Unaware\nwhen applied to text-to-video diffusion models. To address these problem, we\nintroduce an LLM-based prompt adaptation framework, termed as Prompt-A-Video,\nwhich excels in crafting Video-Centric, Labor-Free and Preference-Aligned\nprompts tailored to specific video diffusion model. Our approach involves a\nmeticulously crafted two-stage optimization and alignment system. Initially, we\nconduct a reward-guided prompt evolution pipeline to automatically create\noptimal prompts pool and leverage them for supervised fine-tuning (SFT) of the\nLLM. Then multi-dimensional rewards are employed to generate pairwise data for\nthe SFT model, followed by the direct preference optimization (DPO) algorithm\nto further facilitate preference alignment. Through extensive experimentation\nand comparative analyses, we validate the effectiveness of Prompt-A-Video\nacross diverse generation models, highlighting its potential to push the\nboundaries of video generation.\n","authors":["Yatai Ji","Jiacheng Zhang","Jie Wu","Shilong Zhang","Shoufa Chen","Chongjian GE","Peize Sun","Weifeng Chen","Wenqi Shao","Xuefeng Xiao","Weilin Huang","Ping Luo"],"pdf_url":"https://arxiv.org/pdf/2412.15156v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15151v1","updated":"2024-12-19T18:28:41Z","published":"2024-12-19T18:28:41Z","title":"Language Models as Continuous Self-Evolving Data Engineers","summary":"  Large Language Models (LLMs) have demonstrated remarkable capabilities on\nvarious tasks, while the further evolvement is limited to the lack of\nhigh-quality training data. In addition, traditional training approaches rely\ntoo much on expert-labeled data, setting an upper limit on the performance of\nLLMs. To address this issue, we propose a novel paradigm that enables LLMs to\ntrain itself by autonomously generating, cleaning, reviewing, and annotating\ndata with preference information, named LANCE. Our approach demonstrates that\nLLMs can serve as continuous self-evolving data engineers, significantly\nreducing the time and cost of the post-training data construction process.\nThrough iterative fine-tuning on different variants of the Qwen2, we validate\nthe effectiveness of LANCE across various tasks, showing that it can\ncontinuously improve model performance and maintain high-quality data\ngeneration. Across eight benchmark dimensions, LANCE resulted in an average\nscore enhancement of 3.36 for Qwen2-7B and 2.70 for Qwen2-7B-Instruct. This\ntraining paradigm with autonomous data construction not only reduces the\nreliance on human experts or external models but also ensures that the data\naligns with human values and preferences, paving the way for the development of\nfuture superintelligent systems that can exceed human capabilities.\n","authors":["Peidong Wang","Ming Wang","Zhiming Ma","Xiaocui Yang","Shi Feng","Daling Wang","Yifei Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.15151v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15127v1","updated":"2024-12-19T18:08:04Z","published":"2024-12-19T18:08:04Z","title":"Adaptive Pruning for Large Language Models with Structural Importance\n  Awareness","summary":"  The recent advancements in large language models (LLMs) have significantly\nimproved language understanding and generation capabilities. However, it is\ndifficult to deploy LLMs on resource-constrained edge devices due to their high\ncomputational and storage resource demands. To address this issue, we propose a\nnovel LLM model pruning method, namely structurally-aware adaptive pruning\n(SAAP), to significantly reduce the computational and memory costs while\nmaintaining model performance. We first define an adaptive importance fusion\nmetric to evaluate the importance of all coupled structures in LLMs by\nconsidering their homoscedastic uncertainty. Then, we rank the importance of\nall modules to determine the specific layers that should be pruned to meet\nparticular performance requirements. Furthermore, we develop a new group\nfine-tuning strategy to improve the inference efficiency of LLMs. Finally, we\nevaluate the proposed SAAP method on multiple LLMs across two common tasks,\ni.e., zero-shot classification and text generation. Experimental results show\nthat our SAAP method outperforms several state-of-the-art baseline methods,\nachieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and\nLLaMA-13B. Additionally, SAAP improves the token generation speed by 5%,\nshowcasing its practical advantages in resource-constrained scenarios.\n","authors":["Haotian Zheng","Jinke Ren","Yushan Sun","Ruichen Zhang","Wenbo Zhang","Zhen Li","Dusit Niyato","Shuguang Cui","Yatong Han"],"pdf_url":"https://arxiv.org/pdf/2412.15127v1.pdf","comment":"12 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2412.15118v1","updated":"2024-12-19T17:59:42Z","published":"2024-12-19T17:59:42Z","title":"Outcome-Refining Process Supervision for Code Generation","summary":"  Large Language Models have demonstrated remarkable capabilities in code\ngeneration, yet they often struggle with complex programming tasks that require\ndeep algorithmic reasoning. While process supervision through learned reward\nmodels shows promise in guiding reasoning steps, it requires expensive training\ndata and suffers from unreliable evaluation. We propose Outcome-Refining\nProcess Supervision, a novel paradigm that treats outcome refinement itself as\nthe process to be supervised. Our framework leverages concrete execution\nsignals to ground the supervision of reasoning steps, while using\ntree-structured exploration to maintain multiple solution trajectories\nsimultaneously. Experiments demonstrate that our approach enables even smaller\nmodels to achieve high success accuracy and performance metrics on competitive\nprogramming tasks, creates more reliable verification than traditional reward\nmodels without requiring training PRMs. Our approach achieves significant\nimprovements across 5 models and 3 datasets: an average of 26.9% increase in\ncorrectness and 42.2% in efficiency. The results suggest that providing\nstructured reasoning space with concrete verification signals is crucial for\nsolving complex programming tasks. We open-source all our code and data at:\nhttps://github.com/zhuohaoyu/ORPS\n","authors":["Zhuohao Yu","Weizheng Gu","Yidong Wang","Zhengran Zeng","Jindong Wang","Wei Ye","Shikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.15118v1.pdf","comment":"18 pages, 5 figures, Code: https://github.com/zhuohaoyu/ORPS"},{"id":"http://arxiv.org/abs/2409.18472v2","updated":"2024-12-19T17:57:43Z","published":"2024-09-27T06:18:55Z","title":"URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological\n  and Multilingual Knowledge Base","summary":"  URIEL is a knowledge base offering geographical, phylogenetic, and\ntypological vector representations for 7970 languages. It includes distance\nmeasures between these vectors for 4005 languages, which are accessible via the\nlang2vec tool. Despite being frequently cited, URIEL is limited in terms of\nlinguistic inclusion and overall usability. To tackle these challenges, we\nintroduce URIEL+, an enhanced version of URIEL and lang2vec that addresses\nthese limitations. In addition to expanding typological feature coverage for\n2898 languages, URIEL+ improves the user experience with robust, customizable\ndistance calculations to better suit the needs of users. These upgrades also\noffer competitive performance on downstream tasks and provide distances that\nbetter align with linguistic distance studies.\n","authors":["Aditya Khan","Mason Shipton","David Anugraha","Kaiyao Duan","Phuong H. Hoang","Eric Khiu","A. Seza Doğruöz","En-Shiun Annie Lee"],"pdf_url":"https://arxiv.org/pdf/2409.18472v2.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.15115v1","updated":"2024-12-19T17:56:09Z","published":"2024-12-19T17:56:09Z","title":"Qwen2.5 Technical Report","summary":"  In this report, we introduce Qwen2.5, a comprehensive series of large\nlanguage models (LLMs) designed to meet diverse needs. Compared to previous\niterations, Qwen 2.5 has been significantly improved during both the\npre-training and post-training stages. In terms of pre-training, we have scaled\nthe high-quality pre-training datasets from the previous 7 trillion tokens to\n18 trillion tokens. This provides a strong foundation for common sense, expert\nknowledge, and reasoning capabilities. In terms of post-training, we implement\nintricate supervised finetuning with over 1 million samples, as well as\nmultistage reinforcement learning. Post-training techniques enhance human\npreference, and notably improve long text generation, structural data analysis,\nand instruction following. To handle diverse and varied use cases effectively,\nwe present Qwen2.5 LLM series in rich sizes. Open-weight offerings include base\nand instruction-tuned models, with quantized versions available. In addition,\nfor hosted solutions, the proprietary models currently include two\nmixture-of-experts (MoE) variants: Qwen2.5-Turbo and Qwen2.5-Plus, both\navailable from Alibaba Cloud Model Studio. Qwen2.5 has demonstrated top-tier\nperformance on a wide range of benchmarks evaluating language understanding,\nreasoning, mathematics, coding, human preference alignment, etc. Specifically,\nthe open-weight flagship Qwen2.5-72B-Instruct outperforms a number of open and\nproprietary models and demonstrates competitive performance to the\nstate-of-the-art open-weight model, Llama-3-405B-Instruct, which is around 5\ntimes larger. Qwen2.5-Turbo and Qwen2.5-Plus offer superior cost-effectiveness\nwhile performing competitively against GPT-4o-mini and GPT-4o respectively.\nAdditionally, as the foundation, Qwen2.5 models have been instrumental in\ntraining specialized models such as Qwen2.5-Math, Qwen2.5-Coder, QwQ, and\nmultimodal models.\n","authors":[" Qwen"," :","An Yang","Baosong Yang","Beichen Zhang","Binyuan Hui","Bo Zheng","Bowen Yu","Chengyuan Li","Dayiheng Liu","Fei Huang","Haoran Wei","Huan Lin","Jian Yang","Jianhong Tu","Jianwei Zhang","Jianxin Yang","Jiaxi Yang","Jingren Zhou","Junyang Lin","Kai Dang","Keming Lu","Keqin Bao","Kexin Yang","Le Yu","Mei Li","Mingfeng Xue","Pei Zhang","Qin Zhu","Rui Men","Runji Lin","Tianhao Li","Tingyu Xia","Xingzhang Ren","Xuancheng Ren","Yang Fan","Yang Su","Yichang Zhang","Yu Wan","Yuqiong Liu","Zeyu Cui","Zhenru Zhang","Zihan Qiu"],"pdf_url":"https://arxiv.org/pdf/2412.15115v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15113v1","updated":"2024-12-19T17:55:42Z","published":"2024-12-19T17:55:42Z","title":"Associative memory inspires improvements for in-context learning using a\n  novel attention residual stream architecture","summary":"  Large language models (LLMs) demonstrate an impressive ability to utilise\ninformation within the context of their input sequences to appropriately\nrespond to data unseen by the LLM during its training procedure. This ability\nis known as in-context learning (ICL). Humans and non-human animals demonstrate\nsimilar abilities, however their neural architectures differ substantially from\nLLMs. Despite this, a critical component within LLMs, the attention mechanism,\nresembles modern associative memory models, widely used in and influenced by\nthe computational neuroscience community to model biological memory systems.\nUsing this connection, we introduce an associative memory model capable of\nperforming ICL. We use this as inspiration for a novel residual stream\narchitecture which allows information to directly flow between attention heads.\nWe test this architecture during training within a two-layer Transformer and\nshow its ICL abilities manifest more quickly than without this modification. We\nthen apply our architecture in small language models with 8 million parameters,\nfocusing on attention head values, with results also indicating improved ICL\nperformance at this larger and more naturalistic scale.\n","authors":["Thomas F Burns","Tomoki Fukai","Christopher J Earls"],"pdf_url":"https://arxiv.org/pdf/2412.15113v1.pdf","comment":"18 pages, 6 figures, 3 tables"},{"id":"http://arxiv.org/abs/2412.04619v3","updated":"2024-12-19T17:51:34Z","published":"2024-12-05T21:12:37Z","title":"Sometimes I am a Tree: Data Drives Unstable Hierarchical Generalization","summary":"  Language models (LMs), like other neural networks, often favor shortcut\nheuristics based on surface-level patterns. Although LMs behave like n-gram\nmodels early in training, they must eventually learn hierarchical syntactic\nrepresentations to correctly apply grammatical rules out-of-distribution (OOD).\nIn this work, we use case studies of English grammar to explore how complex,\ndiverse training data drives models to generalize OOD. We construct a framework\nthat unifies our understanding of random variation with training dynamics, rule\nselection with memorization, and data diversity with complexity. We show that\nthese factors are nuanced, and that intermediate levels of diversity and\ncomplexity lead to inconsistent behavior across random seeds and to unstable\ntraining dynamics. Our findings emphasize the critical role of training data in\nshaping generalization patterns and illuminate how competing model strategies\nlead to inconsistent generalization outcomes across random seeds. Code is\navailable at https://github.com/sunnytqin/concept_comp.git.\n","authors":["Tian Qin","Naomi Saphra","David Alvarez-Melis"],"pdf_url":"https://arxiv.org/pdf/2412.04619v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15101v1","updated":"2024-12-19T17:48:23Z","published":"2024-12-19T17:48:23Z","title":"Review-Then-Refine: A Dynamic Framework for Multi-Hop Question Answering\n  with Temporal Adaptability","summary":"  Retrieve-augmented generation (RAG) frameworks have emerged as a promising\nsolution to multi-hop question answering(QA) tasks since it enables large\nlanguage models (LLMs) to incorporate external knowledge and mitigate their\ninherent knowledge deficiencies. Despite this progress, existing RAG\nframeworks, which usually follows the retrieve-then-read paradigm, often\nstruggle with multi-hop QA with temporal information since it has difficulty\nretrieving and synthesizing accurate time-related information. To address the\nchallenge, this paper proposes a novel framework called review-then-refine,\nwhich aims to enhance LLM performance in multi-hop QA scenarios with temporal\ninformation. Our approach begins with a review phase, where decomposed\nsub-queries are dynamically rewritten with temporal information, allowing for\nsubsequent adaptive retrieval and reasoning process. In addition, we implement\nadaptive retrieval mechanism to minimize unnecessary retrievals, thus reducing\nthe potential for hallucinations. In the subsequent refine phase, the LLM\nsynthesizes the retrieved information from each sub-query along with its\ninternal knowledge to formulate a coherent answer. Extensive experimental\nresults across multiple datasets demonstrate the effectiveness of our proposed\nframework, highlighting its potential to significantly improve multi-hop QA\ncapabilities in LLMs.\n","authors":["Xiangsen Chen","Xuming Hu","Nan Tang"],"pdf_url":"https://arxiv.org/pdf/2412.15101v1.pdf","comment":"20 pages, 2 figures"},{"id":"http://arxiv.org/abs/2412.15098v1","updated":"2024-12-19T17:46:13Z","published":"2024-12-19T17:46:13Z","title":"A Cross-Domain Study of the Use of Persuasion Techniques in Online\n  Disinformation","summary":"  Disinformation, irrespective of domain or language, aims to deceive or\nmanipulate public opinion, typically through employing advanced persuasion\ntechniques. Qualitative and quantitative research on the weaponisation of\npersuasion techniques in disinformation has been mostly topic-specific (e.g.,\nCOVID-19) with limited cross-domain studies, resulting in a lack of\ncomprehensive understanding of these strategies. This study employs a\nstate-of-the-art persuasion technique classifier to conduct a large-scale,\nmulti-domain analysis of the role of 16 persuasion techniques in disinformation\nnarratives. It shows how different persuasion techniques are employed\ndisproportionately in different disinformation domains. We also include a\ndetailed case study on climate change disinformation, highlighting how\nlinguistic, psychological, and cultural factors shape the adaptation of\npersuasion strategies to fit unique thematic contexts.\n","authors":["João A. Leite","Olesya Razuvayevskaya","Carolina Scarton","Kalina Bontcheva"],"pdf_url":"https://arxiv.org/pdf/2412.15098v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13702v2","updated":"2024-12-19T17:36:38Z","published":"2024-12-18T10:45:24Z","title":"Typhoon 2: A Family of Open Text and Multimodal Thai Large Language\n  Models","summary":"  This paper introduces Typhoon 2, a series of text and multimodal large\nlanguage models optimized for the Thai language. The series includes models for\ntext, vision, and audio. Typhoon2-Text builds on state-of-the-art open models,\nsuch as Llama 3 and Qwen2, and we perform continual pre-training on a mixture\nof English and Thai data. We employ post-training techniques to enhance Thai\nlanguage performance while preserving the base models' original capabilities.\nWe release text models across a range of sizes, from 1 to 70 billion\nparameters, available in both base and instruction-tuned variants. To guardrail\ntext generation, we release Typhoon2-Safety, a classifier enhanced for Thai\ncultures and language. Typhoon2-Vision improves Thai document understanding\nwhile retaining general visual capabilities, such as image captioning.\nTyphoon2-Audio introduces an end-to-end speech-to-speech model architecture\ncapable of processing audio, speech, and text inputs and generating both text\nand speech outputs.\n","authors":["Kunat Pipatanakul","Potsawee Manakul","Natapong Nitarach","Warit Sirichotedumrong","Surapon Nonesung","Teetouch Jaknamon","Parinthapat Pengpun","Pittawat Taveekitworachai","Adisai Na-Thalang","Sittipong Sripaisarnmongkol","Krisanapong Jirayoot","Kasima Tharnpipitchai"],"pdf_url":"https://arxiv.org/pdf/2412.13702v2.pdf","comment":"technical report, 55 pages"},{"id":"http://arxiv.org/abs/2412.15084v1","updated":"2024-12-19T17:29:44Z","published":"2024-12-19T17:29:44Z","title":"AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward\n  Modeling","summary":"  In this paper, we introduce AceMath, a suite of frontier math models that\nexcel in solving complex math problems, along with highly effective reward\nmodels capable of evaluating generated solutions and reliably identifying the\ncorrect ones. To develop the instruction-tuned math models, we propose a\nsupervised fine-tuning (SFT) process that first achieves competitive\nperformance across general domains, followed by targeted fine-tuning for the\nmath domain using a carefully curated set of prompts and synthetically\ngenerated responses. The resulting model, AceMath-72B-Instruct greatly\noutperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop\nmath-specialized reward model, we first construct AceMath-RewardBench, a\ncomprehensive and robust benchmark for evaluating math reward models across\ndiverse problems and difficulty levels. After that, we present a systematic\napproach to build our math reward models. The resulting model, AceMath-72B-RM,\nconsistently outperforms state-of-the-art reward models. Furthermore, when\ncombining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest\naverage rm@8 score across the math reasoning benchmarks. We will release model\nweights, training data, and evaluation benchmarks at:\nhttps://research.nvidia.com/labs/adlr/acemath\n","authors":["Zihan Liu","Yang Chen","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2412.15084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15077v1","updated":"2024-12-19T17:26:07Z","published":"2024-12-19T17:26:07Z","title":"Till the Layers Collapse: Compressing a Deep Neural Network through the\n  Lenses of Batch Normalization Layers","summary":"  Today, deep neural networks are widely used since they can handle a variety\nof complex tasks. Their generality makes them very powerful tools in modern\ntechnology. However, deep neural networks are often overparameterized. The\nusage of these large models consumes a lot of computation resources. In this\npaper, we introduce a method called \\textbf{T}ill the \\textbf{L}ayers\n\\textbf{C}ollapse (TLC), which compresses deep neural networks through the\nlenses of batch normalization layers. By reducing the depth of these networks,\nour method decreases deep neural networks' computational requirements and\noverall latency. We validate our method on popular models such as Swin-T,\nMobileNet-V2, and RoBERTa, across both image classification and natural\nlanguage processing (NLP) tasks.\n","authors":["Zhu Liao","Nour Hezbri","Victor Quétu","Van-Tam Nguyen","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2412.15077v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.15060v1","updated":"2024-12-19T17:08:11Z","published":"2024-12-19T17:08:11Z","title":"ConfliBERT: A Language Model for Political Conflict","summary":"  Conflict scholars have used rule-based approaches to extract information\nabout political violence from news reports and texts. Recent Natural Language\nProcessing developments move beyond rigid rule-based approaches. We review our\nrecent ConfliBERT language model (Hu et al. 2022) to process political and\nviolence related texts. The model can be used to extract actor and action\nclassifications from texts about political conflict. When fine-tuned, results\nshow that ConfliBERT has superior performance in accuracy, precision and recall\nover other large language models (LLM) like Google's Gemma 2 (9B), Meta's Llama\n3.1 (7B), and Alibaba's Qwen 2.5 (14B) within its relevant domains. It is also\nhundreds of times faster than these more generalist LLMs. These results are\nillustrated using texts from the BBC, re3d, and the Global Terrorism Dataset\n(GTD).\n","authors":["Patrick T. Brandt","Sultan Alsarra","Vito J. D`Orazio","Dagmar Heintze","Latifur Khan","Shreyas Meher","Javier Osorio","Marcus Sianan"],"pdf_url":"https://arxiv.org/pdf/2412.15060v1.pdf","comment":"30 pages, 4 figures, 5 tables"},{"id":"http://arxiv.org/abs/2412.15035v1","updated":"2024-12-19T16:46:54Z","published":"2024-12-19T16:46:54Z","title":"LLMs Lost in Translation: M-ALERT uncovers Cross-Linguistic Safety Gaps","summary":"  Building safe Large Language Models (LLMs) across multiple languages is\nessential in ensuring both safe access and linguistic diversity. To this end,\nwe introduce M-ALERT, a multilingual benchmark that evaluates the safety of\nLLMs in five languages: English, French, German, Italian, and Spanish. M-ALERT\nincludes 15k high-quality prompts per language, totaling 75k, following the\ndetailed ALERT taxonomy. Our extensive experiments on 10 state-of-the-art LLMs\nhighlight the importance of language-specific safety analysis, revealing that\nmodels often exhibit significant inconsistencies in safety across languages and\ncategories. For instance, Llama3.2 shows high unsafety in the category\ncrime_tax for Italian but remains safe in other languages. Similar differences\ncan be observed across all models. In contrast, certain categories, such as\nsubstance_cannabis and crime_propaganda, consistently trigger unsafe responses\nacross models and languages. These findings underscore the need for robust\nmultilingual safety practices in LLMs to ensure safe and responsible usage\nacross diverse user communities.\n","authors":["Felix Friedrich","Simone Tedeschi","Patrick Schramowski","Manuel Brack","Roberto Navigli","Huu Nguyen","Bo Li","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2412.15035v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14512v3","updated":"2024-12-19T16:37:00Z","published":"2024-08-25T04:32:45Z","title":"LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with\n  LLM Token Embeddings","summary":"  Zero-shot graph machine learning, especially with graph neural networks\n(GNNs), has garnered significant interest due to the challenge of scarce\nlabeled data. While methods like self-supervised learning and graph prompt\nlearning have been extensively explored, they often rely on fine-tuning with\ntask-specific labels, limiting their effectiveness in zero-shot scenarios.\nInspired by the zero-shot capabilities of instruction-fine-tuned large language\nmodels (LLMs), we introduce a novel framework named Token Embedding-Aligned\nGraph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and\ncross-task zero-shot learners for graph machine learning. Concretely, we\npretrain a GNN, aligning its representations with token embeddings of an LLM.\nWe then train a linear projector that transforms the GNN's representations into\na fixed number of graph token embeddings without tuning the LLM. A unified\ninstruction is designed for various graph tasks at different levels, such as\nnode classification (node-level) and link prediction (edge-level). These design\nchoices collectively enhance our method's effectiveness in zero-shot learning,\nsetting it apart from existing methods. Experiments show that our graph token\nembeddings help the LLM predictor achieve state-of-the-art performance on\nunseen datasets and tasks compared to other methods using LLMs as predictors.\n","authors":["Duo Wang","Yuan Zuo","Fengzhi Li","Junjie Wu"],"pdf_url":"https://arxiv.org/pdf/2408.14512v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.10868v4","updated":"2024-12-19T16:22:07Z","published":"2024-06-16T09:36:32Z","title":"Identifying Query-Relevant Neurons in Large Language Models for\n  Long-Form Texts","summary":"  Large Language Models (LLMs) possess vast amounts of knowledge within their\nparameters, prompting research into methods for locating and editing this\nknowledge. Previous work has largely focused on locating entity-related (often\nsingle-token) facts in smaller models. However, several key questions remain\nunanswered: (1) How can we effectively locate query-relevant neurons in\ndecoder-only LLMs, such as Llama and Mistral? (2) How can we address the\nchallenge of long-form (or free-form) text generation? (3) Are there localized\nknowledge regions in LLMs? In this study, we introduce Query-Relevant Neuron\nCluster Attribution (QRNCA), a novel architecture-agnostic framework capable of\nidentifying query-relevant neurons in LLMs. QRNCA allows for the examination of\nlong-form answers beyond triplet facts by employing the proxy task of\nmulti-choice question answering. To evaluate the effectiveness of our detected\nneurons, we build two multi-choice QA datasets spanning diverse domains and\nlanguages. Empirical evaluations demonstrate that our method outperforms\nbaseline methods significantly. Further, analysis of neuron distributions\nreveals the presence of visible localized regions, particularly within\ndifferent domains. Finally, we show potential applications of our detected\nneurons in knowledge editing and neuron-based prediction.\n","authors":["Lihu Chen","Adam Dejl","Francesca Toni"],"pdf_url":"https://arxiv.org/pdf/2406.10868v4.pdf","comment":"AAAI 2025 Main Track"},{"id":"http://arxiv.org/abs/2411.10912v2","updated":"2024-12-19T16:20:49Z","published":"2024-11-16T23:29:32Z","title":"SPICA: Retrieving Scenarios for Pluralistic In-Context Alignment","summary":"  When different groups' values differ, one approach to model alignment is to\nsteer models at inference time towards each group's preferences. However,\ntechniques like in-context learning only consider similarity when drawing\nfew-shot examples and not cross-group differences in values. We propose SPICA,\na framework that accounts for group-level differences during in-context example\nretrieval. SPICA introduces three designs: scenario banks, group-informed\nretrieval metrics, and in-context alignment prompts. From an evaluation of\nSPICA on an alignment task collecting inputs from four demographic groups ($n =\n544$), our metrics retrieve in-context examples that more closely match\nobserved preferences, with the best prompt configuration using multiple\ncontrastive responses to demonstrate examples. In an end-to-end evaluation ($n\n= 120$), we observe that SPICA is higher rated than similarity-based retrieval,\nwith groups seeing up to a +0.16 point improvement on a 5 point scale.\nAdditionally, gains from SPICA were more uniform, with all groups benefiting\nfrom alignment rather than only some. Finally, we find that while a\ngroup-agnostic approach can align to aggregated values, it is not most suited\nfor divergent groups.\n","authors":["Quan Ze Chen","K. J. Kevin Feng","Chan Young Park","Amy X. Zhang"],"pdf_url":"https://arxiv.org/pdf/2411.10912v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15004v1","updated":"2024-12-19T16:20:22Z","published":"2024-12-19T16:20:22Z","title":"Large Language Models and Code Security: A Systematic Literature Review","summary":"  Large Language Models (LLMs) have emerged as powerful tools for automating\nvarious programming tasks, including security-related ones, such as detecting\nand fixing vulnerabilities. Despite their promising capabilities, when required\nto produce or modify pre-existing code, LLMs could introduce vulnerabilities\nunbeknown to the programmer. When analyzing code, they could miss clear\nvulnerabilities or signal nonexistent ones. In this Systematic Literature\nReview (SLR), we aim to investigate both the security benefits and potential\ndrawbacks of using LLMs for a variety of code-related tasks. In particular,\nfirst we focus on the types of vulnerabilities that could be introduced by\nLLMs, when used for producing code. Second, we analyze the capabilities of LLMs\nto detect and fix vulnerabilities, in any given code, and how the prompting\nstrategy of choice impacts their performance in these two tasks. Last, we\nprovide an in-depth analysis on how data poisoning attacks on LLMs can impact\nperformance in the aforementioned tasks.\n","authors":["Enna Basic","Alberto Giaretta"],"pdf_url":"https://arxiv.org/pdf/2412.15004v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.08406v2","updated":"2024-12-19T16:09:47Z","published":"2024-09-12T21:39:01Z","title":"Knowledge Tagging with Large Language Model based Multi-Agent System","summary":"  Knowledge tagging for questions is vital in modern intelligent educational\napplications, including learning progress diagnosis, practice question\nrecommendations, and course content organization. Traditionally, these\nannotations have been performed by pedagogical experts, as the task demands not\nonly a deep semantic understanding of question stems and knowledge definitions\nbut also a strong ability to link problem-solving logic with relevant knowledge\nconcepts. With the advent of advanced natural language processing (NLP)\nalgorithms, such as pre-trained language models and large language models\n(LLMs), pioneering studies have explored automating the knowledge tagging\nprocess using various machine learning models. In this paper, we investigate\nthe use of a multi-agent system to address the limitations of previous\nalgorithms, particularly in handling complex cases involving intricate\nknowledge definitions and strict numerical constraints. By demonstrating its\nsuperior performance on the publicly available math question knowledge tagging\ndataset, MathKnowCT, we highlight the significant potential of an LLM-based\nmulti-agent system in overcoming the challenges that previous methods have\nencountered. Finally, through an in-depth discussion of the implications of\nautomating knowledge tagging, we underscore the promising results of deploying\nLLM-based algorithms in educational contexts.\n","authors":["Hang Li","Tianlong Xu","Ethan Chang","Qingsong Wen"],"pdf_url":"https://arxiv.org/pdf/2409.08406v2.pdf","comment":"Accepted by AAAI 2025 (AAAI/IAAI 2025 Innovative Application Award)"},{"id":"http://arxiv.org/abs/2412.14986v1","updated":"2024-12-19T15:58:53Z","published":"2024-12-19T15:58:53Z","title":"Chain-of-MetaWriting: Linguistic and Textual Analysis of How Small\n  Language Models Write Young Students Texts","summary":"  Large Language Models (LLMs) have been used to generate texts in response to\ndifferent writing tasks: reports, essays, story telling. However, language\nmodels do not have a meta-representation of the text writing process, nor\ninherent communication learning needs, comparable to those of young human\nstudents. This paper introduces a fine-grained linguistic and textual analysis\nof multilingual Small Language Models' (SLMs) writing. With our method,\nChain-of-MetaWriting, SLMs can imitate some steps of the human writing process,\nsuch as planning and evaluation. We mainly focused on short story and essay\nwriting tasks in French for schoolchildren and undergraduate students\nrespectively. Our results show that SLMs encounter difficulties in assisting\nyoung students on sensitive topics such as violence in the schoolyard, and they\nsometimes use words too complex for the target audience. In particular, the\noutput is quite different from the human produced texts in term of text\ncohesion and coherence regarding temporal connectors, topic progression,\nreference.\n","authors":["Ioana Buhnila","Georgeta Cislaru","Amalia Todirascu"],"pdf_url":"https://arxiv.org/pdf/2412.14986v1.pdf","comment":"Accepted at WRAICOGS 2025 (Writing Aids at the Crossroads of AI,\n  Cognitive Science, and NLP) co-located with COLING 2025"},{"id":"http://arxiv.org/abs/2412.11745v2","updated":"2024-12-19T15:55:45Z","published":"2024-12-16T13:03:43Z","title":"Beyond Dataset Creation: Critical View of Annotation Variation and Bias\n  Probing of a Dataset for Online Radical Content Detection","summary":"  The proliferation of radical content on online platforms poses significant\nrisks, including inciting violence and spreading extremist ideologies. Despite\nongoing research, existing datasets and models often fail to address the\ncomplexities of multilingual and diverse data. To bridge this gap, we introduce\na publicly available multilingual dataset annotated with radicalization levels,\ncalls for action, and named entities in English, French, and Arabic. This\ndataset is pseudonymized to protect individual privacy while preserving\ncontextual information. Beyond presenting our freely available dataset, we\nanalyze the annotation process, highlighting biases and disagreements among\nannotators and their implications for model performance. Additionally, we use\nsynthetic data to investigate the influence of socio-demographic traits on\nannotation patterns and model predictions. Our work offers a comprehensive\nexamination of the challenges and opportunities in building robust datasets for\nradical content detection, emphasizing the importance of fairness and\ntransparency in model development.\n","authors":["Arij Riabi","Virginie Mouilleron","Menel Mahamdi","Wissam Antoun","Djamé Seddah"],"pdf_url":"https://arxiv.org/pdf/2412.11745v2.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.13765v2","updated":"2024-12-19T15:50:54Z","published":"2024-12-18T12:01:53Z","title":"LLM-SEM: A Sentiment-Based Student Engagement Metric Using LLMS for\n  E-Learning Platforms","summary":"  Current methods for analyzing student engagement in e-learning platforms,\nincluding automated systems, often struggle with challenges such as handling\nfuzzy sentiment in text comments and relying on limited metadata. Traditional\napproaches, such as surveys and questionnaires, also face issues like small\nsample sizes and scalability. In this paper, we introduce LLM-SEM (Language\nModel-Based Student Engagement Metric), a novel approach that leverages video\nmetadata and sentiment analysis of student comments to measure engagement. By\nutilizing recent Large Language Models (LLMs), we generate high-quality\nsentiment predictions to mitigate text fuzziness and normalize key features\nsuch as views and likes. Our holistic method combines comprehensive metadata\nwith sentiment polarity scores to gauge engagement at both the course and\nlesson levels. Extensive experiments were conducted to evaluate various LLM\nmodels, demonstrating the effectiveness of LLM-SEM in providing a scalable and\naccurate measure of student engagement. We fine-tuned TXLM-RoBERTa using\nhuman-annotated sentiment datasets to enhance prediction accuracy and utilized\nLLama 3B, and Gemma 9B from Ollama.\n","authors":["Ali Hamdi","Ahmed Abdelmoneim Mazrou","Mohamed Shaltout"],"pdf_url":"https://arxiv.org/pdf/2412.13765v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14965v1","updated":"2024-12-19T15:44:04Z","published":"2024-12-19T15:44:04Z","title":"Movie2Story: A framework for understanding videos and telling stories in\n  the form of novel text","summary":"  Multimodal video-to-text models have made considerable progress, primarily in\ngenerating brief descriptions of video content. However, there is still a\ndeficiency in generating rich long-form text descriptions that integrate both\nvideo and audio. In this paper, we introduce a framework called M2S, designed\nto generate novel-length text by combining audio, video, and character\nrecognition. M2S includes modules for video long-form text description and\ncomprehension, audio-based analysis of emotion, speech rate, and character\nalignment, and visual-based character recognition alignment. By integrating\nmultimodal information using the large language model GPT4o, M2S stands out in\nthe field of multimodal text generation. We demonstrate the effectiveness and\naccuracy of M2S through comparative experiments and human evaluation.\nAdditionally, the model framework has good scalability and significant\npotential for future research.\n","authors":["Kangning Li","Zheyang Jia","Anyu Ying"],"pdf_url":"https://arxiv.org/pdf/2412.14965v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14964v1","updated":"2024-12-19T15:44:01Z","published":"2024-12-19T15:44:01Z","title":"Knowledge Injection via Prompt Distillation","summary":"  In many practical applications, large language models (LLMs) need to\nincorporate new knowledge not present in their pre-training data. The primary\nmethods for this are fine-tuning and retrieval-augmented generation (RAG).\nAlthough RAG has emerged as the industry standard for knowledge injection,\nfine-tuning has not yet achieved comparable success. In this paper, we propose\na new fine-tuning technique for learning new knowledge and show that it can\nreach the performance of RAG. The proposed method is based on the\nself-distillation approach, which we call prompt distillation. First, we\ngenerate question-answer pairs about the new knowledge. Then, we fine-tune a\nstudent model on the question-answer pairs to imitate the output distributions\nof a teacher model, which additionally receives the new knowledge in its\nprompt. The student model is identical to the teacher, except it is equipped\nwith a LoRA adapter. This training procedure facilitates distilling the new\nknowledge from the teacher's prompt into the student's weights.\n","authors":["Kalle Kujanpää","Harri Valpola","Alexander Ilin"],"pdf_url":"https://arxiv.org/pdf/2412.14964v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.14959v1","updated":"2024-12-19T15:39:31Z","published":"2024-12-19T15:39:31Z","title":"Understanding the Dark Side of LLMs' Intrinsic Self-Correction","summary":"  Intrinsic self-correction was proposed to improve LLMs' responses via\nfeedback prompts solely based on their inherent capability. However, recent\nworks show that LLMs' intrinsic self-correction fails without oracle labels as\nfeedback prompts. In this paper, we aim to interpret LLMs' intrinsic\nself-correction for different tasks, especially for those failure cases. By\nincluding one simple task and three complex tasks with state-of-the-art (SOTA)\nLLMs like ChatGPT families (o1, 4o, 3.5-turbo) and Llama families (2-7B, 3-8B,\nand 3.1-8B), we design three interpretation methods to reveal the dark side of\nLLMs' intrinsic self-correction. We identify intrinsic self-correction can (1)\ncause LLMs to waver both intermedia and final answers and lead to prompt bias\non simple factual questions; (2) introduce human-like cognitive bias on complex\ntasks. In light of our findings, we also provide two simple yet effective\nstrategies for alleviation: question repeating and supervised fine-tuning with\na few samples. We open-source our work at https://x-isc.info/.\n","authors":["Qingjie Zhang","Han Qiu","Di Wang","Haoting Qian","Yiming Li","Tianwei Zhang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2412.14959v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13647v2","updated":"2024-12-19T15:37:55Z","published":"2024-12-18T09:23:12Z","title":"G-VEval: A Versatile Metric for Evaluating Image and Video Captions\n  Using GPT-4o","summary":"  Evaluation metric of visual captioning is important yet not thoroughly\nexplored. Traditional metrics like BLEU, METEOR, CIDEr, and ROUGE often miss\nsemantic depth, while trained metrics such as CLIP-Score, PAC-S, and Polos are\nlimited in zero-shot scenarios. Advanced Language Model-based metrics also\nstruggle with aligning to nuanced human preferences. To address these issues,\nwe introduce G-VEval, a novel metric inspired by G-Eval and powered by the new\nGPT-4o. G-VEval uses chain-of-thought reasoning in large multimodal models and\nsupports three modes: reference-free, reference-only, and combined,\naccommodating both video and image inputs. We also propose MSVD-Eval, a new\ndataset for video captioning evaluation, to establish a more transparent and\nconsistent framework for both human experts and evaluation metrics. It is\ndesigned to address the lack of clear criteria in existing datasets by\nintroducing distinct dimensions of Accuracy, Completeness, Conciseness, and\nRelevance (ACCR). Extensive results show that G-VEval outperforms existing\nmethods in correlation with human annotations, as measured by Kendall tau-b and\nKendall tau-c. This provides a flexible solution for diverse captioning tasks\nand suggests a straightforward yet effective approach for large language models\nto understand video content, paving the way for advancements in automated\ncaptioning. Codes are available at https://github.com/ztangaj/gveval\n","authors":["Tony Cheng Tong","Sirui He","Zhiwen Shao","Dit-Yan Yeung"],"pdf_url":"https://arxiv.org/pdf/2412.13647v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.20054v2","updated":"2024-12-19T15:30:40Z","published":"2024-06-28T17:07:06Z","title":"To Word Senses and Beyond: Inducing Concepts with Contextualized\n  Language Models","summary":"  Polysemy and synonymy are two crucial interrelated facets of lexical\nambiguity. While both phenomena are widely documented in lexical resources and\nhave been studied extensively in NLP, leading to dedicated systems, they are\noften being considered independently in practical problems. While many tasks\ndealing with polysemy (e.g. Word Sense Disambiguiation or Induction) highlight\nthe role of word's senses, the study of synonymy is rooted in the study of\nconcepts, i.e. meanings shared across the lexicon. In this paper, we introduce\nConcept Induction, the unsupervised task of learning a soft clustering among\nwords that defines a set of concepts directly from data. This task generalizes\nWord Sense Induction. We propose a bi-level approach to Concept Induction that\nleverages both a local lemma-centric view and a global cross-lexicon view to\ninduce concepts. We evaluate the obtained clustering on SemCor's annotated data\nand obtain good performance (BCubed F1 above 0.60). We find that the local and\nthe global levels are mutually beneficial to induce concepts and also senses in\nour setting. Finally, we create static embeddings representing our induced\nconcepts and use them on the Word-in-Context task, obtaining competitive\nperformance with the State-of-the-Art.\n","authors":["Bastien Liétard","Pascal Denis","Mikaella Keller"],"pdf_url":"https://arxiv.org/pdf/2406.20054v2.pdf","comment":"Published in EMNLP 2024 main conference proceedings"},{"id":"http://arxiv.org/abs/2408.10839v2","updated":"2024-12-19T15:25:41Z","published":"2024-08-20T13:34:17Z","title":"Benchmarking Large Language Models for Math Reasoning Tasks","summary":"  The use of Large Language Models (LLMs) in mathematical reasoning has become\na cornerstone of related research, demonstrating the intelligence of these\nmodels and enabling potential practical applications through their advanced\nperformance, such as in educational settings. Despite the variety of datasets\nand in-context learning algorithms designed to improve the ability of LLMs to\nautomate mathematical problem solving, the lack of comprehensive benchmarking\nacross different datasets makes it complicated to select an appropriate model\nfor specific tasks. In this project, we present a benchmark that fairly\ncompares seven state-of-the-art in-context learning algorithms for mathematical\nproblem solving across five widely used mathematical datasets on four powerful\nfoundation models. Furthermore, we explore the trade-off between efficiency and\nperformance, highlighting the practical applications of LLMs for mathematical\nreasoning. Our results indicate that larger foundation models like GPT-4o and\nLLaMA 3-70B can solve mathematical reasoning independently from the concrete\nprompting strategy, while for smaller models the in-context learning approach\nsignificantly influences the performance. Moreover, the optimal prompt depends\non the chosen foundation model. We open-source our benchmark code to support\nthe integration of additional models in future research.\n","authors":["Kathrin Seßler","Yao Rong","Emek Gözlüklü","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2408.10839v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2412.11795v2","updated":"2024-12-19T15:21:44Z","published":"2024-12-16T14:07:39Z","title":"ProsodyFM: Unsupervised Phrasing and Intonation Control for Intelligible\n  Speech Synthesis","summary":"  Prosody contains rich information beyond the literal meaning of words, which\nis crucial for the intelligibility of speech. Current models still fall short\nin phrasing and intonation; they not only miss or misplace breaks when\nsynthesizing long sentences with complex structures but also produce unnatural\nintonation. We propose ProsodyFM, a prosody-aware text-to-speech synthesis\n(TTS) model with a flow-matching (FM) backbone that aims to enhance the\nphrasing and intonation aspects of prosody. ProsodyFM introduces two key\ncomponents: a Phrase Break Encoder to capture initial phrase break locations,\nfollowed by a Duration Predictor for the flexible adjustment of break\ndurations; and a Terminal Intonation Encoder which learns a bank of intonation\nshape tokens combined with a novel Pitch Processor for more robust modeling of\nhuman-perceived intonation change. ProsodyFM is trained with no explicit\nprosodic labels and yet can uncover a broad spectrum of break durations and\nintonation patterns. Experimental results demonstrate that ProsodyFM can\neffectively improve the phrasing and intonation aspects of prosody, thereby\nenhancing the overall intelligibility compared to four state-of-the-art (SOTA)\nmodels. Out-of-distribution experiments show that this prosody improvement can\nfurther bring ProsodyFM superior generalizability for unseen complex sentences\nand speakers. Our case study intuitively illustrates the powerful and\nfine-grained controllability of ProsodyFM over phrasing and intonation.\n","authors":["Xiangheng He","Junjie Chen","Zixing Zhang","Björn W. Schuller"],"pdf_url":"https://arxiv.org/pdf/2412.11795v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2410.07991v4","updated":"2024-12-19T15:16:49Z","published":"2024-10-10T14:48:57Z","title":"Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic\n  Analysis of Annotators and Targets","summary":"  The rise of online platforms exacerbated the spread of hate speech, demanding\nscalable and effective detection. However, the accuracy of hate speech\ndetection systems heavily relies on human-labeled data, which is inherently\nsusceptible to biases. While previous work has examined the issue, the\ninterplay between the characteristics of the annotator and those of the target\nof the hate are still unexplored. We fill this gap by leveraging an extensive\ndataset with rich socio-demographic information of both annotators and targets,\nuncovering how human biases manifest in relation to the target's attributes.\nOur analysis surfaces the presence of widespread biases, which we\nquantitatively describe and characterize based on their intensity and\nprevalence, revealing marked differences. Furthermore, we compare human biases\nwith those exhibited by persona-based LLMs. Our findings indicate that while\npersona-based LLMs do exhibit biases, these differ significantly from those of\nhuman annotators. Overall, our work offers new and nuanced results on human\nbiases in hate speech annotations, as well as fresh insights into the design of\nAI-driven hate speech detection systems.\n","authors":["Tommaso Giorgi","Lorenzo Cima","Tiziano Fagni","Marco Avvenuti","Stefano Cresci"],"pdf_url":"https://arxiv.org/pdf/2410.07991v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09378v2","updated":"2024-12-19T15:14:18Z","published":"2024-12-12T15:46:43Z","title":"From Bench to Bedside: A Review of Clinical Trials in Drug Discovery and\n  Development","summary":"  Clinical trials are an indispensable part of the drug development process,\nbridging the gap between basic research and clinical application. During the\ndevelopment of new drugs, clinical trials are used not only to evaluate the\nsafety and efficacy of the drug but also to explore its dosage, treatment\nregimens, and potential side effects. This review discusses the various stages\nof clinical trials, including Phase I (safety assessment), Phase II\n(preliminary efficacy evaluation), Phase III (large-scale validation), and\nPhase IV (post-marketing surveillance), highlighting the characteristics of\neach phase and their interrelationships. Additionally, the paper addresses the\nmajor challenges encountered in clinical trials, such as ethical issues,\nsubject recruitment difficulties, diversity and representativeness concerns,\nand proposes strategies for overcoming these challenges. With the advancement\nof technology, innovative technologies such as artificial intelligence, big\ndata, and digitalization are gradually transforming clinical trial design and\nimplementation, improving trial efficiency and data quality. The article also\nlooks forward to the future of clinical trials, particularly the impact of\nemerging therapies such as gene therapy and immunotherapy on trial design, as\nwell as the importance of regulatory reforms and global collaboration. In\nconclusion, the core role of clinical trials in drug development will continue\nto drive the progress of innovative drug development and clinical treatment.\n","authors":["Tianyang Wang","Ming Liu","Benji Peng","Xinyuan Song","Charles Zhang","Xintian Sun","Qian Niu","Junyu Liu","Silin Chen","Keyu Chen","Ming Li","Pohsun Feng","Ziqian Bi","Yunze Wang","Yichao Zhang","Cheng Fei","Lawrence KQ Yan"],"pdf_url":"https://arxiv.org/pdf/2412.09378v2.pdf","comment":"11 pages"},{"id":"http://arxiv.org/abs/2407.04693v2","updated":"2024-12-19T15:11:47Z","published":"2024-07-05T17:56:38Z","title":"ANAH-v2: Scaling Analytical Hallucination Annotation of Large Language\n  Models","summary":"  Large language models (LLMs) exhibit hallucinations in long-form\nquestion-answering tasks across various domains and wide applications. Current\nhallucination detection and mitigation datasets are limited in domains and\nsizes, which struggle to scale due to prohibitive labor costs and insufficient\nreliability of existing hallucination annotators. To facilitate the scalable\noversight of LLM hallucinations, this paper introduces an iterative\nself-training framework that simultaneously and progressively scales up the\nhallucination annotation dataset and improves the accuracy of the hallucination\nannotator. Based on the Expectation Maximization (EM) algorithm, in each\niteration, the framework first applies a hallucination annotation pipeline to\nannotate a scaled dataset and then trains a more accurate hallucination\nannotator on the dataset. This new hallucination annotator is adopted in the\nhallucination annotation pipeline used for the next iteration. Extensive\nexperimental results demonstrate that the finally obtained hallucination\nannotator with only 7B parameters surpasses the performance of GPT-4 and\nobtains new state-of-the-art hallucination detection results on HaluEval and\nHalluQA by zero-shot inference. Such an annotator can not only evaluate the\nhallucination levels of various LLMs on the large-scale dataset but also help\nto mitigate the hallucination of LLMs generations, with the Natural Language\nInference (NLI) metric increasing from 25% to 37% on HaluEval.\n","authors":["Yuzhe Gu","Ziwei Ji","Wenwei Zhang","Chengqi Lyu","Dahua Lin","Kai Chen"],"pdf_url":"https://arxiv.org/pdf/2407.04693v2.pdf","comment":"Accepted by NeurIPS 2024. Dataset, code, and model are released at\n  https://github.com/open-compass/ANAH"},{"id":"http://arxiv.org/abs/2411.16300v3","updated":"2024-12-19T15:11:46Z","published":"2024-11-25T11:35:08Z","title":"BayLing 2: A Multilingual Large Language Model with Efficient Language\n  Alignment","summary":"  Large language models (LLMs), with their powerful generative capabilities and\nvast knowledge, empower various tasks in everyday life. However, these\nabilities are primarily concentrated in high-resource languages, leaving\nlow-resource languages with weaker generative capabilities and relatively\nlimited knowledge. Enhancing the multilingual capabilities of LLMs is therefore\ncrucial for serving over 100 linguistic communities worldwide. An intuitive\napproach to enhance the multilingual capabilities would be to construct\ninstruction data for various languages, but constructing instruction data for\nover 100 languages is prohibitively costly. In this paper, we introduce BayLing\n2, which efficiently transfers generative capabilities and knowledge from\nhigh-resource languages to low-resource languages through language alignment.\nTo achieve this, we constructed a dataset of 3.2 million instructions,\ncomprising high-resource language instructions (Chinese and English) and\ncross-lingual instructions for 100+ languages and performed instruction tuning\nbased on the dataset to facilitate the capability transfer between languages.\nUsing Llama as the foundation model, we developed BayLing-2-7B, BayLing-2-13B,\nand BayLing-2-8B, and conducted a comprehensive evaluation of BayLing. For\nmultilingual translation across 100+ languages, BayLing shows superior\nperformance compared to open-source models of similar scale. For multilingual\nknowledge and understanding benchmarks, BayLing achieves significant\nimprovements across over 20 low-resource languages, demonstrating its\ncapability of effective knowledge transfer from high-resource to low-resource\nlanguages. Furthermore, results on English benchmarks indicate that BayLing\nmaintains high performance in highresource languages while enhancing the\nperformance in low-resource languages. Demo, homepage, code and models of\nBayLing are available.\n","authors":["Shaolei Zhang","Kehao Zhang","Qingkai Fang","Shoutao Guo","Yan Zhou","Xiaodong Liu","Yang Feng"],"pdf_url":"https://arxiv.org/pdf/2411.16300v3.pdf","comment":"BayLing 2's online demo: http://nlp.ict.ac.cn/bayling/demo. BayLing\n  2's code and models: https://github.com/ictnlp/BayLing"},{"id":"http://arxiv.org/abs/2312.00326v5","updated":"2024-12-19T15:07:38Z","published":"2023-12-01T03:44:54Z","title":"Agent-OM: Leveraging LLM Agents for Ontology Matching","summary":"  Ontology matching (OM) enables semantic interoperability between different\nontologies and resolves their conceptual heterogeneity by aligning related\nentities. OM systems currently have two prevailing design paradigms:\nconventional knowledge-based expert systems and newer machine learning-based\npredictive systems. While large language models (LLMs) and LLM agents have\nrevolutionised data engineering and have been applied creatively in many\ndomains, their potential for OM remains underexplored. This study introduces a\nnovel agent-powered LLM-based design paradigm for OM systems. With\nconsideration of several specific challenges in leveraging LLM agents for OM,\nwe propose a generic framework, namely Agent-OM (Agent for Ontology Matching),\nconsisting of two Siamese agents for retrieval and matching, with a set of\nsimple OM tools. Our framework is implemented in a proof-of-concept system.\nEvaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks\nover state-of-the-art OM systems show that our system can achieve results very\nclose to the long-standing best performance on simple OM tasks and can\nsignificantly improve the performance on complex and few-shot OM tasks.\n","authors":["Zhangcheng Qiang","Weiqing Wang","Kerry Taylor"],"pdf_url":"https://arxiv.org/pdf/2312.00326v5.pdf","comment":"19 pages, 13 figures, 4 tables"},{"id":"http://arxiv.org/abs/2412.14922v1","updated":"2024-12-19T15:00:18Z","published":"2024-12-19T15:00:18Z","title":"RobustFT: Robust Supervised Fine-tuning for Large Language Models under\n  Noisy Response","summary":"  Supervised fine-tuning (SFT) plays a crucial role in adapting large language\nmodels (LLMs) to specific domains or tasks. However, as demonstrated by\nempirical experiments, the collected data inevitably contains noise in\npractical applications, which poses significant challenges to model performance\non downstream tasks. Therefore, there is an urgent need for a noise-robust SFT\nframework to enhance model capabilities in downstream tasks. To address this\nchallenge, we introduce a robust SFT framework (RobustFT) that performs noise\ndetection and relabeling on downstream task data. For noise identification, our\napproach employs a multi-expert collaborative system with inference-enhanced\nmodels to achieve superior noise detection. In the denoising phase, we utilize\na context-enhanced strategy, which incorporates the most relevant and confident\nknowledge followed by careful assessment to generate reliable annotations.\nAdditionally, we introduce an effective data selection mechanism based on\nresponse entropy, ensuring only high-quality samples are retained for\nfine-tuning. Extensive experiments conducted on multiple LLMs across five\ndatasets demonstrate RobustFT's exceptional performance in noisy scenarios.\n","authors":["Junyu Luo","Xiao Luo","Kaize Ding","Jingyang Yuan","Zhiping Xiao","Ming Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.14922v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14905v1","updated":"2024-12-19T14:37:11Z","published":"2024-12-19T14:37:11Z","title":"Dehallucinating Parallel Context Extension for Retrieval-Augmented\n  Generation","summary":"  Large language models (LLMs) are susceptible to generating hallucinated\ninformation, despite the integration of retrieval-augmented generation (RAG).\nParallel context extension (PCE) is a line of research attempting to\neffectively integrating parallel (unordered) contexts, while it still suffers\nfrom hallucinations when adapted to RAG scenarios. In this paper, we propose\nDePaC (Dehallucinating Parallel Context Extension), which alleviates the\nhallucination problem with context-aware negative training and\ninformation-calibrated aggregation. DePaC is designed to alleviate two types of\nin-context hallucination: fact fabrication (i.e., LLMs present claims that are\nnot supported by the contexts) and fact omission (i.e., LLMs fail to present\nclaims that can be supported by the contexts). Specifically, (1) for fact\nfabrication, we apply the context-aware negative training that fine-tunes the\nLLMs with negative supervisions, thus explicitly guiding the LLMs to refuse to\nanswer when contexts are not related to questions; (2) for fact omission, we\npropose the information-calibrated aggregation which prioritizes context\nwindows with higher information increment from their contexts. The experimental\nresults on nine RAG tasks demonstrate that DePaC significantly alleviates the\ntwo types of hallucination and consistently achieves better performances on\nthese tasks.\n","authors":["Zexiong Ma","Shengnan An","Zeqi Lin","Yanzhen Zou","Jian-Guang Lou","Bing Xie"],"pdf_url":"https://arxiv.org/pdf/2412.14905v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14872v1","updated":"2024-12-19T14:11:15Z","published":"2024-12-19T14:11:15Z","title":"Why language models collapse when trained on recursively generated text","summary":"  Language models (LMs) have been widely used to generate text on the Internet.\nThe generated text is often collected into the training corpus of the next\ngenerations of LMs. Previous work has experimentally found that LMs collapse\nwhen trained on recursively generated text. This paper contributes to existing\nknowledge from two aspects. We present a theoretical proof of LM collapse. Our\nproof reveals the cause of LM collapse and proves that all auto-regressive LMs\nwill definitely collapse. We present a new finding: the performance of LMs\ngradually declines when trained on recursively generated text until they\nperform no better than a randomly initialized LM. The trained LMs produce large\namounts of repetitive text and perform poorly across a wide range of natural\nlanguage tasks. The above proof and new findings deepen our understanding of LM\ncollapse and offer valuable insights that may inspire new training techniques\nto mitigate this threat.\n","authors":["Lecheng Wang","Xianjie Shi","Ge Li","Jia Li","Yihong Dong","Xuanming Zhang","Wenpin Jiao","Hong Mei"],"pdf_url":"https://arxiv.org/pdf/2412.14872v1.pdf","comment":"28 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.14867v1","updated":"2024-12-19T14:03:22Z","published":"2024-12-19T14:03:22Z","title":"Graph-Convolutional Networks: Named Entity Recognition and Large\n  Language Model Embedding in Document Clustering","summary":"  Recent advances in machine learning, particularly Large Language Models\n(LLMs) such as BERT and GPT, provide rich contextual embeddings that improve\ntext representation. However, current document clustering approaches often\nignore the deeper relationships between named entities (NEs) and the potential\nof LLM embeddings. This paper proposes a novel approach that integrates Named\nEntity Recognition (NER) and LLM embeddings within a graph-based framework for\ndocument clustering. The method builds a graph with nodes representing\ndocuments and edges weighted by named entity similarity, optimized using a\ngraph-convolutional network (GCN). This ensures a more effective grouping of\nsemantically related documents. Experimental results indicate that our approach\noutperforms conventional co-occurrence-based methods in clustering, notably for\ndocuments rich in named entities.\n","authors":["Imed Keraghel","Mohamed Nadif"],"pdf_url":"https://arxiv.org/pdf/2412.14867v1.pdf","comment":"11 pages, 4 figures"},{"id":"http://arxiv.org/abs/2411.06228v2","updated":"2024-12-19T13:57:05Z","published":"2024-11-09T16:17:14Z","title":"An $\\mathbf{L^*}$ Algorithm for Deterministic Weighted Regular Languages","summary":"  Extracting finite state automata (FSAs) from black-box models offers a\npowerful approach to gaining interpretable insights into complex model\nbehaviors. To support this pursuit, we present a weighted variant of Angluin's\n(1987) $\\mathbf{L^*}$ algorithm for learning FSAs. We stay faithful to the\noriginal algorithm, devising a way to exactly learn deterministic weighted FSAs\nwhose weights support division. Furthermore, we formulate the learning process\nin a manner that highlights the connection with FSA minimization, showing how\n$\\mathbf{L^*}$ directly learns a minimal automaton for the target language.\n","authors":["Clemente Pasti","Talu Karagöz","Anej Svete","Franz Nowak","Reda Boumasmoud","Ryan Cotterell"],"pdf_url":"https://arxiv.org/pdf/2411.06228v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14860v1","updated":"2024-12-19T13:55:48Z","published":"2024-12-19T13:55:48Z","title":"Think&Cite: Improving Attributed Text Generation with Self-Guided Tree\n  Search and Progress Reward Modeling","summary":"  Despite their outstanding capabilities, large language models (LLMs) are\nprone to hallucination and producing factually incorrect information. This\nchallenge has spurred efforts in attributed text generation, which prompts LLMs\nto generate content with supporting evidence. In this paper, we propose a novel\nframework, called Think&Cite, and formulate attributed text generation as a\nmulti-step reasoning problem integrated with search. Specifically, we propose\nSelf-Guided Monte Carlo Tree Search (SG-MCTS), which capitalizes on the\nself-reflection capability of LLMs to reflect on the intermediate states of\nMCTS for guiding the tree expansion process. To provide reliable and\ncomprehensive feedback, we introduce Progress Reward Models to measure the\nprogress of tree search from the root to the current state from two aspects,\ni.e., generation and attribution progress. We conduct extensive experiments on\nthree datasets and the results show that our approach significantly outperforms\nbaseline approaches.\n","authors":["Junyi Li","Hwee Tou Ng"],"pdf_url":"https://arxiv.org/pdf/2412.14860v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14849v1","updated":"2024-12-19T13:39:47Z","published":"2024-12-19T13:39:47Z","title":"DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for\n  Few-Shot Aspect-Based Sentiment Analysis","summary":"  Recently developed large language models (LLMs) have presented promising new\navenues to address data scarcity in low-resource scenarios. In few-shot\naspect-based sentiment analysis (ABSA), previous efforts have explored data\naugmentation techniques, which prompt LLMs to generate new samples by modifying\nexisting ones. However, these methods fail to produce adequately diverse data,\nimpairing their effectiveness. Besides, some studies apply in-context learning\nfor ABSA by using specific instructions and a few selected examples as prompts.\nThough promising, LLMs often yield labels that deviate from task requirements.\nTo overcome these limitations, we propose DS$^2$-ABSA, a dual-stream data\nsynthesis framework targeted for few-shot ABSA. It leverages LLMs to synthesize\ndata from two complementary perspectives: \\textit{key-point-driven} and\n\\textit{instance-driven}, which effectively generate diverse and high-quality\nABSA samples in low-resource settings. Furthermore, a \\textit{label refinement}\nmodule is integrated to improve the synthetic labels. Extensive experiments\ndemonstrate that DS$^2$-ABSA significantly outperforms previous few-shot ABSA\nsolutions and other LLM-oriented data generation methods.\n","authors":["Hongling Xu","Yice Zhang","Qianlong Wang","Ruifeng Xu"],"pdf_url":"https://arxiv.org/pdf/2412.14849v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14847v1","updated":"2024-12-19T13:39:24Z","published":"2024-12-19T13:39:24Z","title":"A Survey of RWKV","summary":"  The Receptance Weighted Key Value (RWKV) model offers a novel alternative to\nthe Transformer architecture, merging the benefits of recurrent and\nattention-based systems. Unlike conventional Transformers, which depend heavily\non self-attention, RWKV adeptly captures long-range dependencies with minimal\ncomputational demands. By utilizing a recurrent framework, RWKV addresses some\ncomputational inefficiencies found in Transformers, particularly in tasks with\nlong sequences. RWKV has recently drawn considerable attention for its robust\nperformance across multiple domains. Despite its growing popularity, no\nsystematic review of the RWKV model exists. This paper seeks to fill this gap\nas the first comprehensive review of the RWKV architecture, its core\nprinciples, and its varied applications, such as natural language generation,\nnatural language understanding, and computer vision. We assess how RWKV\ncompares to traditional Transformer models, highlighting its capability to\nmanage long sequences efficiently and lower computational costs. Furthermore,\nwe explore the challenges RWKV encounters and propose potential directions for\nfuture research and advancement. We consistently maintain the related\nopen-source materials at: https://github.com/MLGroupJLU/RWKV-Survey.\n","authors":["Zhiyuan Li","Tingyu Xia","Yi Chang","Yuan Wu"],"pdf_url":"https://arxiv.org/pdf/2412.14847v1.pdf","comment":"18 pages"},{"id":"http://arxiv.org/abs/2412.14843v1","updated":"2024-12-19T13:36:18Z","published":"2024-12-19T13:36:18Z","title":"Mapping and Influencing the Political Ideology of Large Language Models\n  using Synthetic Personas","summary":"  The analysis of political biases in large language models (LLMs) has\nprimarily examined these systems as single entities with fixed viewpoints.\nWhile various methods exist for measuring such biases, the impact of\npersona-based prompting on LLMs' political orientation remains unexplored. In\nthis work we leverage PersonaHub, a collection of synthetic persona\ndescriptions, to map the political distribution of persona-based prompted LLMs\nusing the Political Compass Test (PCT). We then examine whether these initial\ncompass distributions can be manipulated through explicit ideological prompting\ntowards diametrically opposed political orientations: right-authoritarian and\nleft-libertarian. Our experiments reveal that synthetic personas predominantly\ncluster in the left-libertarian quadrant, with models demonstrating varying\ndegrees of responsiveness when prompted with explicit ideological descriptors.\nWhile all models demonstrate significant shifts towards right-authoritarian\npositions, they exhibit more limited shifts towards left-libertarian positions,\nsuggesting an asymmetric response to ideological manipulation that may reflect\ninherent biases in model training.\n","authors":["Pietro Bernardelle","Leon Fröhling","Stefano Civelli","Riccardo Lunardi","Kevin Roiter","Gianluca Demartini"],"pdf_url":"https://arxiv.org/pdf/2412.14843v1.pdf","comment":"4 pages, 2 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.14838v1","updated":"2024-12-19T13:28:42Z","published":"2024-12-19T13:28:42Z","title":"DynamicKV: Task-Aware Adaptive KV Cache Compression for Long Context\n  LLMs","summary":"  Efficient KV cache management in LLMs is crucial for long-context tasks like\nRAG and summarization. Existing KV cache compression methods enforce a fixed\npattern, neglecting task-specific characteristics and reducing the retention of\nessential information. However, we observe distinct activation patterns across\nlayers in various tasks, highlighting the need for adaptive strategies tailored\nto each task's unique demands. Based on this insight, we propose DynamicKV, a\nmethod that dynamically optimizes token retention by adjusting the number of\ntokens retained at each layer to adapt to the specific task. DynamicKV\nestablishes global and per-layer maximum KV cache budgets, temporarily\nretaining the maximum budget for the current layer, and periodically updating\nthe KV cache sizes of all preceding layers during inference. Our method retains\nonly 1.7% of the KV cache size while achieving ~85% of the Full KV cache\nperformance on LongBench. Notably, even under extreme compression (0.9%),\nDynamicKV surpasses state-of-the-art (SOTA) methods by 11% in the\nNeedle-in-a-Haystack test using Mistral-7B-Instruct-v0.2. The code will be\nreleased.\n","authors":["Xiabin Zhou","Wenbin Wang","Minyan Zeng","Jiaxian Guo","Xuebo Liu","Li Shen","Min Zhang","Liang Ding"],"pdf_url":"https://arxiv.org/pdf/2412.14838v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14835v1","updated":"2024-12-19T13:25:39Z","published":"2024-12-19T13:25:39Z","title":"Progressive Multimodal Reasoning via Active Retrieval","summary":"  Multi-step multimodal reasoning tasks pose significant challenges for\nmultimodal large language models (MLLMs), and finding effective ways to enhance\ntheir performance in such scenarios remains an unresolved issue. In this paper,\nwe propose AR-MCTS, a universal framework designed to progressively improve the\nreasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo\nTree Search (MCTS). Our approach begins with the development of a unified\nretrieval module that retrieves key supporting insights for solving complex\nreasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in\nautomated multimodal reasoning verification, we employ the MCTS algorithm\ncombined with an active retrieval mechanism, which enables the automatic\ngeneration of step-wise annotations. This strategy dynamically retrieves key\ninsights for each reasoning step, moving beyond traditional beam search\nsampling to improve the diversity and reliability of the reasoning space.\nAdditionally, we introduce a process reward model that aligns progressively to\nsupport the automatic verification of multimodal reasoning tasks. Experimental\nresults across three complex multimodal reasoning benchmarks confirm the\neffectiveness of the AR-MCTS framework in enhancing the performance of various\nmultimodal models. Further analysis demonstrates that AR-MCTS can optimize\nsampling diversity and accuracy, yielding reliable multimodal reasoning.\n","authors":["Guanting Dong","Chenghao Zhang","Mengjie Deng","Yutao Zhu","Zhicheng Dou","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2412.14835v1.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2412.14829v1","updated":"2024-12-19T13:19:19Z","published":"2024-12-19T13:19:19Z","title":"Mention Attention for Pronoun Translation","summary":"  Most pronouns are referring expressions, computers need to resolve what do\nthe pronouns refer to, and there are divergences on pronoun usage across\nlanguages. Thus, dealing with these divergences and translating pronouns is a\nchallenge in machine translation. Mentions are referring candidates of pronouns\nand have closer relations with pronouns compared to general tokens. We assume\nthat extracting additional mention features can help pronoun translation.\nTherefore, we introduce an additional mention attention module in the decoder\nto pay extra attention to source mentions but not non-mention tokens. Our\nmention attention module not only extracts features from source mentions, but\nalso considers target-side context which benefits pronoun translation. In\naddition, we also introduce two mention classifiers to train models to\nrecognize mentions, whose outputs guide the mention attention. We conduct\nexperiments on the WMT17 English-German translation task, and evaluate our\nmodels on general translation and pronoun translation, using BLEU, APT, and\ncontrastive evaluation metrics. Our proposed model outperforms the baseline\nTransformer model in terms of APT and BLEU scores, this confirms our hypothesis\nthat we can improve pronoun translation by paying additional attention to\nsource mentions, and shows that our introduced additional modules do not have\nnegative effect on the general translation quality.\n","authors":["Gongbo Tang","Christian Hardmeier"],"pdf_url":"https://arxiv.org/pdf/2412.14829v1.pdf","comment":"camera-ready version of the paper accepted by JCRAI-23 conference, in\n  ACL format"},{"id":"http://arxiv.org/abs/2408.17072v2","updated":"2024-12-19T13:16:40Z","published":"2024-08-30T07:57:30Z","title":"MaFeRw: Query Rewriting with Multi-Aspect Feedbacks for\n  Retrieval-Augmented Large Language Models","summary":"  In a real-world RAG system, the current query often involves spoken ellipses\nand ambiguous references from dialogue contexts, necessitating query rewriting\nto better describe user's information needs. However, traditional context-based\nrewriting has minimal enhancement on downstream generation tasks due to the\nlengthy process from query rewriting to response generation. Some researchers\ntry to utilize reinforcement learning with generation feedback to assist the\nrewriter, but these sparse rewards provide little guidance in most cases,\nleading to unstable training and generation results. We find that user's needs\nare also reflected in the gold document, retrieved documents and ground truth.\nTherefore, by feeding back these multi-aspect dense rewards to query rewriting,\nmore stable and satisfactory responses can be achieved. In this paper, we\npropose a novel query rewriting method MaFeRw, which improves RAG performance\nby integrating multi-aspect feedback from both the retrieval process and\ngenerated results. Specifically, we first use manual data to train a T5 model\nfor the rewriter initialization. Next, we design three metrics as reinforcement\nlearning feedback: the similarity between the rewritten query and the gold\ndocument, the ranking metrics, and ROUGE between the generation and the ground\ntruth. Inspired by RLAIF, we train three kinds of reward models for the above\nmetrics to achieve more efficient training. Finally, we combine the scores of\nthese reward models as feedback, and use PPO algorithm to explore the optimal\nquery rewriting strategy. Experimental results on two conversational RAG\ndatasets demonstrate that MaFeRw achieves superior generation metrics and more\nstable training compared to baselines.\n","authors":["Yujing Wang","Hainan Zhang","Liang Pang","Binghui Guo","Hongwei Zheng","Zhiming Zheng"],"pdf_url":"https://arxiv.org/pdf/2408.17072v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14809v1","updated":"2024-12-19T12:57:47Z","published":"2024-12-19T12:57:47Z","title":"ResoFilter: Rine-grained Synthetic Data Filtering for Large Language\n  Models through Data-Parameter Resonance Analysis","summary":"  Large language models (LLMs) have shown remarkable effectiveness across\nvarious domains, with data augmentation methods utilizing GPT for synthetic\ndata generation becoming prevalent. However, the quality and utility of\naugmented data remain questionable, and current methods lack clear metrics for\nevaluating data characteristics. To address these challenges, we propose\nResoFilter, a novel method that integrates models, data, and tasks to refine\ndatasets. ResoFilter leverages the fine-tuning process to obtain Data-Parameter\nfeatures for data selection, offering improved interpretability by representing\ndata characteristics through model weights. Our experiments demonstrate that\nResoFilter achieves comparable results to full-scale fine-tuning using only\nhalf the data in mathematical tasks and exhibits strong generalization across\ndifferent models and domains. This method provides valuable insights for\nconstructing synthetic datasets and evaluating high-quality data, offering a\npromising solution for enhancing data augmentation techniques and improving\ntraining dataset quality for LLMs. For reproducibility, we will release our\ncode and data upon acceptance.\n","authors":["Zeao Tu","Xiangdi Meng","Yu He","Zihan Yao","Tianyu Qi","Jun Liu","Ming Li"],"pdf_url":"https://arxiv.org/pdf/2412.14809v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2412.14780v1","updated":"2024-12-19T12:06:24Z","published":"2024-12-19T12:06:24Z","title":"Disentangling Reasoning Tokens and Boilerplate Tokens For Language Model\n  Fine-tuning","summary":"  When using agent-task datasets to enhance agent capabilities for Large\nLanguage Models (LLMs), current methodologies often treat all tokens within a\nsample equally. However, we argue that tokens serving different roles -\nspecifically, reasoning tokens versus boilerplate tokens (e.g., those governing\noutput format) - differ significantly in importance and learning complexity,\nnecessitating their disentanglement and distinct treatment. To address this, we\npropose a novel Shuffle-Aware Discriminator (SHAD) for adaptive token\ndiscrimination. SHAD classifies tokens by exploiting predictability differences\nobserved after shuffling input-output combinations across samples: boilerplate\ntokens, due to their repetitive nature among samples, maintain predictability,\nwhereas reasoning tokens do not. Using SHAD, we propose the\nReasoning-highlighted Fine-Tuning (RFT) method, which adaptively emphasizes\nreasoning tokens during fine-tuning, yielding notable performance gains over\ncommon Supervised Fine-Tuning (SFT).\n","authors":["Ziang Ye","Zhenru Zhang","Yang Zhang","Jianxin Ma","Junyang Lin","Fuli Feng"],"pdf_url":"https://arxiv.org/pdf/2412.14780v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14771v1","updated":"2024-12-19T11:55:51Z","published":"2024-12-19T11:55:51Z","title":"ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in\n  Palestine","summary":"  Large Language Models (LLMs) have demonstrated remarkable potential in\ndiverse domains, yet their application in the legal sector, particularly in\nlow-resource contexts, remains limited. This study addresses the challenges of\nadapting LLMs to the Palestinian legal domain, where political instability,\nfragmented legal frameworks, and limited AI resources hinder effective\nmachine-learning applications. We present a fine-tuned model based on a\nquantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set\nderived from Palestinian legal texts. Using smaller-scale models and\nstrategically generated question-answer pairs, we achieve a cost-effective,\nlocally sustainable solution that provides accurate and contextually relevant\nlegal guidance. Our experiments demonstrate promising performance on various\nquery types, ranging from yes/no questions and narrative explanations to\ncomplex legal differentiations, while highlighting areas for improvement, such\nas handling calculation-based inquiries and structured list formatting. This\nwork provides a pathway for the deployment of AI-driven legal assistance tools\ntailored to the needs of resource-constrained environments.\n","authors":["Rabee Qasem","Mohannad Hendi","Banan Tantour"],"pdf_url":"https://arxiv.org/pdf/2412.14771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14769v1","updated":"2024-12-19T11:51:57Z","published":"2024-12-19T11:51:57Z","title":"PsyDraw: A Multi-Agent Multimodal System for Mental Health Screening in\n  Left-Behind Children","summary":"  Left-behind children (LBCs), numbering over 66 million in China, face severe\nmental health challenges due to parental migration for work. Early screening\nand identification of at-risk LBCs is crucial, yet challenging due to the\nsevere shortage of mental health professionals, especially in rural areas.\nWhile the House-Tree-Person (HTP) test shows higher child participation rates,\nits requirement for expert interpretation limits its application in\nresource-scarce regions. To address this challenge, we propose PsyDraw, a\nmulti-agent system based on Multimodal Large Language Models that assists\nmental health professionals in analyzing HTP drawings. The system employs\nspecialized agents for feature extraction and psychological interpretation,\noperating in two stages: comprehensive feature analysis and professional report\ngeneration. Evaluation of HTP drawings from 290 primary school students reveals\nthat 71.03% of the analyzes achieved High Consistency with professional\nevaluations, 26.21% Moderate Consistency and only 2.41% Low Consistency. The\nsystem identified 31.03% of cases requiring professional attention,\ndemonstrating its effectiveness as a preliminary screening tool. Currently\ndeployed in pilot schools, \\method shows promise in supporting mental health\nprofessionals, particularly in resource-limited areas, while maintaining high\nprofessional standards in psychological assessment.\n","authors":["Yiqun Zhang","Xiaocui Yang","Xiaobai Li","Siyuan Yu","Yi Luan","Shi Feng","Daling Wang","Yifei Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.14769v1.pdf","comment":"preprint"},{"id":"http://arxiv.org/abs/2412.14751v1","updated":"2024-12-19T11:30:07Z","published":"2024-12-19T11:30:07Z","title":"Query pipeline optimization for cancer patient question answering\n  systems","summary":"  Retrieval-augmented generation (RAG) mitigates hallucination in Large\nLanguage Models (LLMs) by using query pipelines to retrieve relevant external\ninformation and grounding responses in retrieved knowledge. However, query\npipeline optimization for cancer patient question-answering (CPQA) systems\nrequires separately optimizing multiple components with domain-specific\nconsiderations. We propose a novel three-aspect optimization approach for the\nRAG query pipeline in CPQA systems, utilizing public biomedical databases like\nPubMed and PubMed Central. Our optimization includes: (1) document retrieval,\nutilizing a comparative analysis of NCBI resources and introducing Hybrid\nSemantic Real-time Document Retrieval (HSRDR); (2) passage retrieval,\nidentifying optimal pairings of dense retrievers and rerankers; and (3)\nsemantic representation, introducing Semantic Enhanced Overlap Segmentation\n(SEOS) for improved contextual understanding. On a custom-developed dataset\ntailored for cancer-related inquiries, our optimized RAG approach improved the\nanswer accuracy of Claude-3-haiku by 5.24% over chain-of-thought prompting and\nabout 3% over a naive RAG setup. This study highlights the importance of\ndomain-specific query optimization in realizing the full potential of RAG and\nprovides a robust framework for building more accurate and reliable CPQA\nsystems, advancing the development of RAG-based biomedical systems.\n","authors":["Maolin He","Rena Gao","Mike Conway","Brian E. Chapman"],"pdf_url":"https://arxiv.org/pdf/2412.14751v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14737v1","updated":"2024-12-19T11:10:36Z","published":"2024-12-19T11:10:36Z","title":"On Verbalized Confidence Scores for LLMs","summary":"  The rise of large language models (LLMs) and their tight integration into our\ndaily life make it essential to dedicate efforts towards their trustworthiness.\nUncertainty quantification for LLMs can establish more human trust into their\nresponses, but also allows LLM agents to make more informed decisions based on\neach other's uncertainty. To estimate the uncertainty in a response, internal\ntoken logits, task-specific proxy models, or sampling of multiple responses are\ncommonly used. This work focuses on asking the LLM itself to verbalize its\nuncertainty with a confidence score as part of its output tokens, which is a\npromising way for prompt- and model-agnostic uncertainty quantification with\nlow overhead. Using an extensive benchmark, we assess the reliability of\nverbalized confidence scores with respect to different datasets, models, and\nprompt methods. Our results reveal that the reliability of these scores\nstrongly depends on how the model is asked, but also that it is possible to\nextract well-calibrated confidence scores with certain prompt methods. We argue\nthat verbalized confidence scores can become a simple but effective and\nversatile uncertainty quantification method in the future. Our code is\navailable at https://github.com/danielyxyang/llm-verbalized-uq .\n","authors":["Daniel Yang","Yao-Hung Hubert Tsai","Makoto Yamada"],"pdf_url":"https://arxiv.org/pdf/2412.14737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.18403v2","updated":"2024-12-19T11:07:09Z","published":"2024-06-26T14:56:13Z","title":"LLMs instead of Human Judges? A Large Scale Empirical Study across 20\n  NLP Evaluation Tasks","summary":"  There is an increasing trend towards evaluating NLP models with LLMs instead\nof human judgments, raising questions about the validity of these evaluations,\nas well as their reproducibility in the case of proprietary models. We provide\nJUDGE-BENCH, an extensible collection of 20 NLP datasets with human annotations\ncovering a broad range of evaluated properties and types of data, and\ncomprehensively evaluate 11 current LLMs, covering both open-weight and\nproprietary models, for their ability to replicate the annotations. Our\nevaluations show substantial variance across models and datasets. Models are\nreliable evaluators on some tasks, but overall display substantial variability\ndepending on the property being evaluated, the expertise level of the human\njudges, and whether the language is human or model-generated. We conclude that\nLLMs should be carefully validated against human judgments before being used as\nevaluators.\n","authors":["Anna Bavaresco","Raffaella Bernardi","Leonardo Bertolazzi","Desmond Elliott","Raquel Fernández","Albert Gatt","Esam Ghaleb","Mario Giulianelli","Michael Hanna","Alexander Koller","André F. T. Martins","Philipp Mondorf","Vera Neplenbroek","Sandro Pezzelle","Barbara Plank","David Schlangen","Alessandro Suglia","Aditya K Surikuchi","Ece Takmaz","Alberto Testoni"],"pdf_url":"https://arxiv.org/pdf/2406.18403v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11242v2","updated":"2024-12-19T10:33:13Z","published":"2024-12-15T16:47:16Z","title":"TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs","summary":"  Specializing large language models (LLMs) for local deployment in\ndomain-specific use cases is necessary for strong performance while meeting\nlatency and privacy constraints. However, conventional task-specific adaptation\napproaches do not show simultaneous memory saving and inference speedup at\ndeployment time. Practical compression techniques like quantization and pruning\nrequire dedicated hardware or kernel support to achieve measured inference\nspeedup. We develop TrimLLM based on the layer-wise specialization phenomenon\nwe empirically observed and verified on contemporary LLMs. TrimLLM reduces the\ndepth of LLMs via progressive layer dropping. We show it retains LLMs' capacity\nin specific domains and achieves inference speedup irrespective of hardware and\ndeep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for\ninference; models adapted on medical, legal, and financial datasets all\ndemonstrate $2.1-5.7\\times$ inference speedup on consumer GPUs and up to\n$3.1\\times$ speedup on A100 when compared to state-of-the-art model compression\nalgorithms, with no loss in accuracy at 50$\\sim$60\\% model compression ratio.\n","authors":["Lanxiang Hu","Tajana Rosing","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.11242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07675v3","updated":"2024-12-19T10:11:42Z","published":"2024-12-10T17:02:58Z","title":"RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text\n  Rewriting","summary":"  Despite the widespread use of LLMs due to their superior performance in\nvarious tasks, their high computational costs often lead potential users to opt\nfor the pretraining-finetuning pipeline. However, biases prevalent in manually\nconstructed datasets can introduce spurious correlations between tokens and\nlabels, creating so-called shortcuts and hindering the generalizability of\nfine-tuned models. Existing debiasing methods often rely on prior knowledge of\nspecific dataset biases, which is challenging to acquire a priori. We propose\nRAZOR (Rewriting And Zero-bias Optimization Refinement), a novel, unsupervised,\nand data-focused debiasing approach based on text rewriting for shortcut\nmitigation. RAZOR leverages LLMs to iteratively rewrite potentially biased text\nsegments by replacing them with heuristically selected alternatives in a\nshortcut space defined by token statistics and positional information. This\nprocess aims to align surface-level text features more closely with diverse\nlabel distributions, thereby promoting the learning of genuine linguistic\npatterns. Compared with unsupervised SoTA models, RAZOR improves by 3.5% on the\nFEVER and 6.5% on MNLI and SNLI datasets according to the F1 score.\nAdditionally, RAZOR effectively mitigates specific known biases, reducing\nbias-related terms by x2 without requiring prior bias information, a result\nthat is on par with SoTA models that leverage prior information. Our work\nprioritizes data manipulation over architectural modifications, emphasizing the\npivotal role of data quality in enhancing model performance and fairness. This\nresearch contributes to developing more robust evaluation benchmarks for\ndebiasing methods by incorporating metrics for bias reduction and overall model\nefficacy.\n","authors":["Shuo Yang","Bardh Prenkaj","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2412.07675v3.pdf","comment":"Shuo and Bardh contributed equally. Accepted to AAAI'25, Paper #17117"},{"id":"http://arxiv.org/abs/2412.14689v1","updated":"2024-12-19T09:43:39Z","published":"2024-12-19T09:43:39Z","title":"How to Synthesize Text Data without Model Collapse?","summary":"  Model collapse in synthetic data indicates that iterative training on\nself-generated data leads to a gradual decline in performance. With the\nproliferation of AI models, synthetic data will fundamentally reshape the web\ndata ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend\nof synthetic and human-produced data. In this paper, we focus on two questions:\nwhat is the impact of synthetic data on language model training, and how to\nsynthesize data without model collapse? We first pre-train language models\nacross different proportions of synthetic data, revealing a negative\ncorrelation between the proportion of synthetic data and model performance. We\nfurther conduct statistical analysis on synthetic data to uncover\ndistributional shift phenomenon and over-concentration of n-gram features.\nInspired by the above findings, we propose token editing on human-produced data\nto obtain semi-synthetic data. As a proof of concept, we theoretically\ndemonstrate that token-level editing can prevent model collapse, as the test\nerror is constrained by a finite upper bound. We conduct extensive experiments\non pre-training from scratch, continual pre-training, and supervised\nfine-tuning. The results validate our theoretical proof that token-level\nediting improves data quality and enhances model performance.\n","authors":["Xuekai Zhu","Daixuan Cheng","Hengli Li","Kaiyan Zhang","Ermo Hua","Xingtai Lv","Ning Ding","Zhouhan Lin","Zilong Zheng","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.14689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14686v1","updated":"2024-12-19T09:40:17Z","published":"2024-12-19T09:40:17Z","title":"Each Fake News is Fake in its Own Way: An Attribution Multi-Granularity\n  Benchmark for Multimodal Fake News Detection","summary":"  Social platforms, while facilitating access to information, have also become\nsaturated with a plethora of fake news, resulting in negative consequences.\nAutomatic multimodal fake news detection is a worthwhile pursuit. Existing\nmultimodal fake news datasets only provide binary labels of real or fake.\nHowever, real news is alike, while each fake news is fake in its own way. These\ndatasets fail to reflect the mixed nature of various types of multimodal fake\nnews. To bridge the gap, we construct an attributing multi-granularity\nmultimodal fake news detection dataset \\amg, revealing the inherent fake\npattern. Furthermore, we propose a multi-granularity clue alignment model \\our\nto achieve multimodal fake news detection and attribution. Experimental results\ndemonstrate that \\amg is a challenging dataset, and its attribution setting\nopens up new avenues for future research.\n","authors":["Hao Guo","Zihan Ma","Zhi Zeng","Minnan Luo","Weixin Zeng","Jiuyang Tang","Xiang Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.14686v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14675v1","updated":"2024-12-19T09:29:08Z","published":"2024-12-19T09:29:08Z","title":"LLMs as mediators: Can they diagnose conflicts accurately?","summary":"  Prior research indicates that to be able to mediate conflict, observers of\ndisagreements between parties must be able to reliably distinguish the sources\nof their disagreement as stemming from differences in beliefs about what is\ntrue (causality) vs. differences in what they value (morality). In this paper,\nwe test if OpenAI's Large Language Models GPT 3.5 and GPT 4 can perform this\ntask and whether one or other type of disagreement proves particularly\nchallenging for LLM's to diagnose. We replicate study 1 in Ko\\c{c}ak et al.\n(2003), which employes a vignette design, with OpenAI's GPT 3.5 and GPT 4. We\nfind that both LLMs have similar semantic understanding of the distinction\nbetween causal and moral codes as humans and can reliably distinguish between\nthem. When asked to diagnose the source of disagreement in a conversation, both\nLLMs, compared to humans, exhibit a tendency to overestimate the extent of\ncausal disagreement and underestimate the extent of moral disagreement in the\nmoral misalignment condition. This tendency is especially pronounced for GPT 4\nwhen using a proximate scale that relies on concrete language specific to an\nissue. GPT 3.5 does not perform as well as GPT4 or humans when using either the\nproximate or the distal scale. The study provides a first test of the potential\nfor using LLMs to mediate conflict by diagnosing the root of disagreements in\ncausal and evaluative codes.\n","authors":["Özgecan Koçak","Phanish Puranam","Afşar Yegin"],"pdf_url":"https://arxiv.org/pdf/2412.14675v1.pdf","comment":"27 pages, 2 appendices, 21 tables (incl appendices)"},{"id":"http://arxiv.org/abs/2412.06926v3","updated":"2024-12-19T09:24:39Z","published":"2024-12-09T19:11:54Z","title":"When Every Token Counts: Optimal Segmentation for Low-Resource Language\n  Models","summary":"  Traditional greedy tokenization methods have been a critical step in Natural\nLanguage Processing (NLP), influencing how text is converted into tokens and\ndirectly impacting model performance. While subword tokenizers like Byte-Pair\nEncoding (BPE) are widely used, questions remain about their optimality across\nmodel scales and languages. In this work, we demonstrate through extensive\nexperiments that an optimal BPE configuration significantly reduces token count\ncompared to greedy segmentation, yielding improvements in token-saving\npercentages and performance benefits, particularly for smaller models. We\nevaluate tokenization performance across various intrinsic and extrinsic tasks,\nincluding generation and classification. Our findings suggest that\ncompression-optimized tokenization strategies could provide substantial\nadvantages for multilingual and low-resource language applications,\nhighlighting a promising direction for further research and inclusive NLP.\n","authors":["Bharath Raj S","Garvit Suri","Vikrant Dewangan","Raghav Sonavane"],"pdf_url":"https://arxiv.org/pdf/2412.06926v3.pdf","comment":"LoResLM @ COLING 2025"},{"id":"http://arxiv.org/abs/2412.14670v1","updated":"2024-12-19T09:21:39Z","published":"2024-12-19T09:21:39Z","title":"Analysis and Visualization of Linguistic Structures in Large Language\n  Models: Neural Representations of Verb-Particle Constructions in BERT","summary":"  This study investigates the internal representations of verb-particle\ncombinations within transformer-based large language models (LLMs),\nspecifically examining how these models capture lexical and syntactic nuances\nat different neural network layers. Employing the BERT architecture, we analyse\nthe representational efficacy of its layers for various verb-particle\nconstructions such as 'agree on', 'come back', and 'give up'. Our methodology\nincludes a detailed dataset preparation from the British National Corpus,\nfollowed by extensive model training and output analysis through techniques\nlike multi-dimensional scaling (MDS) and generalized discrimination value (GDV)\ncalculations. Results show that BERT's middle layers most effectively capture\nsyntactic structures, with significant variability in representational accuracy\nacross different verb categories. These findings challenge the conventional\nuniformity assumed in neural network processing of linguistic elements and\nsuggest a complex interplay between network architecture and linguistic\nrepresentation. Our research contributes to a better understanding of how deep\nlearning models comprehend and process language, offering insights into the\npotential and limitations of current neural approaches to linguistic analysis.\nThis study not only advances our knowledge in computational linguistics but\nalso prompts further research into optimizing neural architectures for enhanced\nlinguistic precision.\n","authors":["Hassane Kissane","Achim Schilling","Patrick Krauss"],"pdf_url":"https://arxiv.org/pdf/2412.14670v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14660v1","updated":"2024-12-19T09:10:07Z","published":"2024-12-19T09:10:07Z","title":"Unveiling Uncertainty: A Deep Dive into Calibration and Performance of\n  Multimodal Large Language Models","summary":"  Multimodal large language models (MLLMs) combine visual and textual data for\ntasks such as image captioning and visual question answering. Proper\nuncertainty calibration is crucial, yet challenging, for reliable use in areas\nlike healthcare and autonomous driving. This paper investigates representative\nMLLMs, focusing on their calibration across various scenarios, including before\nand after visual fine-tuning, as well as before and after multimodal training\nof the base LLMs. We observed miscalibration in their performance, and at the\nsame time, no significant differences in calibration across these scenarios. We\nalso highlight how uncertainty differs between text and images and how their\nintegration affects overall uncertainty. To better understand MLLMs'\nmiscalibration and their ability to self-assess uncertainty, we construct the\nIDK (I don't know) dataset, which is key to evaluating how they handle\nunknowns. Our findings reveal that MLLMs tend to give answers rather than admit\nuncertainty, but this self-assessment improves with proper prompt adjustments.\nFinally, to calibrate MLLMs and enhance model reliability, we propose\ntechniques such as temperature scaling and iterative prompt optimization. Our\nresults provide insights into improving MLLMs for effective and responsible\ndeployment in multimodal applications. Code and IDK dataset:\n\\href{https://github.com/hfutml/Calibration-MLLM}{https://github.com/hfutml/Calibration-MLLM}.\n","authors":["Zijun Chen","Wenbo Hu","Guande He","Zhijie Deng","Zheng Zhang","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2412.14660v1.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.14656v1","updated":"2024-12-19T09:07:38Z","published":"2024-12-19T09:07:38Z","title":"Length Controlled Generation for Black-box LLMs","summary":"  Large language models (LLMs) have demonstrated impressive instruction\nfollowing capabilities, while still struggling to accurately manage the length\nof the generated text, which is a fundamental requirement in many real-world\napplications. Existing length control methods involve fine-tuning the\nparameters of LLMs, which is inefficient and suboptimal for practical use. In\nthis paper, we propose a novel iterative sampling framework for text length\ncontrol, integrating the Metropolis-Hastings algorithm with an importance\nsampling acceleration strategy. This framework efficiently and reliably\nregulates LLMs to generate length-constrained text without modifying the\nunderlying parameters, thereby preserving the original capabilities of LLMs.\nExperimental results demonstrate that our framework achieves almost 100\\%\nsuccess rates of length control on Llama3.1 for tasks such as length-controlled\nabstractive summarization and length-constrained instruction following, with\nminimal additional computational overhead. This also highlights the significant\npotential of our method for precise length control across a broader range of\napplications, without compromising the versatility of LLMs.\n","authors":["Yuxuan Gu","Wenjie Wang","Xiaocheng Feng","Weihong Zhong","Kun Zhu","Lei Huang","Tat-Seng Chua","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2412.14656v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.14642v1","updated":"2024-12-19T08:51:16Z","published":"2024-12-19T08:51:16Z","title":"TOMG-Bench: Evaluating LLMs on Text-based Open Molecule Generation","summary":"  In this paper, we propose Text-based Open Molecule Generation Benchmark\n(TOMG-Bench), the first benchmark to evaluate the open-domain molecule\ngeneration capability of LLMs. TOMG-Bench encompasses a dataset of three major\ntasks: molecule editing (MolEdit), molecule optimization (MolOpt), and\ncustomized molecule generation (MolCustom). Each task further contains three\nsubtasks, with each subtask comprising 5,000 test samples. Given the inherent\ncomplexity of open molecule generation, we have also developed an automated\nevaluation system that helps measure both the quality and the accuracy of the\ngenerated molecules. Our comprehensive benchmarking of 25 LLMs reveals the\ncurrent limitations and potential areas for improvement in text-guided molecule\ndiscovery. Furthermore, with the assistance of OpenMolIns, a specialized\ninstruction tuning dataset proposed for solving challenges raised by\nTOMG-Bench, Llama3.1-8B could outperform all the open-source general LLMs, even\nsurpassing GPT-3.5-turbo by 46.5\\% on TOMG-Bench. Our codes and datasets are\navailable through https://github.com/phenixace/TOMG-Bench.\n","authors":["Jiatong Li","Junxian Li","Yunqing Liu","Dongzhan Zhou","Qing Li"],"pdf_url":"https://arxiv.org/pdf/2412.14642v1.pdf","comment":"A benchmark for text-based open molecule generation"},{"id":"http://arxiv.org/abs/2409.17603v2","updated":"2024-12-19T08:39:05Z","published":"2024-09-26T07:40:03Z","title":"Deep CLAS: Deep Contextual Listen, Attend and Spell","summary":"  Contextual-LAS (CLAS) has been shown effective in improving Automatic Speech\nRecognition (ASR) of rare words. It relies on phrase-level contextual modeling\nand attention-based relevance scoring without explicit contextual constraint\nwhich lead to insufficient use of contextual information. In this work, we\npropose deep CLAS to use contextual information better. We introduce bias loss\nforcing model to focus on contextual information. The query of bias attention\nis also enriched to improve the accuracy of the bias attention score. To get\nfine-grained contextual information, we replace phrase-level encoding with\ncharacter-level encoding and encode contextual information with conformer\nrather than LSTM. Moreover, we directly use the bias attention score to correct\nthe output probability distribution of the model. Experiments using the public\nAISHELL-1 and AISHELL-NER. On AISHELL-1, compared to CLAS baselines, deep CLAS\nobtains a 65.78% relative recall and a 53.49% relative F1-score increase in the\nnamed entity recognition scene.\n","authors":["Mengzhi Wang","Shifu Xiong","Genshun Wan","Hang Chen","Jianqing Gao","Lirong Dai"],"pdf_url":"https://arxiv.org/pdf/2409.17603v2.pdf","comment":"Submitted to JUSTC"},{"id":"http://arxiv.org/abs/2412.14626v1","updated":"2024-12-19T08:28:18Z","published":"2024-12-19T08:28:18Z","title":"Learning to Generate Research Idea with Dynamic Control","summary":"  The rapid advancements in large language models (LLMs) have demonstrated\ntheir potential to accelerate scientific discovery, particularly in automating\nthe process of research ideation. LLM-based systems have shown promise in\ngenerating hypotheses and research ideas. However, current approaches\npredominantly rely on prompting-based pre-trained models, limiting their\nability to optimize generated content effectively. Moreover, they also lack the\ncapability to deal with the complex interdependence and inherent restrictions\namong novelty, feasibility, and effectiveness, which remains challenging due to\nthe inherent trade-offs among these dimensions, such as the\ninnovation-feasibility conflict. To address these limitations, we for the first\ntime propose fine-tuning LLMs to be better idea proposers and introduce a novel\nframework that employs a two-stage approach combining Supervised Fine-Tuning\n(SFT) and controllable Reinforcement Learning (RL). In the SFT stage, the model\nlearns foundational patterns from pairs of research papers and follow-up ideas.\nIn the RL stage, multi-dimensional reward modeling, guided by fine-grained\nfeedback, evaluates and optimizes the generated ideas across key metrics.\nDimensional controllers enable dynamic adjustment of generation, while a\nsentence-level decoder ensures context-aware emphasis during inference. Our\nframework provides a balanced approach to research ideation, achieving\nhigh-quality outcomes by dynamically navigating the trade-offs among novelty,\nfeasibility, and effectiveness.\n","authors":["Ruochen Li","Liqiang Jing","Chi Han","Jiawei Zhou","Xinya Du"],"pdf_url":"https://arxiv.org/pdf/2412.14626v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14011v2","updated":"2024-12-19T08:27:54Z","published":"2024-12-18T16:29:45Z","title":"Towards an optimised evaluation of teachers' discourse: The case of\n  engaging messages","summary":"  Evaluating teachers' skills is crucial for enhancing education quality and\nstudent outcomes. Teacher discourse, significantly influencing student\nperformance, is a key component. However, coding this discourse can be\nlaborious. This study addresses this issue by introducing a new methodology for\noptimising the assessment of teacher discourse. The research consisted of two\nstudies, both within the framework of engaging messages used by secondary\neducation teachers. The first study involved training two large language models\non real-world examples from audio-recorded lessons over two academic years to\nidentify and classify the engaging messages from the lessons' transcripts. This\nresulted in sensitivities of 84.31% and 91.11%, and specificities of 97.69% and\n86.36% in identification and classification, respectively. The second study\napplied these models to transcripts of audio-recorded lessons from a third\nacademic year to examine the frequency and distribution of message types by\neducational level and moment of the academic year. Results showed teachers\npredominantly use messages emphasising engagement benefits, linked to improved\noutcomes, while one-third highlighted non-engagement disadvantages, associated\nwith increased anxiety. The use of engaging messages declined in Grade 12 and\ntowards the academic year's end. These findings suggest potential interventions\nto optimise engaging message use, enhancing teaching quality and student\noutcomes.\n","authors":["Samuel Falcon","Jaime Leon"],"pdf_url":"https://arxiv.org/pdf/2412.14011v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14617v1","updated":"2024-12-19T08:06:09Z","published":"2024-12-19T08:06:09Z","title":"How good is GPT at writing political speeches for the White House?","summary":"  Using large language models (LLMs), computers are able to generate a written\ntext in response to a us er request. As this pervasive technology can be\napplied in numerous contexts, this study analyses the written style of one LLM\ncalled GPT by comparing its generated speeches with those of the recent US\npresidents. To achieve this objective, the State of the Union (SOTU) addresses\nwritten by Reagan to Biden are contrasted to those produced by both GPT-3.5 and\nGPT-4.o versions. Compared to US presidents, GPT tends to overuse the lemma\n\"we\" and produce shorter messages with, on average, longer sentences. Moreover,\nGPT opts for an optimistic tone, opting more often for political (e.g.,\npresident, Congress), symbolic (e.g., freedom), and abstract terms (e.g.,\nfreedom). Even when imposing an author's style to GPT, the resulting speech\nremains distinct from addresses written by the target author. Finally, the two\nGPT versions present distinct characteristics, but both appear overall\ndissimilar to true presidential messages.\n","authors":["Jacques Savoy"],"pdf_url":"https://arxiv.org/pdf/2412.14617v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14613v1","updated":"2024-12-19T08:03:16Z","published":"2024-12-19T08:03:16Z","title":"HarmonicEval: Multi-modal, Multi-task, Multi-criteria Automatic\n  Evaluation Using a Vision Language Model","summary":"  Vision-language models (VLMs) have shown impressive abilities in text and\nimage understanding. However, existing metrics for evaluating the text\ngenerated by VLMs focus exclusively on overall quality, leading to two\nlimitations: 1) it is challenging to identify which aspects of the text need\nimprovement from the overall score; 2) metrics may overlook specific evaluation\ncriteria when predicting an overall score. To address these limitations, we\npropose HarmonicEval, a reference-free evaluation metric that aggregates\ncriterion-wise scores to produce the overall score in a bottom-up manner.\nFurthermore, we construct the Multi-task Multi-criteria Human Evaluation (MMHE)\ndataset, which comprises 18,000 expert human judgments across four\nvision-language tasks. Our experiments demonstrate that HarmonicEval achieves\nhigher correlations with human judgments than conventional metrics while\nproviding numerical scores for each criterion.\n","authors":["Masanari Ohi","Masahiro Kaneko","Naoaki Okazaki","Nakamasa Inoue"],"pdf_url":"https://arxiv.org/pdf/2412.14613v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14612v1","updated":"2024-12-19T08:02:08Z","published":"2024-12-19T08:02:08Z","title":"KARRIEREWEGE: A Large Scale Career Path Prediction Dataset","summary":"  Accurate career path prediction can support many stakeholders, like job\nseekers, recruiters, HR, and project managers. However, publicly available data\nand tools for career path prediction are scarce. In this work, we introduce\nKARRIEREWEGE, a comprehensive, publicly available dataset containing over 500k\ncareer paths, significantly surpassing the size of previously available\ndatasets. We link the dataset to the ESCO taxonomy to offer a valuable resource\nfor predicting career trajectories. To tackle the problem of free-text inputs\ntypically found in resumes, we enhance it by synthesizing job titles and\ndescriptions resulting in KARRIEREWEGE+. This allows for accurate predictions\nfrom unstructured data, closely aligning with real-world application\nchallenges. We benchmark existing state-of-the-art (SOTA) models on our dataset\nand a prior benchmark and observe improved performance and robustness,\nparticularly for free-text use cases, due to the synthesized data.\n","authors":["Elena Senger","Yuri Campbell","Rob van der Goot","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2412.14612v1.pdf","comment":"Accepted at COLING Industry Track"},{"id":"http://arxiv.org/abs/2412.14596v1","updated":"2024-12-19T07:31:40Z","published":"2024-12-19T07:31:40Z","title":"LDP: Generalizing to Multilingual Visual Information Extraction by\n  Language Decoupled Pretraining","summary":"  Visual Information Extraction (VIE) plays a crucial role in the comprehension\nof semi-structured documents, and several pre-trained models have been\ndeveloped to enhance performance. However, most of these works are monolingual\n(usually English). Due to the extremely unbalanced quantity and quality of\npre-training corpora between English and other languages, few works can extend\nto non-English scenarios. In this paper, we conduct systematic experiments to\nshow that vision and layout modality hold invariance among images with\ndifferent languages. If decoupling language bias from document images, a\nvision-layout-based model can achieve impressive cross-lingual generalization.\nAccordingly, we present a simple but effective multilingual training paradigm\nLDP (Language Decoupled Pre-training) for better utilization of monolingual\npre-training data. Our proposed model LDM (Language Decoupled Model) is first\npre-trained on the language-independent data, where the language knowledge is\ndecoupled by a diffusion model, and then the LDM is fine-tuned on the\ndownstream languages. Extensive experiments show that the LDM outperformed all\nSOTA multilingual pre-trained models, and also maintains competitiveness on\ndownstream monolingual/English benchmarks.\n","authors":["Huawen Shen","Gengluo Li","Jinwen Zhong","Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.14596v1.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2411.12262v2","updated":"2024-12-19T07:29:23Z","published":"2024-11-19T06:21:51Z","title":"Low-resource Machine Translation: what for? who for? An observational\n  study on a dedicated Tetun language translation service","summary":"  Low-resource machine translation (MT) presents a diversity of community needs\nand application challenges that remain poorly understood. To complement surveys\nand focus groups, which tend to rely on small samples of respondents, we\npropose an observational study on actual usage patterns of a specialized MT\nservice for the Tetun language, which is the lingua franca in Timor-Leste. Our\nanalysis of 100,000 translation requests reveals patterns that challenge\nassumptions based on existing corpora. We find that users, many of them\nstudents on mobile devices, typically translate text from a high-resource\nlanguage into Tetun across diverse domains including science, healthcare, and\ndaily life. This contrasts sharply with available Tetun corpora, which are\ndominated by news articles covering government and social issues. Our results\nsuggest that MT systems for minority languages like Tetun should prioritize\naccuracy on domains relevant to educational contexts, in the high-resource to\nlow-resource direction. More broadly, this study demonstrates how observational\nanalysis can inform low-resource language technology development, by grounding\nresearch in practical community needs.\n","authors":["Raphael Merx","Adérito José Guterres Correia","Hanna Suominen","Ekaterina Vylomova"],"pdf_url":"https://arxiv.org/pdf/2411.12262v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14588v1","updated":"2024-12-19T07:14:13Z","published":"2024-12-19T07:14:13Z","title":"Beyond Guilt: Legal Judgment Prediction with Trichotomous Reasoning","summary":"  In legal practice, judges apply the trichotomous dogmatics of criminal law,\nsequentially assessing the elements of the offense, unlawfulness, and\nculpability to determine whether an individual's conduct constitutes a crime.\nAlthough current legal large language models (LLMs) show promising accuracy in\njudgment prediction, they lack trichotomous reasoning capabilities due to the\nabsence of an appropriate benchmark dataset, preventing them from predicting\ninnocent outcomes. As a result, every input is automatically assigned a charge,\nlimiting their practical utility in legal contexts. To bridge this gap, we\nintroduce LJPIV, the first benchmark dataset for Legal Judgment Prediction with\nInnocent Verdicts. Adhering to the trichotomous dogmatics, we extend three\nwidely-used legal datasets through LLM-based augmentation and manual\nverification. Our experiments with state-of-the-art legal LLMs and novel\nstrategies that integrate trichotomous reasoning into zero-shot prompting and\nfine-tuning reveal: (1) current legal LLMs have significant room for\nimprovement, with even the best models achieving an F1 score of less than 0.3\non LJPIV; and (2) our strategies notably enhance both in-domain and\ncross-domain judgment prediction accuracy, especially for cases resulting in an\ninnocent verdict.\n","authors":["Kepu Zhang","Haoyue Yang","Xu Tang","Weijie Yu","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2412.14588v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14584v1","updated":"2024-12-19T07:06:01Z","published":"2024-12-19T07:06:01Z","title":"Simulation-Free Hierarchical Latent Policy Planning for Proactive\n  Dialogues","summary":"  Recent advancements in proactive dialogues have garnered significant\nattention, particularly for more complex objectives (e.g. emotion support and\npersuasion). Unlike traditional task-oriented dialogues, proactive dialogues\ndemand advanced policy planning and adaptability, requiring rich scenarios and\ncomprehensive policy repositories to develop such systems. However, existing\napproaches tend to rely on Large Language Models (LLMs) for user simulation and\nonline learning, leading to biases that diverge from realistic scenarios and\nresult in suboptimal efficiency. Moreover, these methods depend on manually\ndefined, context-independent, coarse-grained policies, which not only incur\nhigh expert costs but also raise concerns regarding their completeness. In our\nwork, we highlight the potential for automatically discovering policies\ndirectly from raw, real-world dialogue records. To this end, we introduce a\nnovel dialogue policy planning framework, LDPP. It fully automates the process\nfrom mining policies in dialogue records to learning policy planning.\nSpecifically, we employ a variant of the Variational Autoencoder to discover\nfine-grained policies represented as latent vectors. After automatically\nannotating the data with these latent policy labels, we propose an Offline\nHierarchical Reinforcement Learning (RL) algorithm in the latent space to\ndevelop effective policy planning capabilities. Our experiments demonstrate\nthat LDPP outperforms existing methods on two proactive scenarios, even\nsurpassing ChatGPT with only a 1.8-billion-parameter LLM.\n","authors":["Tao He","Lizi Liao","Yixin Cao","Yuanxing Liu","Yiheng Sun","Zerui Chen","Ming Liu","Bing Qin"],"pdf_url":"https://arxiv.org/pdf/2412.14584v1.pdf","comment":"24 pages, 5 fgiures, AAAI 2025"},{"id":"http://arxiv.org/abs/2412.14581v1","updated":"2024-12-19T07:01:25Z","published":"2024-12-19T07:01:25Z","title":"CORD: Balancing COnsistency and Rank Distillation for Robust\n  Retrieval-Augmented Generation","summary":"  With the adoption of retrieval-augmented generation (RAG), large language\nmodels (LLMs) are expected to ground their generation to the retrieved\ncontexts. Yet, this is hindered by position bias of LLMs, failing to evenly\nattend to all contexts. Previous work has addressed this by synthesizing\ncontexts with perturbed positions of gold segment, creating a\nposition-diversified train set. We extend this intuition to propose consistency\nregularization with augmentation and distillation. First, we augment each\ntraining instance with its position perturbation to encourage consistent\npredictions, regardless of ordering. We also distill behaviors of this pair,\nalthough it can be counterproductive in certain RAG scenarios where the given\norder from the retriever is crucial for generation quality. We thus propose\nCORD, balancing COnsistency and Rank Distillation. CORD adaptively samples\nnoise-controlled perturbations from an interpolation space, ensuring both\nconsistency and respect for the rank prior. Empirical results show this balance\nenables CORD to outperform consistently in diverse RAG benchmarks.\n","authors":["Youngwon Lee","Seung-won Hwang","Daniel Campos","Filip Graliński","Zhewei Yao","Yuxiong He"],"pdf_url":"https://arxiv.org/pdf/2412.14581v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.07629v2","updated":"2024-12-19T06:53:37Z","published":"2024-12-10T16:08:14Z","title":"Piece of Table: A Divide-and-Conquer Approach for Selecting Sub-Tables\n  in Table Question Answering","summary":"  Applying language models (LMs) to tables is challenging due to the inherent\nstructural differences between two-dimensional tables and one-dimensional text\nfor which the LMs were originally designed. Furthermore, when applying\nlinearized tables to LMs, the maximum token lengths often imposed in\nself-attention calculations make it difficult to comprehensively understand the\ncontext spread across large tables. To address these challenges, we present\nPieTa (Piece of Table), a new framework for sub-table-based question answering\n(QA). PieTa operates through an iterative process of dividing tables into\nsmaller windows, using LMs to select relevant cells within each window, and\nmerging these cells into a sub-table. This multi-resolution approach captures\ndependencies across multiple rows and columns while avoiding the limitations\ncaused by long context inputs. Instantiated as a simple iterative sub-table\nunion algorithm, PieTa demonstrates improved performance over previous\nsub-table-based QA approaches.\n","authors":["Wonjin Lee","Kyumin Kim","Sungjae Lee","Jihun Lee","Kwang In Kim"],"pdf_url":"https://arxiv.org/pdf/2412.07629v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14574v1","updated":"2024-12-19T06:44:59Z","published":"2024-12-19T06:44:59Z","title":"Sliding Windows Are Not the End: Exploring Full Ranking with\n  Long-Context Large Language Models","summary":"  Large Language Models (LLMs) have shown exciting performance in listwise\npassage ranking. Due to the limited input length, existing methods often adopt\nthe sliding window strategy. Such a strategy, though effective, is inefficient\nas it involves repetitive and serialized processing, which usually re-evaluates\nrelevant passages multiple times. As a result, it incurs redundant API costs,\nwhich are proportional to the number of inference tokens. The development of\nlong-context LLMs enables the full ranking of all passages within a single\ninference, avoiding redundant API costs. In this paper, we conduct a\ncomprehensive study of long-context LLMs for ranking tasks in terms of\nefficiency and effectiveness. Surprisingly, our experiments reveal that full\nranking with long-context LLMs can deliver superior performance in the\nsupervised fine-tuning setting with a huge efficiency improvement. Furthermore,\nwe identify two limitations of fine-tuning the full ranking model based on\nexisting methods: (1) sliding window strategy fails to produce a full ranking\nlist as a training label, and (2) the language modeling loss cannot emphasize\ntop-ranked passage IDs in the label. To alleviate these issues, we propose a\nnew complete listwise label construction approach and a novel importance-aware\nlearning objective for full ranking. Experiments show the superior performance\nof our method over baselines. Our codes are available at\n\\url{https://github.com/8421BCD/fullrank}.\n","authors":["Wenhan Liu","Xinyu Ma","Yutao Zhu","Ziliang Zhao","Shuaiqiang Wang","Dawei Yin","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2412.14574v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2408.07663v2","updated":"2024-12-19T06:34:31Z","published":"2024-08-14T16:51:21Z","title":"Alignment-Enhanced Decoding:Defending via Token-Level Adaptive Refining\n  of Probability Distributions","summary":"  Large language models are susceptible to jailbreak attacks, which can result\nin the generation of harmful content. While prior defenses mitigate these risks\nby perturbing or inspecting inputs, they ignore competing objectives, the\nunderlying cause of alignment failures. In this paper, we propose\nAlignment-Enhanced Decoding (AED), a novel defense that employs adaptive\ndecoding to address the root causes of jailbreak issues. We first define the\nCompetitive Index to quantify alignment failures and utilize feedback from\nself-evaluation to compute post-alignment logits. Then, AED adaptively combines\nAED and post-alignment logits with the original logits to obtain harmless and\nhelpful distributions. Consequently, our method enhances safety alignment while\nmaintaining helpfulness. We conduct experiments across five models and four\ncommon jailbreaks, with the results validating the effectiveness of our\napproach. Code is available at https://github.com/GIGABaozi/AED.git.\n","authors":["Quan Liu","Zhenhong Zhou","Longzhu He","Yi Liu","Wei Zhang","Sen Su"],"pdf_url":"https://arxiv.org/pdf/2408.07663v2.pdf","comment":"Accepted by EMNLP 2024, 15 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.13663v2","updated":"2024-12-19T06:32:26Z","published":"2024-12-18T09:39:44Z","title":"Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for\n  Fast, Memory Efficient, and Long Context Finetuning and Inference","summary":"  Encoder-only transformer models such as BERT offer a great performance-size\ntradeoff for retrieval and classification tasks with respect to larger\ndecoder-only models. Despite being the workhorse of numerous production\npipelines, there have been limited Pareto improvements to BERT since its\nrelease. In this paper, we introduce ModernBERT, bringing modern model\noptimizations to encoder-only models and representing a major Pareto\nimprovement over older encoders. Trained on 2 trillion tokens with a native\n8192 sequence length, ModernBERT models exhibit state-of-the-art results on a\nlarge pool of evaluations encompassing diverse classification tasks and both\nsingle and multi-vector retrieval on different domains (including code). In\naddition to strong downstream performance, ModernBERT is also the most speed\nand memory efficient encoder and is designed for inference on common GPUs.\n","authors":["Benjamin Warner","Antoine Chaffin","Benjamin Clavié","Orion Weller","Oskar Hallström","Said Taghadouini","Alexis Gallagher","Raja Biswas","Faisal Ladhak","Tom Aarsen","Nathan Cooper","Griffin Adams","Jeremy Howard","Iacopo Poli"],"pdf_url":"https://arxiv.org/pdf/2412.13663v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.19813v3","updated":"2024-12-19T06:27:44Z","published":"2024-07-29T09:05:10Z","title":"Improving Retrieval Augmented Language Model with Self-Reasoning","summary":"  The Retrieval-Augmented Language Model (RALM) has shown remarkable\nperformance on knowledge-intensive tasks by incorporating external knowledge\nduring inference, which mitigates the factual hallucinations inherited in large\nlanguage models (LLMs). Despite these advancements, challenges persist in the\nimplementation of RALMs, particularly concerning their reliability and\ntraceability. To be specific, the irrelevant document retrieval may result in\nunhelpful response generation or even deteriorate the performance of LLMs,\nwhile the lack of proper citations in generated outputs complicates efforts to\nverify the trustworthiness of the models. To this end, we propose a novel\nself-reasoning framework aimed at improving the reliability and traceability of\nRALMs, whose core idea is to leverage reasoning trajectories generated by the\nLLM itself. The framework involves constructing self-reason trajectories with\nthree processes: a relevance-aware process, an evidence-aware selective\nprocess, and a trajectory analysis process. We have evaluated our framework\nacross four public datasets (two short-form QA datasets, one long-form QA\ndataset, and one fact verification dataset) to demonstrate the superiority of\nour method, which can outperform existing state-of-the-art models and can\nachieve comparable performance with GPT-4, while only using 2,000 training\nsamples.\n","authors":["Yuan Xia","Jingbo Zhou","Zhenhui Shi","Jun Chen","Haifeng Huang"],"pdf_url":"https://arxiv.org/pdf/2407.19813v3.pdf","comment":"AAAI 2025 (main conference)"},{"id":"http://arxiv.org/abs/2412.14556v1","updated":"2024-12-19T06:14:20Z","published":"2024-12-19T06:14:20Z","title":"CitaLaw: Enhancing LLM with Citations in Legal Domain","summary":"  In this paper, we propose CitaLaw, the first benchmark designed to evaluate\nLLMs' ability to produce legally sound responses with appropriate citations.\nCitaLaw features a diverse set of legal questions for both laypersons and\npractitioners, paired with a comprehensive corpus of law articles and precedent\ncases as a reference pool. This framework enables LLM-based systems to retrieve\nsupporting citations from the reference corpus and align these citations with\nthe corresponding sentences in their responses. Moreover, we introduce\nsyllogism-inspired evaluation methods to assess the legal alignment between\nretrieved references and LLM-generated responses, as well as their consistency\nwith user questions. Extensive experiments on 2 open-domain and 7\nlegal-specific LLMs demonstrate that integrating legal references substantially\nenhances response quality. Furthermore, our proposed syllogism-based evaluation\nmethod exhibits strong agreement with human judgments.\n","authors":["Kepu Zhang","Weijie Yu","Sunhao Dai","Jun Xu"],"pdf_url":"https://arxiv.org/pdf/2412.14556v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08125v2","updated":"2024-12-19T05:46:29Z","published":"2024-12-11T06:21:33Z","title":"Progressive Multi-granular Alignments for Grounded Reasoning in Large\n  Vision-Language Models","summary":"  Existing Large Vision-Language Models (LVLMs) excel at matching concepts\nacross multi-modal inputs but struggle with compositional concepts and\nhigh-level relationships between entities. This paper introduces Progressive\nmulti-granular Vision-Language alignments (PromViL), a novel framework to\nenhance LVLMs' ability in performing grounded compositional visual reasoning\ntasks. Our approach constructs a hierarchical structure of multi-modal\nalignments, ranging from simple to complex concepts. By progressively aligning\ntextual descriptions with corresponding visual regions, our model learns to\nleverage contextual information from lower levels to inform higher-level\nreasoning. To facilitate this learning process, we introduce a data generation\nprocess that creates a novel dataset derived from Visual Genome, providing a\nwide range of nested compositional vision-language pairs. Experimental results\ndemonstrate that our PromViL framework significantly outperforms baselines on\nvarious visual grounding and compositional question answering tasks. The code\nis available at: https://github.com/lqh52/PromViL.\n","authors":["Quang-Hung Le","Long Hoang Dang","Ngan Le","Truyen Tran","Thao Minh Le"],"pdf_url":"https://arxiv.org/pdf/2412.08125v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.00451v3","updated":"2024-12-19T05:32:59Z","published":"2024-10-01T07:11:55Z","title":"Unleashing the Unseen: Harnessing Benign Datasets for Jailbreaking Large\n  Language Models","summary":"  Despite significant ongoing efforts in safety alignment, large language\nmodels (LLMs) such as GPT-4 and LLaMA 3 remain vulnerable to jailbreak attacks\nthat can induce harmful behaviors, including through the use of adversarial\nsuffixes. Building on prior research, we hypothesize that these adversarial\nsuffixes are not mere bugs but may represent features that can dominate the\nLLM's behavior. To evaluate this hypothesis, we conduct several experiments.\nFirst, we demonstrate that benign features can be effectively made to function\nas adversarial suffixes, i.e., we develop a feature extraction method to\nextract sample-agnostic features from benign dataset in the form of suffixes\nand show that these suffixes may effectively compromise safety alignment.\nSecond, we show that adversarial suffixes generated from jailbreak attacks may\ncontain meaningful features, i.e., appending the same suffix to different\nprompts results in responses exhibiting specific characteristics. Third, we\nshow that such benign-yet-safety-compromising features can be easily introduced\nthrough fine-tuning using only benign datasets. As a result, we are able to\ncompletely eliminate GPT's safety alignment in a blackbox setting through\nfinetuning with only benign data. Our code and data is available at\n\\url{https://github.com/suffix-maybe-feature/adver-suffix-maybe-features}.\n","authors":["Wei Zhao","Zhe Li","Yige Li","Jun Sun"],"pdf_url":"https://arxiv.org/pdf/2410.00451v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.13362v3","updated":"2024-12-19T05:26:14Z","published":"2024-06-19T09:07:31Z","title":"VisualRWKV: Exploring Recurrent Neural Networks for Visual Language\n  Models","summary":"  Visual Language Models (VLMs) have rapidly progressed with the recent success\nof large language models. However, there have been few attempts to incorporate\nefficient linear Recurrent Neural Networks (RNNs) architectures into VLMs. In\nthis study, we introduce VisualRWKV, the first application of a linear RNN\nmodel to multimodal learning tasks, leveraging the pre-trained RWKV language\nmodel. We propose a data-dependent recurrence and sandwich prompts to enhance\nour modeling capabilities, along with a 2D image scanning mechanism to enrich\nthe processing of visual sequences. Extensive experiments demonstrate that\nVisualRWKV achieves competitive performance compared to Transformer-based\nmodels like LLaVA-1.5 on various benchmarks. Compared to LLaVA-1.5, VisualRWKV\nhas a speed advantage of 3.98 times and can save 54% of GPU memory when\nreaching an inference length of 24K tokens. To facilitate further research and\nanalysis, we have made the checkpoints and the associated code publicly\naccessible at the following GitHub repository: see\nhttps://github.com/howard-hou/VisualRWKV.\n","authors":["Haowen Hou","Peigen Zeng","Fei Ma","Fei Richard Yu"],"pdf_url":"https://arxiv.org/pdf/2406.13362v3.pdf","comment":"Accepted at COLING 2025 main conference"},{"id":"http://arxiv.org/abs/2412.14533v1","updated":"2024-12-19T05:11:16Z","published":"2024-12-19T05:11:16Z","title":"ClusterTalk: Corpus Exploration Framework using Multi-Dimensional\n  Exploratory Search","summary":"  Exploratory search of large text corpora is essential in domains like\nbiomedical research, where large amounts of research literature are\ncontinuously generated. This paper presents ClusterTalk (The demo video and\nsource code are available at: https://github.com/achouhan93/ClusterTalk), a\nframework for corpus exploration using multi-dimensional exploratory search.\nOur system integrates document clustering with faceted search, allowing users\nto interactively refine their exploration and ask corpus and document-level\nqueries. Compared to traditional one-dimensional search approaches like keyword\nsearch or clustering, this system improves the discoverability of information\nby encouraging a deeper interaction with the corpus. We demonstrate the\nfunctionality of the ClusterTalk framework based on four million PubMed\nabstracts for the four-year time frame.\n","authors":["Ashish Chouhan","Saifeldin Mandour","Michael Gertz"],"pdf_url":"https://arxiv.org/pdf/2412.14533v1.pdf","comment":"5 pages, 1 figure"},{"id":"http://arxiv.org/abs/2404.01349v2","updated":"2024-12-19T05:05:46Z","published":"2024-03-31T22:22:53Z","title":"Fairness in Large Language Models: A Taxonomic Survey","summary":"  Large Language Models (LLMs) have demonstrated remarkable success across\nvarious domains. However, despite their promising performance in numerous\nreal-world applications, most of these algorithms lack fairness considerations.\nConsequently, they may lead to discriminatory outcomes against certain\ncommunities, particularly marginalized populations, prompting extensive study\nin fair LLMs. On the other hand, fairness in LLMs, in contrast to fairness in\ntraditional machine learning, entails exclusive backgrounds, taxonomies, and\nfulfillment techniques. To this end, this survey presents a comprehensive\noverview of recent advances in the existing literature concerning fair LLMs.\nSpecifically, a brief introduction to LLMs is provided, followed by an analysis\nof factors contributing to bias in LLMs. Additionally, the concept of fairness\nin LLMs is discussed categorically, summarizing metrics for evaluating bias in\nLLMs and existing algorithms for promoting fairness. Furthermore, resources for\nevaluating bias in LLMs, including toolkits and datasets, are summarized.\nFinally, existing research challenges and open questions are discussed.\n","authors":["Zhibo Chu","Zichong Wang","Wenbin Zhang"],"pdf_url":"https://arxiv.org/pdf/2404.01349v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08108v2","updated":"2024-12-19T05:01:33Z","published":"2024-12-11T05:23:34Z","title":"Doubly-Universal Adversarial Perturbations: Deceiving Vision-Language\n  Models Across Both Images and Text with a Single Perturbation","summary":"  Large Vision-Language Models (VLMs) have demonstrated remarkable performance\nacross multimodal tasks by integrating vision encoders with large language\nmodels (LLMs). However, these models remain vulnerable to adversarial attacks.\nAmong such attacks, Universal Adversarial Perturbations (UAPs) are especially\npowerful, as a single optimized perturbation can mislead the model across\nvarious input images. In this work, we introduce a novel UAP specifically\ndesigned for VLMs: the Doubly-Universal Adversarial Perturbation (Doubly-UAP),\ncapable of universally deceiving VLMs across both image and text inputs. To\nsuccessfully disrupt the vision encoder's fundamental process, we analyze the\ncore components of the attention mechanism. After identifying value vectors in\nthe middle-to-late layers as the most vulnerable, we optimize Doubly-UAP in a\nlabel-free manner with a frozen model. Despite being developed as a black-box\nto the LLM, Doubly-UAP achieves high attack success rates on VLMs, consistently\noutperforming baseline methods across vision-language tasks. Extensive ablation\nstudies and analyses further demonstrate the robustness of Doubly-UAP and\nprovide insights into how it influences internal attention mechanisms.\n","authors":["Hee-Seon Kim","Minbeom Kim","Changick Kim"],"pdf_url":"https://arxiv.org/pdf/2412.08108v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14528v1","updated":"2024-12-19T04:51:06Z","published":"2024-12-19T04:51:06Z","title":"Multi-Level Optimal Transport for Universal Cross-Tokenizer Knowledge\n  Distillation on Language Models","summary":"  Knowledge distillation (KD) has become a prevalent technique for compressing\nlarge language models (LLMs). Existing KD methods are constrained by the need\nfor identical tokenizers (i.e., vocabularies) between teacher and student\nmodels, limiting their versatility in handling LLMs of different architecture\nfamilies. In this paper, we introduce the Multi-Level Optimal Transport\n(MultiLevelOT), a novel approach that advances the optimal transport for\nuniversal cross-tokenizer knowledge distillation. Our method aligns the logit\ndistributions of the teacher and the student at both token and sequence levels\nusing diverse cost matrices, eliminating the need for dimensional or\ntoken-by-token correspondence. At the token level, MultiLevelOT integrates both\nglobal and local information by jointly optimizing all tokens within a sequence\nto enhance robustness. At the sequence level, we efficiently capture complex\ndistribution structures of logits via the Sinkhorn distance, which approximates\nthe Wasserstein distance for divergence measures. Extensive experiments on\ntasks such as extractive QA, generative QA, and summarization demonstrate that\nthe MultiLevelOT outperforms state-of-the-art cross-tokenizer KD methods under\nvarious settings. Our approach is robust to different student and teacher\nmodels across model families, architectures, and parameter sizes.\n","authors":["Xiao Cui","Mo Zhu","Yulei Qin","Liang Xie","Wengang Zhou","Houqiang Li"],"pdf_url":"https://arxiv.org/pdf/2412.14528v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2411.16646v2","updated":"2024-12-19T04:50:45Z","published":"2024-11-25T18:28:26Z","title":"Self-Generated Critiques Boost Reward Modeling for Language Models","summary":"  Reward modeling is crucial for aligning large language models (LLMs) with\nhuman preferences, especially in reinforcement learning from human feedback\n(RLHF). However, current reward models mainly produce scalar scores and\nstruggle to incorporate critiques in a natural language format. We hypothesize\nthat predicting both critiques and the scalar reward would improve reward\nmodeling ability. Motivated by this, we propose Critic-RM, a framework that\nimproves reward models using self-generated critiques without extra\nsupervision. Critic-RM employs a two-stage process: generating and filtering\nhigh-quality critiques, followed by joint fine-tuning on reward prediction and\ncritique generation. Experiments across benchmarks show that Critic-RM improves\nreward modeling accuracy by 3.7%-7.3% compared to standard reward models and\nLLM judges, demonstrating strong performance and data efficiency. Additional\nstudies further validate the effectiveness of generated critiques in rectifying\nflawed reasoning steps with 2.5%-3.2% gains in improving reasoning accuracy.\n","authors":["Yue Yu","Zhengxing Chen","Aston Zhang","Liang Tan","Chenguang Zhu","Richard Yuanzhe Pang","Yundi Qian","Xuewei Wang","Suchin Gururangan","Chao Zhang","Melanie Kambadur","Dhruv Mahajan","Rui Hou"],"pdf_url":"https://arxiv.org/pdf/2411.16646v2.pdf","comment":"20 pages"},{"id":"http://arxiv.org/abs/2412.00869v2","updated":"2024-12-19T04:38:59Z","published":"2024-12-01T16:15:14Z","title":"KnowledgePrompts: Exploring the Abilities of Large Language Models to\n  Solve Proportional Analogies via Knowledge-Enhanced Prompting","summary":"  Making analogies is fundamental to cognition. Proportional analogies, which\nconsist of four terms, are often used to assess linguistic and cognitive\nabilities. For instance, completing analogies like \"Oxygen is to Gas as <blank>\nis to <blank>\" requires identifying the semantic relationship (e.g., \"type of\")\nbetween the first pair of terms (\"Oxygen\" and \"Gas\") and finding a second pair\nthat shares the same relationship (e.g., \"Aluminum\" and \"Metal\"). In this work,\nwe introduce a 15K Multiple-Choice Question Answering (MCQA) dataset for\nproportional analogy completion and evaluate the performance of contemporary\nLarge Language Models (LLMs) in various knowledge-enhanced prompt settings.\nSpecifically, we augment prompts with three types of knowledge: exemplar,\nstructured, and targeted. Our results show that despite extensive training\ndata, solving proportional analogies remains challenging for current LLMs, with\nthe best model achieving an accuracy of 55%. Notably, we find that providing\ntargeted knowledge can better assist models in completing proportional\nanalogies compared to providing exemplars or collections of structured\nknowledge. Our code and data are available at:\nhttps://github.com/Thiliniiw/KnowledgePrompts/\n","authors":["Thilini Wijesiriwardene","Ruwan Wickramarachchi","Sreeram Vennam","Vinija Jain","Aman Chadha","Amitava Das","Ponnurangam Kumaraguru","Amit Sheth"],"pdf_url":"https://arxiv.org/pdf/2412.00869v2.pdf","comment":"Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2305.09574v2","updated":"2024-12-19T04:35:08Z","published":"2023-05-16T16:11:48Z","title":"UOR: Universal Backdoor Attacks on Pre-trained Language Models","summary":"  Backdoors implanted in pre-trained language models (PLMs) can be transferred\nto various downstream tasks, which exposes a severe security threat. However,\nmost existing backdoor attacks against PLMs are un-targeted and task-specific.\nFew targeted and task-agnostic methods use manually pre-defined triggers and\noutput representations, which prevent the attacks from being more effective and\ngeneral. In this paper, we first summarize the requirements that a more\nthreatening backdoor attack against PLMs should satisfy, and then propose a new\nbackdoor attack method called UOR, which breaks the bottleneck of the previous\napproach by turning manual selection into automatic optimization. Specifically,\nwe define poisoned supervised contrastive learning which can automatically\nlearn the more uniform and universal output representations of triggers for\nvarious PLMs. Moreover, we use gradient search to select appropriate trigger\nwords which can be adaptive to different PLMs and vocabularies. Experiments\nshow that our method can achieve better attack performance on various text\nclassification tasks compared to manual methods. Further, we tested our method\non PLMs with different architectures, different usage paradigms, and more\ndifficult tasks, which demonstrated the universality of our method.\n","authors":["Wei Du","Peixuan Li","Boqun Li","Haodong Zhao","Gongshen Liu"],"pdf_url":"https://arxiv.org/pdf/2305.09574v2.pdf","comment":"ACL-Findings 2024"},{"id":"http://arxiv.org/abs/2412.14516v1","updated":"2024-12-19T04:31:56Z","published":"2024-12-19T04:31:56Z","title":"Cal-DPO: Calibrated Direct Preference Optimization for Language Model\n  Alignment","summary":"  We study the problem of aligning large language models (LLMs) with human\npreference data. Contrastive preference optimization has shown promising\nresults in aligning LLMs with available preference data by optimizing the\nimplicit reward associated with the policy. However, the contrastive objective\nfocuses mainly on the relative values of implicit rewards associated with two\nresponses while ignoring their actual values, resulting in suboptimal alignment\nwith human preferences. To address this limitation, we propose calibrated\ndirect preference optimization (Cal-DPO), a simple yet effective algorithm. We\nshow that substantial improvement in alignment with the given preferences can\nbe achieved simply by calibrating the implicit reward to ensure that the\nlearned implicit rewards are comparable in scale to the ground-truth rewards.\nWe demonstrate the theoretical advantages of Cal-DPO over existing approaches.\nThe results of our experiments on a variety of standard benchmarks show that\nCal-DPO remarkably improves off-the-shelf methods.\n","authors":["Teng Xiao","Yige Yuan","Huaisheng Zhu","Mingxiao Li","Vasant G Honavar"],"pdf_url":"https://arxiv.org/pdf/2412.14516v1.pdf","comment":"Accepted by NeurIPS 2024 Main"},{"id":"http://arxiv.org/abs/2412.14510v1","updated":"2024-12-19T04:18:51Z","published":"2024-12-19T04:18:51Z","title":"PA-RAG: RAG Alignment via Multi-Perspective Preference Optimization","summary":"  The emergence of Retrieval-augmented generation (RAG) has alleviated the\nissues of outdated and hallucinatory content in the generation of large\nlanguage models (LLMs), yet it still reveals numerous limitations. When a\ngeneral-purpose LLM serves as the RAG generator, it often suffers from\ninadequate response informativeness, response robustness, and citation quality.\nPast approaches to tackle these limitations, either by incorporating additional\nsteps beyond generating responses or optimizing the generator through\nsupervised fine-tuning (SFT), still failed to align with the RAG requirement\nthoroughly. Consequently, optimizing the RAG generator from multiple preference\nperspectives while maintaining its end-to-end LLM form remains a challenge. To\nbridge this gap, we propose Multiple Perspective Preference Alignment for\nRetrieval-Augmented Generation (PA-RAG), a method for optimizing the generator\nof RAG systems to align with RAG requirements comprehensively. Specifically, we\nconstruct high-quality instruction fine-tuning data and multi-perspective\npreference data by sampling varied quality responses from the generator across\ndifferent prompt documents quality scenarios. Subsequently, we optimize the\ngenerator using SFT and Direct Preference Optimization (DPO). Extensive\nexperiments conducted on four question-answer datasets across three LLMs\ndemonstrate that PA-RAG can significantly enhance the performance of RAG\ngenerators. Our code and datasets are available at\nhttps://github.com/wujwyi/PA-RAG.\n","authors":["Jiayi Wu","Hengyi Cai","Lingyong Yan","Hao Sun","Xiang Li","Shuaiqiang Wang","Dawei Yin","Ming Gao"],"pdf_url":"https://arxiv.org/pdf/2412.14510v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14501v1","updated":"2024-12-19T03:48:40Z","published":"2024-12-19T03:48:40Z","title":"Do Large Language Models Defend Inferentialist Semantics?: On the\n  Logical Expressivism and Anti-Representationalism of LLMs","summary":"  The philosophy of language, which has historically been developed through an\nanthropocentric lens, is now being forced to move towards post-anthropocentrism\ndue to the advent of large language models (LLMs) like ChatGPT (OpenAI), Claude\n(Anthropic), which are considered to possess linguistic abilities comparable to\nthose of humans. Traditionally, LLMs have been explained through distributional\nsemantics as their foundational semantics. However, recent research is\nexploring alternative foundational semantics beyond distributional semantics.\nThis paper proposes Robert Brandom's inferentialist semantics as an suitable\nfoundational semantics for LLMs, specifically focusing on the issue of\nlinguistic representationalism within this post-anthropocentric trend. Here, we\nshow that the anti-representationalism and logical expressivism of inferential\nsemantics, as well as quasi-compositionality, are useful in interpreting the\ncharacteristics and behaviors of LLMs. Further, we propose a \\emph{consensus\ntheory of truths} for LLMs. This paper argues that the characteristics of LLMs\nchallenge mainstream assumptions in philosophy of language, such as semantic\nexternalism and compositionality. We believe the argument in this paper leads\nto a re-evaluation of anti\\hyphen{}representationalist views of language,\npotentially leading to new developments in the philosophy of language.\n","authors":["Yuzuki Arai","Sho Tsugawa"],"pdf_url":"https://arxiv.org/pdf/2412.14501v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14480v1","updated":"2024-12-19T03:04:34Z","published":"2024-12-19T03:04:34Z","title":"GraphEQA: Using 3D Semantic Scene Graphs for Real-time Embodied Question\n  Answering","summary":"  In Embodied Question Answering (EQA), agents must explore and develop a\nsemantic understanding of an unseen environment in order to answer a situated\nquestion with confidence. This remains a challenging problem in robotics, due\nto the difficulties in obtaining useful semantic representations, updating\nthese representations online, and leveraging prior world knowledge for\nefficient exploration and planning. Aiming to address these limitations, we\npropose GraphEQA, a novel approach that utilizes real-time 3D metric-semantic\nscene graphs (3DSGs) and task relevant images as multi-modal memory for\ngrounding Vision-Language Models (VLMs) to perform EQA tasks in unseen\nenvironments. We employ a hierarchical planning approach that exploits the\nhierarchical nature of 3DSGs for structured planning and semantic-guided\nexploration. Through experiments in simulation on the HM-EQA dataset and in the\nreal world in home and office environments, we demonstrate that our method\noutperforms key baselines by completing EQA tasks with higher success rates and\nfewer planning steps.\n","authors":["Saumya Saxena","Blake Buchanan","Chris Paxton","Bingqing Chen","Narunas Vaskevicius","Luigi Palmieri","Jonathan Francis","Oliver Kroemer"],"pdf_url":"https://arxiv.org/pdf/2412.14480v1.pdf","comment":"Project website: https://saumyasaxena.github.io/grapheqa"},{"id":"http://arxiv.org/abs/2310.13008v2","updated":"2024-12-19T02:54:42Z","published":"2023-10-16T07:26:24Z","title":"DavIR: Data Selection via Implicit Reward for Large Language Models","summary":"  We introduce DavIR, a model-based data selection method for post-training\nLarge Language Models. DavIR generalizes Reducible Holdout Loss to core-set\nselection problem of causal language modeling, and quantifies the learnability\nof a given datum with respect to a pre-trained LLM based on relative reduction\nin loss during fine-tuning, a metric we show to be closely related to the\nimplicit reward model described in Direct Preference Optimization (DPO). We\nshow that 6% of Alpaca dataset selected with DavIR can steer both the LLaMA and\nGemma model family to produce superior performance compared to the same models\ntrained on the full 52K dataset. We also show that Alpaca dataset compressed\nwith DavIR can be combined with GSM8K dataset to effectively balance\nopen-domain freeform QA and mathematical reasoning capabilities. Finally, we\napply the DavIR objective to DPO and develop a normalized DavIR-DPO objective\nwhich improves alignment performance of Zephyr-7B-SFT model by 8% (relative) on\nAlpacaEval, compared against training on vanilla DPO objective.\n","authors":["Haotian Zhou","Tingkai Liu","Qianli Ma","Yufeng Zhang","Jianbo Yuan","Pengfei Liu","Yang You","Hongxia Yang"],"pdf_url":"https://arxiv.org/pdf/2310.13008v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14475v1","updated":"2024-12-19T02:49:55Z","published":"2024-12-19T02:49:55Z","title":"MegaPairs: Massive Data Synthesis For Universal Multimodal Retrieval","summary":"  Despite the rapidly growing demand for multimodal retrieval, progress in this\nfield remains severely constrained by a lack of training data. In this paper,\nwe introduce MegaPairs, a novel data synthesis method that leverages vision\nlanguage models (VLMs) and open-domain images, together with a massive\nsynthetic dataset generated from this method. Our empirical analysis shows that\nMegaPairs generates high-quality data, enabling the multimodal retriever to\nsignificantly outperform the baseline model trained on 70$\\times$ more data\nfrom existing datasets. Moreover, since MegaPairs solely relies on general\nimage corpora and open-source VLMs, it can be easily scaled up, enabling\ncontinuous improvements in retrieval performance. In this stage, we produced\nmore than 26 million training instances and trained several models of varying\nsizes using this data. These new models achieve state-of-the-art zero-shot\nperformance across 4 popular composed image retrieval (CIR) benchmarks and the\nhighest overall performance on the 36 datasets provided by MMEB. They also\ndemonstrate notable performance improvements with additional downstream\nfine-tuning. Our produced dataset, well-trained models, and data synthesis\npipeline will be made publicly available to facilitate the future development\nof this field.\n","authors":["Junjie Zhou","Zheng Liu","Ze Liu","Shitao Xiao","Yueze Wang","Bo Zhao","Chen Jason Zhang","Defu Lian","Yongping Xiong"],"pdf_url":"https://arxiv.org/pdf/2412.14475v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14471v1","updated":"2024-12-19T02:39:26Z","published":"2024-12-19T02:39:26Z","title":"Why We Build Local Large Language Models: An Observational Analysis from\n  35 Japanese and Multilingual LLMs","summary":"  Why do we build local large language models (LLMs)? What should a local LLM\nlearn from the target language? Which abilities can be transferred from other\nlanguages? Do language-specific scaling laws exist? To explore these research\nquestions, we evaluated 35 Japanese, English, and multilingual LLMs on 19\nevaluation benchmarks for Japanese and English, taking Japanese as a local\nlanguage. Adopting an observational approach, we analyzed correlations of\nbenchmark scores, and conducted principal component analysis (PCA) on the\nscores to derive \\textit{ability factors} of local LLMs. We found that training\non English text can improve the scores of academic subjects in Japanese\n(JMMLU). In addition, it is unnecessary to specifically train on Japanese text\nto enhance abilities for solving Japanese code generation, arithmetic\nreasoning, commonsense, and reading comprehension tasks. In contrast, training\non Japanese text could improve question-answering tasks about Japanese\nknowledge and English-Japanese translation, which indicates that abilities for\nsolving these two tasks can be regarded as \\textit{Japanese abilities} for\nLLMs. Furthermore, we confirmed that the Japanese abilities scale with the\ncomputational budget for Japanese text.\n","authors":["Koshiro Saito","Sakae Mizuki","Masanari Ohi","Taishi Nakamura","Taihei Shiotani","Koki Maeda","Youmi Ma","Kakeru Hattori","Kazuki Fujii","Takumi Okamoto","Shigeki Ishida","Hiroya Takamura","Rio Yokota","Naoaki Okazaki"],"pdf_url":"https://arxiv.org/pdf/2412.14471v1.pdf","comment":"Preprint. Under review"},{"id":"http://arxiv.org/abs/2407.21792v2","updated":"2024-12-19T02:39:01Z","published":"2024-07-31T17:59:24Z","title":"Safetywashing: Do AI Safety Benchmarks Actually Measure Safety Progress?","summary":"  As artificial intelligence systems grow more powerful, there has been\nincreasing interest in \"AI safety\" research to address emerging and future\nrisks. However, the field of AI safety remains poorly defined and\ninconsistently measured, leading to confusion about how researchers can\ncontribute. This lack of clarity is compounded by the unclear relationship\nbetween AI safety benchmarks and upstream general capabilities (e.g., general\nknowledge and reasoning). To address these issues, we conduct a comprehensive\nmeta-analysis of AI safety benchmarks, empirically analyzing their correlation\nwith general capabilities across dozens of models and providing a survey of\nexisting directions in AI safety. Our findings reveal that many safety\nbenchmarks highly correlate with both upstream model capabilities and training\ncompute, potentially enabling \"safetywashing\" -- where capability improvements\nare misrepresented as safety advancements. Based on these findings, we propose\nan empirical foundation for developing more meaningful safety metrics and\ndefine AI safety in a machine learning research context as a set of clearly\ndelineated research goals that are empirically separable from generic\ncapabilities advancements. In doing so, we aim to provide a more rigorous\nframework for AI safety research, advancing the science of safety evaluations\nand clarifying the path towards measurable progress.\n","authors":["Richard Ren","Steven Basart","Adam Khoja","Alice Gatti","Long Phan","Xuwang Yin","Mantas Mazeika","Alexander Pan","Gabriel Mukobi","Ryan H. Kim","Stephen Fitz","Dan Hendrycks"],"pdf_url":"https://arxiv.org/pdf/2407.21792v2.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.18118v3","updated":"2024-12-19T02:37:00Z","published":"2024-06-26T07:15:44Z","title":"SafeAligner: Safety Alignment against Jailbreak Attacks via Response\n  Disparity Guidance","summary":"  As the development of large language models (LLMs) rapidly advances, securing\nthese models effectively without compromising their utility has become a\npivotal area of research. However, current defense strategies against jailbreak\nattacks (i.e., efforts to bypass security protocols) often suffer from limited\nadaptability, restricted general capability, and high cost. To address these\nchallenges, we introduce SafeAligner, a methodology implemented at the decoding\nstage to fortify defenses against jailbreak attacks. We begin by developing two\nspecialized models: the Sentinel Model, which is trained to foster safety, and\nthe Intruder Model, designed to generate riskier responses. SafeAligner\nleverages the disparity in security levels between the responses from these\nmodels to differentiate between harmful and beneficial tokens, effectively\nguiding the safety alignment by altering the output token distribution of the\ntarget model. Extensive experiments show that SafeAligner can increase the\nlikelihood of beneficial tokens, while reducing the occurrence of harmful ones,\nthereby ensuring secure alignment with minimal loss to generality.\n","authors":["Caishuang Huang","Wanxu Zhao","Rui Zheng","Huijie Lv","Shihan Dou","Sixian Li","Xiao Wang","Enyu Zhou","Junjie Ye","Yuming Yang","Tao Gui","Qi Zhang","Xuanjing Huang"],"pdf_url":"https://arxiv.org/pdf/2406.18118v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14205v3","updated":"2024-12-19T02:35:48Z","published":"2024-05-23T06:03:19Z","title":"Agent Planning with World Knowledge Model","summary":"  Recent endeavors towards directly using large language models (LLMs) as agent\nmodels to execute interactive planning tasks have shown commendable results.\nDespite their achievements, however, they still struggle with brainless\ntrial-and-error in global planning and generating hallucinatory actions in\nlocal planning due to their poor understanding of the ``real'' physical world.\nImitating humans' mental world knowledge model which provides global prior\nknowledge before the task and maintains local dynamic knowledge during the\ntask, in this paper, we introduce parametric World Knowledge Model (WKM) to\nfacilitate agent planning. Concretely, we steer the agent model to\nself-synthesize knowledge from both expert and sampled trajectories. Then we\ndevelop WKM, providing prior task knowledge to guide the global planning and\ndynamic state knowledge to assist the local planning. Experimental results on\nthree complex real-world simulated datasets with three state-of-the-art\nopen-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our\nmethod can achieve superior performance compared to various strong baselines.\nBesides, we analyze to illustrate that our WKM can effectively alleviate the\nblind trial-and-error and hallucinatory action issues, providing strong support\nfor the agent's understanding of the world. Other interesting findings include:\n1) our instance-level task knowledge can generalize better to unseen tasks, 2)\nweak WKM can guide strong agent model planning, and 3) unified WKM training has\npromising potential for further development. The code is available at\nhttps://github.com/zjunlp/WKM.\n","authors":["Shuofei Qiao","Runnan Fang","Ningyu Zhang","Yuqi Zhu","Xiang Chen","Shumin Deng","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.14205v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.14470v1","updated":"2024-12-19T02:35:15Z","published":"2024-12-19T02:35:15Z","title":"Agent-SafetyBench: Evaluating the Safety of LLM Agents","summary":"  As large language models (LLMs) are increasingly deployed as agents, their\nintegration into interactive environments and tool use introduce new safety\nchallenges beyond those associated with the models themselves. However, the\nabsence of comprehensive benchmarks for evaluating agent safety presents a\nsignificant barrier to effective assessment and further improvement. In this\npaper, we introduce Agent-SafetyBench, a comprehensive benchmark designed to\nevaluate the safety of LLM agents. Agent-SafetyBench encompasses 349\ninteraction environments and 2,000 test cases, evaluating 8 categories of\nsafety risks and covering 10 common failure modes frequently encountered in\nunsafe interactions. Our evaluation of 16 popular LLM agents reveals a\nconcerning result: none of the agents achieves a safety score above 60%. This\nhighlights significant safety challenges in LLM agents and underscores the\nconsiderable need for improvement. Through quantitative analysis, we identify\ncritical failure modes and summarize two fundamental safety detects in current\nLLM agents: lack of robustness and lack of risk awareness. Furthermore, our\nfindings suggest that reliance on defense prompts alone is insufficient to\naddress these safety issues, emphasizing the need for more advanced and robust\nstrategies. We release Agent-SafetyBench at\n\\url{https://github.com/thu-coai/Agent-SafetyBench} to facilitate further\nresearch and innovation in agent safety evaluation and improvement.\n","authors":["Zhexin Zhang","Shiyao Cui","Yida Lu","Jingzhuo Zhou","Junxiao Yang","Hongning Wang","Minlie Huang"],"pdf_url":"https://arxiv.org/pdf/2412.14470v1.pdf","comment":"23 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.14461v1","updated":"2024-12-19T02:21:41Z","published":"2024-12-19T02:21:41Z","title":"From Human Annotation to LLMs: SILICON Annotation Workflow for\n  Management Research","summary":"  Unstructured text data annotation and analysis are fundamental to management\nresearch, often relying on human annotators through crowdsourcing platforms.\nWhile Large Language Models (LLMs) promise to provide a cost-effective and\nefficient alternative to human annotation, there lacks a systematic workflow\nthat evaluate when LLMs are suitable or how to proceed with LLM-based text\nannotation in a reproducible manner. This paper addresses this methodological\ngap by introducing the ``SILICON\" (\\textbf{S}ystematic \\textbf{I}nference with\n\\textbf{L}LMs for \\textbf{I}nformation \\textbf{C}lassificati\\textbf{o}n and\n\\textbf{N}otation) workflow. The workflow integrates established principles of\nhuman annotation with systematic prompt optimization and model selection,\naddressing challenges such as developing robust annotation guidelines,\nestablishing high-quality human baselines, optimizing prompts, and ensuring\nreproducibility across LLMs. We validate the SILICON workflow through seven\ncase studies covering common management research tasks, including business\nproposal evaluation, dialog intent and breakdown analysis, review attribute\ndetection. Our findings highlight the importance of validating annotation\nguideline agreement, the superiority of expert-developed human baselines over\ncrowdsourced ones, the iterative nature of prompt optimization, and the\nnecessity of testing multiple LLMs. Notably, we propose a regression-based\nmethodology to empirically compare LLM outputs across prompts and models. Our\nworkflow advances management research by establishing reproducible processes\nfor LLM-based annotation that maintain scientific rigor. We provide practical\nguidance for researchers to effectively navigate the evolving landscape of\ngenerative AI tools effectively while maintaining transparency and\nreproducibility.\n","authors":["Xiang Cheng","Raveesh Mayya","João Sedoc"],"pdf_url":"https://arxiv.org/pdf/2412.14461v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14768v3","updated":"2024-12-19T02:18:54Z","published":"2024-05-23T16:35:52Z","title":"WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of\n  Large Language Models","summary":"  Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.\n","authors":["Peng Wang","Zexi Li","Ningyu Zhang","Ziwen Xu","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.14768v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2406.13144v3","updated":"2024-12-19T02:14:09Z","published":"2024-06-19T01:37:10Z","title":"DialSim: A Real-Time Simulator for Evaluating Long-Term Multi-Party\n  Dialogue Understanding of Conversational Agents","summary":"  Recent advancements in Large Language Models (LLMs) have significantly\nenhanced the capabilities of conversational agents, making them applicable to\nvarious fields (e.g., education). Despite their progress, the evaluation of the\nagents often overlooks the complexities of real-world conversations, such as\nreal-time interactions, multi-party dialogues, and extended contextual\ndependencies. To bridge this gap, we introduce DialSim, a real-time dialogue\nsimulator. In this simulator, an agent is assigned the role of a character from\npopular TV shows, requiring it to respond to spontaneous questions using past\ndialogue information and to distinguish between known and unknown information.\nKey features of DialSim include assessing the agent's ability to respond within\na reasonable time limit, handling long-term multi-party dialogues, and\nevaluating performance under randomized questioning with LongDialQA, a novel,\nhigh-quality question-answering dataset. Our experiments using DialSim reveal\nthe strengths and weaknesses of the latest conversational agents, offering\nvaluable insights for future advancements in conversational AI. DialSim is\navailable at https://dialsim.github.io/.\n","authors":["Jiho Kim","Woosog Chay","Hyeonji Hwang","Daeun Kyung","Hyunseung Chung","Eunbyeol Cho","Yohan Jo","Edward Choi"],"pdf_url":"https://arxiv.org/pdf/2406.13144v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17969v3","updated":"2024-12-19T02:10:00Z","published":"2024-05-28T08:56:33Z","title":"Knowledge Circuits in Pretrained Transformers","summary":"  The remarkable capabilities of modern large language models are rooted in\ntheir vast repositories of knowledge encoded within their parameters, enabling\nthem to perceive the world and engage in reasoning. The inner workings of how\nthese models store knowledge have long been a subject of intense interest and\ninvestigation among researchers. To date, most studies have concentrated on\nisolated components within these models, such as the Multilayer Perceptrons and\nattention head. In this paper, we delve into the computation graph of the\nlanguage model to uncover the knowledge circuits that are instrumental in\narticulating specific knowledge. The experiments, conducted with GPT2 and\nTinyLLAMA, have allowed us to observe how certain information heads, relation\nheads, and Multilayer Perceptrons collaboratively encode knowledge within the\nmodel. Moreover, we evaluate the impact of current knowledge editing techniques\non these knowledge circuits, providing deeper insights into the functioning and\nconstraints of these editing methodologies. Finally, we utilize knowledge\ncircuits to analyze and interpret language model behaviors such as\nhallucinations and in-context learning. We believe the knowledge circuits hold\npotential for advancing our understanding of Transformers and guiding the\nimproved design of knowledge editing. Code and data are available in\nhttps://github.com/zjunlp/KnowledgeCircuits.\n","authors":["Yunzhi Yao","Ningyu Zhang","Zekun Xi","Mengru Wang","Ziwen Xu","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.17969v3.pdf","comment":"NeurIPS 2024, 26 pages"},{"id":"http://arxiv.org/abs/2412.14454v1","updated":"2024-12-19T02:09:59Z","published":"2024-12-19T02:09:59Z","title":"Are Longer Prompts Always Better? Prompt Selection in Large Language\n  Models for Recommendation Systems","summary":"  In large language models (LLM)-based recommendation systems (LLM-RSs),\naccurately predicting user preferences by leveraging the general knowledge of\nLLMs is possible without requiring extensive training data. By converting\nrecommendation tasks into natural language inputs called prompts, LLM-RSs can\nefficiently solve issues that have been difficult to address due to data\nscarcity but are crucial in applications such as cold-start and cross-domain\nproblems. However, when applying this in practice, selecting the prompt that\nmatches tasks and data is essential. Although numerous prompts have been\nproposed in LLM-RSs and representing the target user in prompts significantly\nimpacts recommendation accuracy, there are still no clear guidelines for\nselecting specific prompts.\n  In this paper, we categorize and analyze prompts from previous research to\nestablish practical prompt selection guidelines. Through 450 experiments with\n90 prompts and five real-world datasets, we examined the relationship between\nprompts and dataset characteristics in recommendation accuracy. We found that\nno single prompt consistently outperforms others; thus, selecting prompts on\nthe basis of dataset characteristics is crucial. Here, we propose a prompt\nselection method that achieves higher accuracy with minimal validation data.\nBecause increasing the number of prompts to explore raises costs, we also\nintroduce a cost-efficient strategy using high-performance and cost-efficient\nLLMs, significantly reducing exploration costs while maintaining high\nprediction accuracy. Our work offers valuable insights into the prompt\nselection, advancing accurate and efficient LLM-RSs.\n","authors":["Genki Kusano","Kosuke Akimoto","Kunihiro Takeoka"],"pdf_url":"https://arxiv.org/pdf/2412.14454v1.pdf","comment":"15 pages"},{"id":"http://arxiv.org/abs/2412.14436v1","updated":"2024-12-19T01:35:47Z","published":"2024-12-19T01:35:47Z","title":"ORBIT: Cost-Effective Dataset Curation for Large Language Model Domain\n  Adaptation with an Astronomy Case Study","summary":"  Recent advances in language modeling demonstrate the need for high-quality\ndomain-specific training data, especially for tasks that require specialized\nknowledge. General-purpose models, while versatile, often lack the depth needed\nfor expert-level tasks because of limited domain-specific information. Domain\nadaptation training can enhance these models, but it demands substantial,\nhigh-quality data. To address this, we propose ORBIT, a cost-efficient\nmethodology for curating massive, high-quality domain-specific datasets from\nnoisy web sources, tailored for training specialist large language models.\nUsing astronomy as a primary case study, we refined the 1.3T-token FineWeb-Edu\ndataset into a high-quality, 10B-token subset focused on astronomy. Fine-tuning\n\\textsc{LLaMA-3-8B} on a 1B-token astronomy subset improved performance on the\nMMLU astronomy benchmark from 69\\% to 76\\% and achieved top results on\nAstroBench, an astronomy-specific benchmark. Moreover, our model (Orbit-LLaMA)\noutperformed \\textsc{LLaMA-3-8B-base}, with GPT-4o evaluations preferring it in\n73\\% of cases across 1000 astronomy-specific questions. Additionally, we\nvalidated ORBIT's generalizability by applying it to law and medicine,\nachieving a significant improvement of data quality compared to an unfiltered\nbaseline. We open-source the ORBIT methodology, including the curated datasets,\nthe codebase, and the resulting model at\n\\href{https://github.com/ModeEric/ORBIT-Llama}{https://github.com/ModeEric/ORBIT-Llama}.\n","authors":["Eric Modesitt","Ke Yang","Spencer Hulsey","Chengxiang Zhai","Volodymyr Kindratenko"],"pdf_url":"https://arxiv.org/pdf/2412.14436v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14426v1","updated":"2024-12-19T00:41:40Z","published":"2024-12-19T00:41:40Z","title":"All-in-One Tuning and Structural Pruning for Domain-Specific LLMs","summary":"  Existing pruning techniques for large language models (LLMs) targeting\ndomain-specific applications typically follow a two-stage process: pruning the\npretrained general-purpose LLMs and then fine-tuning the pruned LLMs on\nspecific domains. However, the pruning decisions, derived from the pretrained\nweights, remain unchanged during fine-tuning, even if the weights have been\nupdated. Therefore, such a combination of the pruning decisions and the\nfinetuned weights may be suboptimal, leading to non-negligible performance\ndegradation. To address these limitations, we propose ATP: All-in-One Tuning\nand Structural Pruning, a unified one-stage structural pruning and fine-tuning\napproach that dynamically identifies the current optimal substructure\nthroughout the fine-tuning phase via a trainable pruning decision generator.\nMoreover, given the limited available data for domain-specific applications,\nLow-Rank Adaptation (LoRA) becomes a common technique to fine-tune the LLMs. In\nATP, we introduce LoRA-aware forward and sparsity regularization to ensure that\nthe substructures corresponding to the learned pruning decisions can be\ndirectly removed after the ATP process. ATP outperforms the state-of-the-art\ntwo-stage pruning methods on tasks in the legal and healthcare domains. More\nspecifically, ATP recovers up to 88% and 91% performance of the dense model\nwhen pruning 40% parameters of LLaMA2-7B and LLaMA3-8B models, respectively.\n","authors":["Lei Lu","Zhepeng Wang","Ruexue Bao","Mengbing Wang","Fangyi Li","Yawen Wu","Weiwen Jiang","Jie Xu","Yanzhi Wang","Shangqian Gao"],"pdf_url":"https://arxiv.org/pdf/2412.14426v1.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.15093v1","updated":"2024-12-19T17:43:27Z","published":"2024-12-19T17:43:27Z","title":"Nano-ESG: Extracting Corporate Sustainability Information from News\n  Articles","summary":"  Determining the sustainability impact of companies is a highly complex\nsubject which has garnered more and more attention over the past few years.\nToday, investors largely rely on sustainability-ratings from established\nrating-providers in order to analyze how responsibly a company acts. However,\nthose ratings have recently been criticized for being hard to understand and\nnearly impossible to reproduce.\n  An independent way to find out about the sustainability practices of\ncompanies lies in the rich landscape of news article data. In this paper, we\nexplore a different approach to identify key opportunities and challenges of\ncompanies in the sustainability domain. We present a novel dataset of more than\n840,000 news articles which were gathered for major German companies between\nJanuary 2023 and September 2024. By applying a mixture of Natural Language\nProcessing techniques, we first identify relevant articles, before summarizing\nthem and extracting their sustainability-related sentiment and aspect using\nLarge Language Models (LLMs). Furthermore, we conduct an evaluation of the\nobtained data and determine that the LLM-produced answers are accurate. We\nrelease both datasets at https://github.com/Bailefan/Nano-ESG.\n","authors":["Fabian Billert","Stefan Conrad"],"pdf_url":"https://arxiv.org/pdf/2412.15093v1.pdf","comment":"To be published at ECIR 2025. Preprint"},{"id":"http://arxiv.org/abs/2301.03767v2","updated":"2024-12-19T16:45:52Z","published":"2023-01-10T03:10:32Z","title":"Metric Compatible Training for Online Backfilling in Large-Scale\n  Retrieval","summary":"  Backfilling is the process of re-extracting all gallery embeddings from\nupgraded models in image retrieval systems. It inevitably requires a\nprohibitively large amount of computational cost and even entails the downtime\nof the service. Although backward-compatible learning sidesteps this challenge\nby tackling query-side representations, this leads to suboptimal solutions in\nprinciple because gallery embeddings cannot benefit from model upgrades. We\naddress this dilemma by introducing an online backfilling algorithm, which\nenables us to achieve a progressive performance improvement during the\nbackfilling process while not sacrificing the final performance of new model\nafter the completion of backfilling. To this end, we first propose a simple\ndistance rank merge technique for online backfilling. Then, we incorporate a\nreverse transformation module for more effective and efficient merging, which\nis further enhanced by adopting a metric-compatible contrastive learning\napproach. These two components help to make the distances of old and new models\ncompatible, resulting in desirable merge results during backfilling with no\nextra computational overhead. Extensive experiments show the effectiveness of\nour framework on four standard benchmarks in various settings.\n","authors":["Seonguk Seo","Mustafa Gokhan Uzunbas","Bohyung Han","Sara Cao","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2301.03767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15005v1","updated":"2024-12-19T16:20:42Z","published":"2024-12-19T16:20:42Z","title":"DisCo: Graph-Based Disentangled Contrastive Learning for Cold-Start\n  Cross-Domain Recommendation","summary":"  Recommender systems are widely used in various real-world applications, but\nthey often encounter the persistent challenge of the user cold-start problem.\nCross-domain recommendation (CDR), which leverages user interactions from one\ndomain to improve prediction performance in another, has emerged as a promising\nsolution. However, users with similar preferences in the source domain may\nexhibit different interests in the target domain. Therefore, directly\ntransferring embeddings may introduce irrelevant source-domain collaborative\ninformation. In this paper, we propose a novel graph-based disentangled\ncontrastive learning framework to capture fine-grained user intent and filter\nout irrelevant collaborative information, thereby avoiding negative transfer.\nSpecifically, for each domain, we use a multi-channel graph encoder to capture\ndiverse user intents. We then construct the affinity graph in the embedding\nspace and perform multi-step random walks to capture high-order user similarity\nrelationships. Treating one domain as the target, we propose a disentangled\nintent-wise contrastive learning approach, guided by user similarity, to refine\nthe bridging of user intents across domains. Extensive experiments on four\nbenchmark CDR datasets demonstrate that DisCo consistently outperforms existing\nstate-of-the-art baselines, thereby validating the effectiveness of both DisCo\nand its components.\n","authors":["Hourun Li","Yifan Wang","Zhiping Xiao","Jia Yang","Changling Zhou","Ming Zhang","Wei Ju"],"pdf_url":"https://arxiv.org/pdf/2412.15005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14978v1","updated":"2024-12-19T15:53:21Z","published":"2024-12-19T15:53:21Z","title":"Spectrum-based Modality Representation Fusion Graph Convolutional\n  Network for Multimodal Recommendation","summary":"  Incorporating multi-modal features as side information has recently become a\ntrend in recommender systems. To elucidate user-item preferences, recent\nstudies focus on fusing modalities via concatenation, element-wise sum, or\nattention mechanisms. Despite having notable success, existing approaches do\nnot account for the modality-specific noise encapsulated within each modality.\nAs a result, direct fusion of modalities will lead to the amplification of\ncross-modality noise. Moreover, the variation of noise that is unique within\neach modality results in noise alleviation and fusion being more challenging.\nIn this work, we propose a new Spectrum-based Modality Representation (SMORE)\nfusion graph recommender that aims to capture both uni-modal and fusion\npreferences while simultaneously suppressing modality noise. Specifically,\nSMORE projects the multi-modal features into the frequency domain and leverages\nthe spectral space for fusion. To reduce dynamic contamination that is unique\nto each modality, we introduce a filter to attenuate and suppress the modality\nnoise adaptively while capturing the universal modality patterns effectively.\nFurthermore, we explore the item latent structures by designing a new\nmulti-modal graph learning module to capture associative semantic correlations\nand universal fusion patterns among similar items. Finally, we formulate a new\nmodality-aware preference module, which infuses behavioral features and\nbalances the uni- and multi-modal features for precise preference modeling.\nThis empowers SMORE with the ability to infer both user modality-specific and\nfusion preferences more accurately. Experiments on three real-world datasets\nshow the efficacy of our proposed model. The source code for this work has been\nmade publicly available at https://github.com/kennethorq/SMORE.\n","authors":["Rongqing Kenneth Ong","Andy W. H. Khong"],"pdf_url":"https://arxiv.org/pdf/2412.14978v1.pdf","comment":"Accepted to ACM Web Search and Data Mining (WSDM) 2025"},{"id":"http://arxiv.org/abs/2412.14967v1","updated":"2024-12-19T15:45:06Z","published":"2024-12-19T15:45:06Z","title":"ECLIPSE: Contrastive Dimension Importance Estimation with\n  Pseudo-Irrelevance Feedback for Dense Retrieval","summary":"  Recent advances in Information Retrieval have leveraged high-dimensional\nembedding spaces to improve the retrieval of relevant documents. Moreover, the\nManifold Clustering Hypothesis suggests that despite these high-dimensional\nrepresentations, documents relevant to a query reside on a lower-dimensional,\nquery-dependent manifold. While this hypothesis has inspired new retrieval\nmethods, existing approaches still face challenges in effectively separating\nnon-relevant information from relevant signals. We propose a novel methodology\nthat addresses these limitations by leveraging information from both relevant\nand non-relevant documents. Our method, ECLIPSE, computes a centroid based on\nirrelevant documents as a reference to estimate noisy dimensions present in\nrelevant ones, enhancing retrieval performance. Extensive experiments on three\nin-domain and one out-of-domain benchmarks demonstrate an average improvement\nof up to 19.50% (resp. 22.35%) in mAP(AP) and 11.42% (resp. 13.10%) in nDCG@10\nw.r.t. the DIME-based baseline (resp. the baseline using all dimensions). Our\nresults pave the way for more robust, pseudo-irrelevance-based retrieval\nsystems in future IR research.\n","authors":["Giulio D'Erasmo","Giovanni Trappolini","Nicola Tonellotto","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2412.14967v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.00326v5","updated":"2024-12-19T15:07:38Z","published":"2023-12-01T03:44:54Z","title":"Agent-OM: Leveraging LLM Agents for Ontology Matching","summary":"  Ontology matching (OM) enables semantic interoperability between different\nontologies and resolves their conceptual heterogeneity by aligning related\nentities. OM systems currently have two prevailing design paradigms:\nconventional knowledge-based expert systems and newer machine learning-based\npredictive systems. While large language models (LLMs) and LLM agents have\nrevolutionised data engineering and have been applied creatively in many\ndomains, their potential for OM remains underexplored. This study introduces a\nnovel agent-powered LLM-based design paradigm for OM systems. With\nconsideration of several specific challenges in leveraging LLM agents for OM,\nwe propose a generic framework, namely Agent-OM (Agent for Ontology Matching),\nconsisting of two Siamese agents for retrieval and matching, with a set of\nsimple OM tools. Our framework is implemented in a proof-of-concept system.\nEvaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks\nover state-of-the-art OM systems show that our system can achieve results very\nclose to the long-standing best performance on simple OM tasks and can\nsignificantly improve the performance on complex and few-shot OM tasks.\n","authors":["Zhangcheng Qiang","Weiqing Wang","Kerry Taylor"],"pdf_url":"https://arxiv.org/pdf/2312.00326v5.pdf","comment":"19 pages, 13 figures, 4 tables"},{"id":"http://arxiv.org/abs/2402.00390v2","updated":"2024-12-19T14:28:19Z","published":"2024-02-01T07:22:52Z","title":"DNS-Rec: Data-aware Neural Architecture Search for Recommender Systems","summary":"  In the era of data proliferation, efficiently sifting through vast\ninformation to extract meaningful insights has become increasingly crucial.\nThis paper addresses the computational overhead and resource inefficiency\nprevalent in existing Sequential Recommender Systems (SRSs). We introduce an\ninnovative approach combining pruning methods with advanced model designs.\nFurthermore, we delve into resource-constrained Neural Architecture Search\n(NAS), an emerging technique in recommender systems, to optimize models in\nterms of FLOPs, latency, and energy consumption while maintaining or enhancing\naccuracy. Our principal contribution is the development of a Data-aware Neural\nArchitecture Search for Recommender System (DNS-Rec). DNS-Rec is specifically\ndesigned to tailor compact network architectures for attention-based SRS\nmodels, thereby ensuring accuracy retention. It incorporates data-aware gates\nto enhance the performance of the recommendation network by learning\ninformation from historical user-item interactions. Moreover, DNS-Rec employs a\ndynamic resource constraint strategy, stabilizing the search process and\nyielding more suitable architectural solutions. We demonstrate the\neffectiveness of our approach through rigorous experiments conducted on three\nbenchmark datasets, which highlight the superiority of DNS-Rec in SRSs. Our\nfindings set a new standard for future research in efficient and accurate\nrecommendation systems, marking a significant step forward in this rapidly\nevolving field.\n","authors":["Sheng Zhang","Maolin Wang","Yao Zhao","Chenyi Zhuang","Jinjie Gu","Ruocheng Guo","Xiangyu Zhao","Zijian Zhang","Hongzhi Yin"],"pdf_url":"https://arxiv.org/pdf/2402.00390v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14835v1","updated":"2024-12-19T13:25:39Z","published":"2024-12-19T13:25:39Z","title":"Progressive Multimodal Reasoning via Active Retrieval","summary":"  Multi-step multimodal reasoning tasks pose significant challenges for\nmultimodal large language models (MLLMs), and finding effective ways to enhance\ntheir performance in such scenarios remains an unresolved issue. In this paper,\nwe propose AR-MCTS, a universal framework designed to progressively improve the\nreasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo\nTree Search (MCTS). Our approach begins with the development of a unified\nretrieval module that retrieves key supporting insights for solving complex\nreasoning problems from a hybrid-modal retrieval corpus. To bridge the gap in\nautomated multimodal reasoning verification, we employ the MCTS algorithm\ncombined with an active retrieval mechanism, which enables the automatic\ngeneration of step-wise annotations. This strategy dynamically retrieves key\ninsights for each reasoning step, moving beyond traditional beam search\nsampling to improve the diversity and reliability of the reasoning space.\nAdditionally, we introduce a process reward model that aligns progressively to\nsupport the automatic verification of multimodal reasoning tasks. Experimental\nresults across three complex multimodal reasoning benchmarks confirm the\neffectiveness of the AR-MCTS framework in enhancing the performance of various\nmultimodal models. Further analysis demonstrates that AR-MCTS can optimize\nsampling diversity and accuracy, yielding reliable multimodal reasoning.\n","authors":["Guanting Dong","Chenghao Zhang","Mengjie Deng","Yutao Zhu","Zhicheng Dou","Ji-Rong Wen"],"pdf_url":"https://arxiv.org/pdf/2412.14835v1.pdf","comment":"Working in progress"},{"id":"http://arxiv.org/abs/2406.05666v9","updated":"2024-12-19T12:13:26Z","published":"2024-06-09T06:49:22Z","title":"Probability Distribution Learning and Its Application in Deep Learning","summary":"  This paper introduces a novel theoretical learning framework, termed\nprobability distribution learning (PD learning). Departing from the traditional\nstatistical learning framework, PD learning focuses on learning the underlying\nprobability distribution, which is modeled as a random variable within the\nprobability simplex. In this framework, the optimization objective is the\nlearning error, which quantifies the posterior expected discrepancy between the\nmodel's predicted distribution and the underlying true distribution, given\navailable sample data and prior knowledge. To optimize the learning error, this\npaper proposes the necessary conditions for loss functions, models, and\noptimization algorithms, ensuring that these conditions are met in real-world\nmachine learning scenarios. Based on these conditions, the non-convex\noptimization mechanism corresponding to model training can be theoretically\nresolved. Moreover, this paper provides model-dependent and model-independent\nbounds on learning error, offering new insights into the model's fitting and\ngeneralization capabilities. Furthermore, the paper applies the PD learning\nframework to elucidate the mechanisms by which various techniques, including\nrandom parameter initialization, over-parameterization, and dropout, influence\ndeep model training. Finally, the paper substantiates the key conclusions of\nthe proposed framework through experimental results.\n","authors":["Binchuan Qi"],"pdf_url":"https://arxiv.org/pdf/2406.05666v9.pdf","comment":"arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors"},{"id":"http://arxiv.org/abs/2411.04677v3","updated":"2024-12-19T12:08:31Z","published":"2024-11-07T13:03:21Z","title":"Lightning IR: Straightforward Fine-tuning and Inference of\n  Transformer-based Language Models for Information Retrieval","summary":"  A wide range of transformer-based language models have been proposed for\ninformation retrieval tasks. However, including transformer-based models in\nretrieval pipelines is often complex and requires substantial engineering\neffort. In this paper, we introduce Lightning IR, an easy-to-use PyTorch\nLightning-based framework for applying transformer-based language models in\nretrieval scenarios. Lightning IR provides a modular and extensible\narchitecture that supports all stages of a retrieval pipeline: from fine-tuning\nand indexing to searching and re-ranking. Designed to be scalable and\nreproducible, Lightning IR is available as open-source:\nhttps://github.com/webis-de/lightning-ir.\n","authors":["Ferdinand Schlatt","Maik Fröbe","Matthias Hagen"],"pdf_url":"https://arxiv.org/pdf/2411.04677v3.pdf","comment":"Accepted as a demo at WSDM'25"},{"id":"http://arxiv.org/abs/2412.11216v2","updated":"2024-12-19T08:32:20Z","published":"2024-12-15T15:13:14Z","title":"Distribution-Consistency-Guided Multi-modal Hashing","summary":"  Multi-modal hashing methods have gained popularity due to their fast speed\nand low storage requirements. Among them, the supervised methods demonstrate\nbetter performance by utilizing labels as supervisory signals compared with\nunsupervised methods. Currently, for almost all supervised multi-modal hashing\nmethods, there is a hidden assumption that training sets have no noisy labels.\nHowever, labels are often annotated incorrectly due to manual labeling in\nreal-world scenarios, which will greatly harm the retrieval performance. To\naddress this issue, we first discover a significant distribution consistency\npattern through experiments, i.e., the 1-0 distribution of the presence or\nabsence of each category in the label is consistent with the high-low\ndistribution of similarity scores of the hash codes relative to category\ncenters. Then, inspired by this pattern, we propose a novel\nDistribution-Consistency-Guided Multi-modal Hashing (DCGMH), which aims to\nfilter and reconstruct noisy labels to enhance retrieval performance.\nSpecifically, the proposed method first randomly initializes several category\ncenters, which are used to compute the high-low distribution of similarity\nscores; Noisy and clean labels are then separately filtered out via the\ndiscovered distribution consistency pattern to mitigate the impact of noisy\nlabels; Subsequently, a correction strategy, which is indirectly designed via\nthe distribution consistency pattern, is applied to the filtered noisy labels,\ncorrecting high-confidence ones while treating low-confidence ones as unlabeled\nfor unsupervised learning, thereby further enhancing the model's performance.\nExtensive experiments on three widely used datasets demonstrate the superiority\nof the proposed method compared to state-of-the-art baselines in multi-modal\nretrieval tasks. The code is available at\nhttps://github.com/LiuJinyu1229/DCGMH.\n","authors":["Jin-Yu Liu","Xian-Ling Mao","Tian-Yi Che","Rong-Cheng Tu"],"pdf_url":"https://arxiv.org/pdf/2412.11216v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.12470v2","updated":"2024-12-19T08:26:32Z","published":"2024-08-22T15:10:56Z","title":"DLCRec: A Novel Approach for Managing Diversity in LLM-Based Recommender\n  Systems","summary":"  The integration of Large Language Models (LLMs) into recommender systems has\nled to substantial performance improvements. However, this often comes at the\ncost of diminished recommendation diversity, which can negatively impact user\nsatisfaction. To address this issue, controllable recommendation has emerged as\na promising approach, allowing users to specify their preferences and receive\nrecommendations that meet their diverse needs. Despite its potential, existing\ncontrollable recommender systems frequently rely on simplistic mechanisms, such\nas a single prompt, to regulate diversity-an approach that falls short of\ncapturing the full complexity of user preferences. In response to these\nlimitations, we propose DLCRec, a novel framework designed to enable\nfine-grained control over diversity in LLM-based recommendations. Unlike\ntraditional methods, DLCRec adopts a fine-grained task decomposition strategy,\nbreaking down the recommendation process into three sequential sub-tasks: genre\nprediction, genre filling, and item prediction. These sub-tasks are trained\nindependently and inferred sequentially according to user-defined control\nnumbers, ensuring more precise control over diversity. Furthermore, the\nscarcity and uneven distribution of diversity-related user behavior data pose\nsignificant challenges for fine-tuning. To overcome these obstacles, we\nintroduce two data augmentation techniques that enhance the model's robustness\nto noisy and out-of-distribution data. These techniques expose the model to a\nbroader range of patterns, improving its adaptability in generating\nrecommendations with varying levels of diversity. Our extensive empirical\nevaluation demonstrates that DLCRec not only provides precise control over\ndiversity but also outperforms state-of-the-art baselines across multiple\nrecommendation scenarios.\n","authors":["Jiaju Chen","Chongming Gao","Shuai Yuan","Shuchang Liu","Qingpeng Cai","Peng Jiang"],"pdf_url":"https://arxiv.org/pdf/2408.12470v2.pdf","comment":"Accepted by WSDM 2025"},{"id":"http://arxiv.org/abs/2412.14574v1","updated":"2024-12-19T06:44:59Z","published":"2024-12-19T06:44:59Z","title":"Sliding Windows Are Not the End: Exploring Full Ranking with\n  Long-Context Large Language Models","summary":"  Large Language Models (LLMs) have shown exciting performance in listwise\npassage ranking. Due to the limited input length, existing methods often adopt\nthe sliding window strategy. Such a strategy, though effective, is inefficient\nas it involves repetitive and serialized processing, which usually re-evaluates\nrelevant passages multiple times. As a result, it incurs redundant API costs,\nwhich are proportional to the number of inference tokens. The development of\nlong-context LLMs enables the full ranking of all passages within a single\ninference, avoiding redundant API costs. In this paper, we conduct a\ncomprehensive study of long-context LLMs for ranking tasks in terms of\nefficiency and effectiveness. Surprisingly, our experiments reveal that full\nranking with long-context LLMs can deliver superior performance in the\nsupervised fine-tuning setting with a huge efficiency improvement. Furthermore,\nwe identify two limitations of fine-tuning the full ranking model based on\nexisting methods: (1) sliding window strategy fails to produce a full ranking\nlist as a training label, and (2) the language modeling loss cannot emphasize\ntop-ranked passage IDs in the label. To alleviate these issues, we propose a\nnew complete listwise label construction approach and a novel importance-aware\nlearning objective for full ranking. Experiments show the superior performance\nof our method over baselines. Our codes are available at\n\\url{https://github.com/8421BCD/fullrank}.\n","authors":["Wenhan Liu","Xinyu Ma","Yutao Zhu","Ziliang Zhao","Shuaiqiang Wang","Dawei Yin","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2412.14574v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2405.00287v2","updated":"2024-12-19T05:48:08Z","published":"2024-05-01T02:27:59Z","title":"SCONE: A Novel Stochastic Sampling to Generate Contrastive Views and\n  Hard Negative Samples for Recommendation","summary":"  Graph-based collaborative filtering (CF) has emerged as a promising approach\nin recommender systems. Despite its achievements, graph-based CF models face\nchallenges due to data sparsity and negative sampling. In this paper, we\npropose a novel Stochastic sampling for i) COntrastive views and ii) hard\nNEgative samples (SCONE) to overcome these issues. SCONE generates dynamic\naugmented views and diverse hard negative samples via a unified stochastic\nsampling approach based on score-based generative models. Our extensive\nexperiments on 6 benchmark datasets show that SCONE consistently outperforms\nstate-of-the-art baselines. SCONE shows efficacy in addressing user sparsity\nand item popularity issues, while enhancing performance for both cold-start\nusers and long-tail items. Furthermore, our approach improves the diversity of\nthe recommendation and the uniformity of the representations. The code is\navailable at https://github.com/jeongwhanchoi/SCONE.\n","authors":["Chaejeong Lee","Jeongwhan Choi","Hyowon Wi","Sung-Bae Cho","Noseong Park"],"pdf_url":"https://arxiv.org/pdf/2405.00287v2.pdf","comment":"Accepted to WSDM 2025. Chaejeong Lee and Jeongwhan Choi are co-first\n  authors with equal contributions"},{"id":"http://arxiv.org/abs/2412.14518v1","updated":"2024-12-19T04:33:22Z","published":"2024-12-19T04:33:22Z","title":"Efficient Self-Supervised Video Hashing with Selective State Spaces","summary":"  Self-supervised video hashing (SSVH) is a practical task in video indexing\nand retrieval. Although Transformers are predominant in SSVH for their\nimpressive temporal modeling capabilities, they often suffer from computational\nand memory inefficiencies. Drawing inspiration from Mamba, an advanced\nstate-space model, we explore its potential in SSVH to achieve a better balance\nbetween efficacy and efficiency. We introduce S5VH, a Mamba-based video hashing\nmodel with an improved self-supervised learning paradigm. Specifically, we\ndesign bidirectional Mamba layers for both the encoder and decoder, which are\neffective and efficient in capturing temporal relationships thanks to the\ndata-dependent selective scanning mechanism with linear complexity. In our\nlearning strategy, we transform global semantics in the feature space into\nsemantically consistent and discriminative hash centers, followed by a center\nalignment loss as a global learning signal. Our self-local-global (SLG)\nparadigm significantly improves learning efficiency, leading to faster and\nbetter convergence. Extensive experiments demonstrate S5VH's improvements over\nstate-of-the-art methods, superior transferability, and scalable advantages in\ninference efficiency. Code is available at\nhttps://github.com/gimpong/AAAI25-S5VH.\n","authors":["Jinpeng Wang","Niu Lian","Jun Li","Yuting Wang","Yan Feng","Bin Chen","Yongbing Zhang","Shu-Tao Xia"],"pdf_url":"https://arxiv.org/pdf/2412.14518v1.pdf","comment":"Accepted by AAAI'25. 9 pages, 5 figures, 2 tables"},{"id":"http://arxiv.org/abs/2412.14486v1","updated":"2024-12-19T03:19:18Z","published":"2024-12-19T03:19:18Z","title":"Moving Beyond LDA: A Comparison of Unsupervised Topic Modelling\n  Techniques for Qualitative Data Analysis of Online Communities","summary":"  Social media constitutes a rich and influential source of information for\nqualitative researchers. Although computational techniques like topic modelling\nassist with managing the volume and diversity of social media content,\nqualitative researcher's lack of programming expertise creates a significant\nbarrier to their adoption. In this paper we explore how BERTopic, an advanced\nLarge Language Model (LLM)-based topic modelling technique, can support\nqualitative data analysis of social media. We conducted interviews and hands-on\nevaluations in which qualitative researchers compared topics from three\nmodelling techniques: LDA, NMF, and BERTopic. BERTopic was favoured by 8 of 12\nparticipants for its ability to provide detailed, coherent clusters for deeper\nunderstanding and actionable insights. Participants also prioritised topic\nrelevance, logical organisation, and the capacity to reveal unexpected\nrelationships within the data. Our findings underscore the potential of\nLLM-based techniques for supporting qualitative analysis.\n","authors":["Amandeep Kaur","James R. Wallace"],"pdf_url":"https://arxiv.org/pdf/2412.14486v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14476v1","updated":"2024-12-19T02:57:02Z","published":"2024-12-19T02:57:02Z","title":"HEC-GCN: Hypergraph Enhanced Cascading Graph Convolution Network for\n  Multi-Behavior Recommendation","summary":"  Multi-behavior recommendation (MBR) has garnered growing attention recently\ndue to its ability to mitigate the sparsity issue by inferring user preferences\nfrom various auxiliary behaviors to improve predictions for the target\nbehavior. Although existing research on MBR has yielded impressive results,\nthey still face two major limitations. First, previous methods mainly focus on\nmodeling fine-grained interaction information between users and items under\neach behavior, which may suffer from sparsity issue. Second, existing models\nusually concentrate on exploiting dependencies between two consecutive\nbehaviors, leaving intra- and inter-behavior consistency largely unexplored. To\nthe end, we propose a novel approach named Hypergraph Enhanced Cascading Graph\nConvolution Network for multi-behavior recommendation (HEC-GCN). To be\nspecific, we first explore both fine- and coarse-grained correlations among\nusers or items of each behavior by simultaneously modeling the\nbehavior-specific interaction graph and its corresponding hypergraph in a\ncascaded manner. Then, we propose a behavior consistency-guided alignment\nstrategy that ensures consistent representations between the interaction graph\nand its associated hypergraph for each behavior, while also maintaining\nrepresentation consistency across different behaviors. Extensive experiments\nand analyses on three public benchmark datasets demonstrate that our proposed\napproach is consistently superior to previous state-of-the-art methods due to\nits capability to effectively attenuate the sparsity issue as well as preserve\nboth intra- and inter-behavior consistencies. The code is available at\nhttps://github.com/marqu22/HEC-GCN.git.\n","authors":["Yabo Yin","Xiaofei Zhu","Wenshan Wang","Yihao Zhang","Pengfei Wang","Yixing Fan","Jiafeng Guo"],"pdf_url":"https://arxiv.org/pdf/2412.14476v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14768v3","updated":"2024-12-19T02:18:54Z","published":"2024-05-23T16:35:52Z","title":"WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of\n  Large Language Models","summary":"  Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code is\navailable at https://github.com/zjunlp/EasyEdit.\n","authors":["Peng Wang","Zexi Li","Ningyu Zhang","Ziwen Xu","Yunzhi Yao","Yong Jiang","Pengjun Xie","Fei Huang","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.14768v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.14457v1","updated":"2024-12-19T02:17:35Z","published":"2024-12-19T02:17:35Z","title":"VISA: Retrieval Augmented Generation with Visual Source Attribution","summary":"  Generation with source attribution is important for enhancing the\nverifiability of retrieval-augmented generation (RAG) systems. However,\nexisting approaches in RAG primarily link generated content to document-level\nreferences, making it challenging for users to locate evidence among multiple\ncontent-rich retrieved documents. To address this challenge, we propose\nRetrieval-Augmented Generation with Visual Source Attribution (VISA), a novel\napproach that combines answer generation with visual source attribution.\nLeveraging large vision-language models (VLMs), VISA identifies the evidence\nand highlights the exact regions that support the generated answers with\nbounding boxes in the retrieved document screenshots. To evaluate its\neffectiveness, we curated two datasets: Wiki-VISA, based on crawled Wikipedia\nwebpage screenshots, and Paper-VISA, derived from PubLayNet and tailored to the\nmedical domain. Experimental results demonstrate the effectiveness of VISA for\nvisual source attribution on documents' original look, as well as highlighting\nthe challenges for improvement. Code, data, and model checkpoints will be\nreleased.\n","authors":["Xueguang Ma","Shengyao Zhuang","Bevan Koopman","Guido Zuccon","Wenhu Chen","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2412.14457v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.17969v3","updated":"2024-12-19T02:10:00Z","published":"2024-05-28T08:56:33Z","title":"Knowledge Circuits in Pretrained Transformers","summary":"  The remarkable capabilities of modern large language models are rooted in\ntheir vast repositories of knowledge encoded within their parameters, enabling\nthem to perceive the world and engage in reasoning. The inner workings of how\nthese models store knowledge have long been a subject of intense interest and\ninvestigation among researchers. To date, most studies have concentrated on\nisolated components within these models, such as the Multilayer Perceptrons and\nattention head. In this paper, we delve into the computation graph of the\nlanguage model to uncover the knowledge circuits that are instrumental in\narticulating specific knowledge. The experiments, conducted with GPT2 and\nTinyLLAMA, have allowed us to observe how certain information heads, relation\nheads, and Multilayer Perceptrons collaboratively encode knowledge within the\nmodel. Moreover, we evaluate the impact of current knowledge editing techniques\non these knowledge circuits, providing deeper insights into the functioning and\nconstraints of these editing methodologies. Finally, we utilize knowledge\ncircuits to analyze and interpret language model behaviors such as\nhallucinations and in-context learning. We believe the knowledge circuits hold\npotential for advancing our understanding of Transformers and guiding the\nimproved design of knowledge editing. Code and data are available in\nhttps://github.com/zjunlp/KnowledgeCircuits.\n","authors":["Yunzhi Yao","Ningyu Zhang","Zekun Xi","Mengru Wang","Ziwen Xu","Shumin Deng","Huajun Chen"],"pdf_url":"https://arxiv.org/pdf/2405.17969v3.pdf","comment":"NeurIPS 2024, 26 pages"},{"id":"http://arxiv.org/abs/2412.14454v1","updated":"2024-12-19T02:09:59Z","published":"2024-12-19T02:09:59Z","title":"Are Longer Prompts Always Better? Prompt Selection in Large Language\n  Models for Recommendation Systems","summary":"  In large language models (LLM)-based recommendation systems (LLM-RSs),\naccurately predicting user preferences by leveraging the general knowledge of\nLLMs is possible without requiring extensive training data. By converting\nrecommendation tasks into natural language inputs called prompts, LLM-RSs can\nefficiently solve issues that have been difficult to address due to data\nscarcity but are crucial in applications such as cold-start and cross-domain\nproblems. However, when applying this in practice, selecting the prompt that\nmatches tasks and data is essential. Although numerous prompts have been\nproposed in LLM-RSs and representing the target user in prompts significantly\nimpacts recommendation accuracy, there are still no clear guidelines for\nselecting specific prompts.\n  In this paper, we categorize and analyze prompts from previous research to\nestablish practical prompt selection guidelines. Through 450 experiments with\n90 prompts and five real-world datasets, we examined the relationship between\nprompts and dataset characteristics in recommendation accuracy. We found that\nno single prompt consistently outperforms others; thus, selecting prompts on\nthe basis of dataset characteristics is crucial. Here, we propose a prompt\nselection method that achieves higher accuracy with minimal validation data.\nBecause increasing the number of prompts to explore raises costs, we also\nintroduce a cost-efficient strategy using high-performance and cost-efficient\nLLMs, significantly reducing exploration costs while maintaining high\nprediction accuracy. Our work offers valuable insights into the prompt\nselection, advancing accurate and efficient LLM-RSs.\n","authors":["Genki Kusano","Kosuke Akimoto","Kunihiro Takeoka"],"pdf_url":"https://arxiv.org/pdf/2412.14454v1.pdf","comment":"15 pages"}],"Machine Learning":[{"id":"http://arxiv.org/abs/2412.15212v1","updated":"2024-12-19T18:59:51Z","published":"2024-12-19T18:59:51Z","title":"Scaling 4D Representations","summary":"  Scaling has not yet been convincingly demonstrated for pure self-supervised\nlearning from video. However, prior work has focused evaluations on\nsemantic-related tasks $\\unicode{x2013}$ action classification, ImageNet\nclassification, etc. In this paper we focus on evaluating self-supervised\nlearning on non-semantic vision tasks that are more spatial (3D) and temporal\n(+1D = 4D), such as camera pose estimation, point and object tracking, and\ndepth estimation. We show that by learning from very large video datasets,\nmasked auto-encoding (MAE) with transformer video models actually scales,\nconsistently improving performance on these 4D tasks, as model size increases\nfrom 20M all the way to the largest by far reported self-supervised video model\n$\\unicode{x2013}$ 22B parameters. Rigorous apples-to-apples comparison with\nmany recent image and video models demonstrates the benefits of scaling 4D\nrepresentations.\n","authors":["João Carreira","Dilara Gokay","Michael King","Chuhan Zhang","Ignacio Rocco","Aravindh Mahendran","Thomas Albert Keck","Joseph Heyward","Skanda Koppula","Etienne Pot","Goker Erdogan","Yana Hasson","Yi Yang","Klaus Greff","Guillaume Le Moing","Sjoerd van Steenkiste","Daniel Zoran","Drew A. Hudson","Pedro Vélez","Luisa Polanía","Luke Friedman","Chris Duvarney","Ross Goroshin","Kelsey Allen","Jacob Walker","Rishabh Kabra","Eric Aboussouan","Jennifer Sun","Thomas Kipf","Carl Doersch","Viorica Pătrăucean","Dima Damen","Pauline Luc","Mehdi S. M. Sajjadi","Andrew Zisserman"],"pdf_url":"https://arxiv.org/pdf/2412.15212v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15209v1","updated":"2024-12-19T18:59:44Z","published":"2024-12-19T18:59:44Z","title":"PRIMA: Multi-Image Vision-Language Models for Reasoning Segmentation","summary":"  Despite significant advancements in Large Vision-Language Models (LVLMs),\nexisting pixel-grounding models operate on single-image settings, limiting\ntheir ability to perform detailed, fine-grained comparisons across multiple\nimages. Conversely, current multi-image understanding models lack pixel-level\ngrounding. Our work addresses this gap by introducing the task of multi-image\npixel-grounded reasoning segmentation, and PRIMA, a novel LVLM that integrates\npixel-level grounding with robust multi-image reasoning capabilities to produce\ncontextually rich, pixel-grounded explanations. Central to PRIMA is an\nefficient vision module that queries fine-grained visual representations across\nmultiple images, reducing TFLOPs by $25.3\\%$. To support training and\nevaluation, we curate $M^4Seg$, a new reasoning segmentation benchmark\nconsisting of $\\sim$224K question-answer pairs that require fine-grained visual\nunderstanding across multiple images. Experimental results demonstrate PRIMA\noutperforms state-of-the-art baselines.\n","authors":["Muntasir Wahed","Kiet A. Nguyen","Adheesh Sunil Juvekar","Xinzhuo Li","Xiaona Zhou","Vedant Shah","Tianjiao Yu","Pinar Yanardag","Ismini Lourentzou"],"pdf_url":"https://arxiv.org/pdf/2412.15209v1.pdf","comment":"Project page: https://plan-lab.github.io/prima"},{"id":"http://arxiv.org/abs/2412.15208v1","updated":"2024-12-19T18:59:40Z","published":"2024-12-19T18:59:40Z","title":"OpenEMMA: Open-Source Multimodal Model for End-to-End Autonomous Driving","summary":"  Since the advent of Multimodal Large Language Models (MLLMs), they have made\na significant impact across a wide range of real-world applications,\nparticularly in Autonomous Driving (AD). Their ability to process complex\nvisual data and reason about intricate driving scenarios has paved the way for\na new paradigm in end-to-end AD systems. However, the progress of developing\nend-to-end models for AD has been slow, as existing fine-tuning methods demand\nsubstantial resources, including extensive computational power, large-scale\ndatasets, and significant funding. Drawing inspiration from recent advancements\nin inference computing, we propose OpenEMMA, an open-source end-to-end\nframework based on MLLMs. By incorporating the Chain-of-Thought reasoning\nprocess, OpenEMMA achieves significant improvements compared to the baseline\nwhen leveraging a diverse range of MLLMs. Furthermore, OpenEMMA demonstrates\neffectiveness, generalizability, and robustness across a variety of challenging\ndriving scenarios, offering a more efficient and effective approach to\nautonomous driving. We release all the codes in\nhttps://github.com/taco-group/OpenEMMA.\n","authors":["Shuo Xing","Chengyuan Qian","Yuping Wang","Hongyuan Hua","Kexin Tian","Yang Zhou","Zhengzhong Tu"],"pdf_url":"https://arxiv.org/pdf/2412.15208v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15206v1","updated":"2024-12-19T18:59:33Z","published":"2024-12-19T18:59:33Z","title":"AutoTrust: Benchmarking Trustworthiness in Large Vision Language Models\n  for Autonomous Driving","summary":"  Recent advancements in large vision language models (VLMs) tailored for\nautonomous driving (AD) have shown strong scene understanding and reasoning\ncapabilities, making them undeniable candidates for end-to-end driving systems.\nHowever, limited work exists on studying the trustworthiness of DriveVLMs -- a\ncritical factor that directly impacts public transportation safety. In this\npaper, we introduce AutoTrust, a comprehensive trustworthiness benchmark for\nlarge vision-language models in autonomous driving (DriveVLMs), considering\ndiverse perspectives -- including trustfulness, safety, robustness, privacy,\nand fairness. We constructed the largest visual question-answering dataset for\ninvestigating trustworthiness issues in driving scenarios, comprising over 10k\nunique scenes and 18k queries. We evaluated six publicly available VLMs,\nspanning from generalist to specialist, from open-source to commercial models.\nOur exhaustive evaluations have unveiled previously undiscovered\nvulnerabilities of DriveVLMs to trustworthiness threats. Specifically, we found\nthat the general VLMs like LLaVA-v1.6 and GPT-4o-mini surprisingly outperform\nspecialized models fine-tuned for driving in terms of overall trustworthiness.\nDriveVLMs like DriveLM-Agent are particularly vulnerable to disclosing\nsensitive information. Additionally, both generalist and specialist VLMs remain\nsusceptible to adversarial attacks and struggle to ensure unbiased\ndecision-making across diverse environments and populations. Our findings call\nfor immediate and decisive action to address the trustworthiness of DriveVLMs\n-- an issue of critical importance to public safety and the welfare of all\ncitizens relying on autonomous transportation systems. Our benchmark is\npublicly available at \\url{https://github.com/taco-group/AutoTrust}, and the\nleaderboard is released at \\url{https://taco-group.github.io/AutoTrust/}.\n","authors":["Shuo Xing","Hongyuan Hua","Xiangbo Gao","Shenzhe Zhu","Renjie Li","Kexin Tian","Xiaopeng Li","Heng Huang","Tianbao Yang","Zhangyang Wang","Yang Zhou","Huaxiu Yao","Zhengzhong Tu"],"pdf_url":"https://arxiv.org/pdf/2412.15206v1.pdf","comment":"55 pages, 14 figures"},{"id":"http://arxiv.org/abs/2412.15199v1","updated":"2024-12-19T18:58:36Z","published":"2024-12-19T18:58:36Z","title":"LiDAR-RT: Gaussian-based Ray Tracing for Dynamic LiDAR Re-simulation","summary":"  This paper targets the challenge of real-time LiDAR re-simulation in dynamic\ndriving scenarios. Recent approaches utilize neural radiance fields combined\nwith the physical modeling of LiDAR sensors to achieve high-fidelity\nre-simulation results. Unfortunately, these methods face limitations due to\nhigh computational demands in large-scale scenes and cannot perform real-time\nLiDAR rendering. To overcome these constraints, we propose LiDAR-RT, a novel\nframework that supports real-time, physically accurate LiDAR re-simulation for\ndriving scenes. Our primary contribution is the development of an efficient and\neffective rendering pipeline, which integrates Gaussian primitives and\nhardware-accelerated ray tracing technology. Specifically, we model the\nphysical properties of LiDAR sensors using Gaussian primitives with learnable\nparameters and incorporate scene graphs to handle scene dynamics. Building upon\nthis scene representation, our framework first constructs a bounding volume\nhierarchy (BVH), then casts rays for each pixel and generates novel LiDAR views\nthrough a differentiable rendering algorithm. Importantly, our framework\nsupports realistic rendering with flexible scene editing operations and various\nsensor configurations. Extensive experiments across multiple public benchmarks\ndemonstrate that our method outperforms state-of-the-art methods in terms of\nrendering quality and efficiency. Our project page is at\nhttps://zju3dv.github.io/lidar-rt.\n","authors":["Chenxu Zhou","Lvchang Fu","Sida Peng","Yunzhi Yan","Zhanhua Zhang","Yong Chen","Jiazhi Xia","Xiaowei Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.15199v1.pdf","comment":"Project page: https://zju3dv.github.io/lidar-rt"},{"id":"http://arxiv.org/abs/2412.15195v1","updated":"2024-12-19T18:58:14Z","published":"2024-12-19T18:58:14Z","title":"Preventing Local Pitfalls in Vector Quantization via Optimal Transport","summary":"  Vector-quantized networks (VQNs) have exhibited remarkable performance across\nvarious tasks, yet they are prone to training instability, which complicates\nthe training process due to the necessity for techniques such as subtle\ninitialization and model distillation. In this study, we identify the local\nminima issue as the primary cause of this instability. To address this, we\nintegrate an optimal transport method in place of the nearest neighbor search\nto achieve a more globally informed assignment. We introduce OptVQ, a novel\nvector quantization method that employs the Sinkhorn algorithm to optimize the\noptimal transport problem, thereby enhancing the stability and efficiency of\nthe training process. To mitigate the influence of diverse data distributions\non the Sinkhorn algorithm, we implement a straightforward yet effective\nnormalization strategy. Our comprehensive experiments on image reconstruction\ntasks demonstrate that OptVQ achieves 100% codebook utilization and surpasses\ncurrent state-of-the-art VQNs in reconstruction quality.\n","authors":["Borui Zhang","Wenzhao Zheng","Jie Zhou","Jiwen Lu"],"pdf_url":"https://arxiv.org/pdf/2412.15195v1.pdf","comment":"Code is available at https://github.com/zbr17/OptVQ"},{"id":"http://arxiv.org/abs/2412.15191v1","updated":"2024-12-19T18:57:21Z","published":"2024-12-19T18:57:21Z","title":"AV-Link: Temporally-Aligned Diffusion Features for Cross-Modal\n  Audio-Video Generation","summary":"  We propose AV-Link, a unified framework for Video-to-Audio and Audio-to-Video\ngeneration that leverages the activations of frozen video and audio diffusion\nmodels for temporally-aligned cross-modal conditioning. The key to our\nframework is a Fusion Block that enables bidirectional information exchange\nbetween our backbone video and audio diffusion models through a\ntemporally-aligned self attention operation. Unlike prior work that uses\nfeature extractors pretrained for other tasks for the conditioning signal,\nAV-Link can directly leverage features obtained by the complementary modality\nin a single framework i.e. video features to generate audio, or audio features\nto generate video. We extensively evaluate our design choices and demonstrate\nthe ability of our method to achieve synchronized and high-quality audiovisual\ncontent, showcasing its potential for applications in immersive media\ngeneration. Project Page: snap-research.github.io/AVLink/\n","authors":["Moayed Haji-Ali","Willi Menapace","Aliaksandr Siarohin","Ivan Skorokhodov","Alper Canberk","Kwot Sin Lee","Vicente Ordonez","Sergey Tulyakov"],"pdf_url":"https://arxiv.org/pdf/2412.15191v1.pdf","comment":"Project Page: snap-research.github.io/AVLink/"},{"id":"http://arxiv.org/abs/2412.15188v1","updated":"2024-12-19T18:56:24Z","published":"2024-12-19T18:56:24Z","title":"LlamaFusion: Adapting Pretrained Language Models for Multimodal\n  Generation","summary":"  We present LlamaFusion, a framework for empowering pretrained text-only large\nlanguage models (LLMs) with multimodal generative capabilities, enabling them\nto understand and generate both text and images in arbitrary sequences.\nLlamaFusion leverages existing Llama-3's weights for processing texts\nautoregressively while introducing additional and parallel transformer modules\nfor processing images with diffusion. During training, the data from each\nmodality is routed to its dedicated modules: modality-specific feedforward\nlayers, query-key-value projections, and normalization layers process each\nmodality independently, while the shared self-attention layers allow\ninteractions across text and image features. By freezing the text-specific\nmodules and only training the image-specific modules, LlamaFusion preserves the\nlanguage capabilities of text-only LLMs while developing strong visual\nunderstanding and generation abilities. Compared to methods that pretrain\nmultimodal generative models from scratch, our experiments demonstrate that,\nLlamaFusion improves image understanding by 20% and image generation by 3.6%\nusing only 50% of the FLOPs while maintaining Llama-3's language capabilities.\nWe also demonstrate that this framework can adapt existing vision-language\nmodels with multimodal generation ability. Overall, this framework not only\nleverages existing computational investments in text-only LLMs but also enables\nthe parallel development of language and vision capabilities, presenting a\npromising direction for efficient multimodal model development.\n","authors":["Weijia Shi","Xiaochuang Han","Chunting Zhou","Weixin Liang","Xi Victoria Lin","Luke Zettlemoyer","Lili Yu"],"pdf_url":"https://arxiv.org/pdf/2412.15188v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15184v1","updated":"2024-12-19T18:55:17Z","published":"2024-12-19T18:55:17Z","title":"Data for Mathematical Copilots: Better Ways of Presenting Proofs for\n  Machine Learning","summary":"  The suite of datasets commonly used to train and evaluate the mathematical\ncapabilities of AI-based mathematical copilots (primarily large language\nmodels) exhibit several shortcomings. These limitations include a restricted\nscope of mathematical complexity, typically not exceeding lower\nundergraduate-level mathematics, binary rating protocols and other issues,\nwhich makes comprehensive proof-based evaluation suites difficult. We\nsystematically explore these limitations and contend that enhancing the\ncapabilities of large language models, or any forthcoming advancements in\nAI-based mathematical assistants (copilots or \"thought partners\"), necessitates\na paradigm shift in the design of mathematical datasets and the evaluation\ncriteria of mathematical ability: It is necessary to move away from\nresult-based datasets (theorem statement to theorem proof) and convert the rich\nfacets of mathematical research practice to data LLMs can train on. Examples of\nthese are mathematical workflows (sequences of atomic, potentially\nsubfield-dependent tasks that are often performed when creating new\nmathematics), which are an important part of the proof-discovery process.\nAdditionally, we advocate for mathematical dataset developers to consider the\nconcept of \"motivated proof\", introduced by G. P\\'olya in 1949, which can serve\nas a blueprint for datasets that offer a better proof learning signal,\nalleviating some of the mentioned limitations. Lastly, we introduce math\ndatasheets for datasets, extending the general, dataset-agnostic variants of\ndatasheets: We provide a questionnaire designed specifically for math datasets\nthat we urge dataset creators to include with their datasets. This will make\ncreators aware of potential limitations of their datasets while at the same\ntime making it easy for readers to assess it from the point of view of training\nand evaluating mathematical copilots.\n","authors":["Simon Frieder","Jonas Bayer","Katherine M. Collins","Julius Berner","Jacob Loader","András Juhász","Fabian Ruehle","Sean Welleck","Gabriel Poesia","Ryan-Rhys Griffiths","Adrian Weller","Anirudh Goyal","Thomas Lukasiewicz","Timothy Gowers"],"pdf_url":"https://arxiv.org/pdf/2412.15184v1.pdf","comment":"40 pages"},{"id":"http://arxiv.org/abs/2412.15182v1","updated":"2024-12-19T18:54:06Z","published":"2024-12-19T18:54:06Z","title":"STRAP: Robot Sub-Trajectory Retrieval for Augmented Policy Learning","summary":"  Robot learning is witnessing a significant increase in the size, diversity,\nand complexity of pre-collected datasets, mirroring trends in domains such as\nnatural language processing and computer vision. Many robot learning methods\ntreat such datasets as multi-task expert data and learn a multi-task,\ngeneralist policy by training broadly across them. Notably, while these\ngeneralist policies can improve the average performance across many tasks, the\nperformance of generalist policies on any one task is often suboptimal due to\nnegative transfer between partitions of the data, compared to task-specific\nspecialist policies. In this work, we argue for the paradigm of training\npolicies during deployment given the scenarios they encounter: rather than\ndeploying pre-trained policies to unseen problems in a zero-shot manner, we\nnon-parametrically retrieve and train models directly on relevant data at test\ntime. Furthermore, we show that many robotics tasks share considerable amounts\nof low-level behaviors and that retrieval at the \"sub\"-trajectory granularity\nenables significantly improved data utilization, generalization, and robustness\nin adapting policies to novel problems. In contrast, existing full-trajectory\nretrieval methods tend to underutilize the data and miss out on shared\ncross-task content. This work proposes STRAP, a technique for leveraging\npre-trained vision foundation models and dynamic time warping to retrieve\nsub-sequences of trajectories from large training corpora in a robust fashion.\nSTRAP outperforms both prior retrieval algorithms and multi-task learning\nmethods in simulated and real experiments, showing the ability to scale to much\nlarger offline datasets in the real world as well as the ability to learn\nrobust control policies with just a handful of real-world demonstrations.\n","authors":["Marius Memmel","Jacob Berg","Bingqing Chen","Abhishek Gupta","Jonathan Francis"],"pdf_url":"https://arxiv.org/pdf/2412.15182v1.pdf","comment":"Project website at https://weirdlabuw.github.io/strap/"},{"id":"http://arxiv.org/abs/2412.15178v1","updated":"2024-12-19T18:52:05Z","published":"2024-12-19T18:52:05Z","title":"HPC-Coder-V2: Studying Code LLMs Across Low-Resource Parallel Languages","summary":"  Large Language Model (LLM) based coding tools have been tremendously\nsuccessful as software development assistants, yet they are often designed for\ngeneral purpose programming tasks and perform poorly for more specialized\ndomains such as high performance computing. Creating specialized models and\ntools for these domains is crucial towards gaining the benefits of LLMs in\nareas such as HPC. While previous work has explored HPC-specific models, LLMs\nstill struggle to generate parallel code and it is not at all clear what\nhurdles are still holding back these LLMs and what must be done to overcome\nthem. In this work, we conduct an in-depth study along the many axes of\nfine-tuning a specialized HPC LLM in order to better understand the challenges.\nBased on our findings we fine-tune and evaluate a specialized HPC LLM that is\nshown to be the best performing open-source code LLM for parallel code\ngeneration to date.\n","authors":["Aman Chaturvedi","Daniel Nichols","Siddharth Singh","Abhinav Bhatele"],"pdf_url":"https://arxiv.org/pdf/2412.15178v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15176v1","updated":"2024-12-19T18:51:06Z","published":"2024-12-19T18:51:06Z","title":"Rethinking Uncertainty Estimation in Natural Language Generation","summary":"  Large Language Models (LLMs) are increasingly employed in real-world\napplications, driving the need to evaluate the trustworthiness of their\ngenerated text. To this end, reliable uncertainty estimation is essential.\nSince current LLMs generate text autoregressively through a stochastic process,\nthe same prompt can lead to varying outputs. Consequently, leading uncertainty\nestimation methods generate and analyze multiple output sequences to determine\nthe LLM's uncertainty. However, generating output sequences is computationally\nexpensive, making these methods impractical at scale. In this work, we inspect\nthe theoretical foundations of the leading methods and explore new directions\nto enhance their computational efficiency. Building on the framework of proper\nscoring rules, we find that the negative log-likelihood of the most likely\noutput sequence constitutes a theoretically grounded uncertainty measure. To\napproximate this alternative measure, we propose G-NLL, which has the advantage\nof being obtained using only a single output sequence generated by greedy\ndecoding. This makes uncertainty estimation more efficient and straightforward,\nwhile preserving theoretical rigor. Empirical results demonstrate that G-NLL\nachieves state-of-the-art performance across various LLMs and tasks. Our work\nlays the foundation for efficient and reliable uncertainty estimation in\nnatural language generation, challenging the necessity of more computationally\ninvolved methods currently leading the field.\n","authors":["Lukas Aichberger","Kajetan Schweighofer","Sepp Hochreiter"],"pdf_url":"https://arxiv.org/pdf/2412.15176v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18479v2","updated":"2024-12-19T18:49:00Z","published":"2024-11-27T16:22:33Z","title":"SoK: Watermarking for AI-Generated Content","summary":"  As the outputs of generative AI (GenAI) techniques improve in quality, it\nbecomes increasingly challenging to distinguish them from human-created\ncontent. Watermarking schemes are a promising approach to address the problem\nof distinguishing between AI and human-generated content. These schemes embed\nhidden signals within AI-generated content to enable reliable detection. While\nwatermarking is not a silver bullet for addressing all risks associated with\nGenAI, it can play a crucial role in enhancing AI safety and trustworthiness by\ncombating misinformation and deception. This paper presents a comprehensive\noverview of watermarking techniques for GenAI, beginning with the need for\nwatermarking from historical and regulatory perspectives. We formalize the\ndefinitions and desired properties of watermarking schemes and examine the key\nobjectives and threat models for existing approaches. Practical evaluation\nstrategies are also explored, providing insights into the development of robust\nwatermarking techniques capable of resisting various attacks. Additionally, we\nreview recent representative works, highlight open challenges, and discuss\npotential directions for this emerging field. By offering a thorough\nunderstanding of watermarking in GenAI, this work aims to guide researchers in\nadvancing watermarking methods and applications, and support policymakers in\naddressing the broader implications of GenAI.\n","authors":["Xuandong Zhao","Sam Gunn","Miranda Christ","Jaiden Fairoze","Andres Fabrega","Nicholas Carlini","Sanjam Garg","Sanghyun Hong","Milad Nasr","Florian Tramer","Somesh Jha","Lei Li","Yu-Xiang Wang","Dawn Song"],"pdf_url":"https://arxiv.org/pdf/2411.18479v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.06289v3","updated":"2024-12-19T18:47:54Z","published":"2024-12-09T08:24:11Z","title":"S$^{2}$FT: Efficient, Scalable and Generalizable LLM Fine-tuning by\n  Structured Sparsity","summary":"  Current PEFT methods for LLMs can achieve either high quality, efficient\ntraining, or scalable serving, but not all three simultaneously. To address\nthis limitation, we investigate sparse fine-tuning and observe a remarkable\nimprovement in generalization ability. Utilizing this key insight, we propose a\nfamily of Structured Sparse Fine-Tuning (S$^{2}$FT) methods for LLMs, which\nconcurrently achieve state-of-the-art fine-tuning performance, training\nefficiency, and inference scalability. S$^{2}$FT accomplishes this by\n\"selecting sparsely and computing densely\". It selects a few heads and channels\nin the MHA and FFN modules for each Transformer block, respectively. Next, it\nco-permutes weight matrices on both sides of the coupled structures in LLMs to\nconnect the selected components in each layer into a dense submatrix. Finally,\nS$^{2}$FT performs in-place gradient updates on all submatrices. Through\ntheoretical analysis and empirical results, our method prevents forgetting\nwhile simplifying optimization, delivers SOTA performance on both commonsense\nand arithmetic reasoning with 4.6% and 1.3% average improvements compared to\nLoRA, and surpasses full FT by 11.5% when generalizing to various domains after\ninstruction tuning. Using our partial backpropagation algorithm, S$^{2}$FT\nsaves training memory up to 3$\\times$ and improves latency by 1.5-2.7$\\times$\ncompared to full FT, while delivering an average 10% improvement over LoRA on\nboth metrics. We further demonstrate that the weight updates in S$^{2}$FT can\nbe decoupled into adapters, enabling effective fusion, fast switch, and\nefficient parallelism for serving multiple fine-tuned models.\n","authors":["Xinyu Yang","Jixuan Leng","Geyang Guo","Jiawei Zhao","Ryumei Nakada","Linjun Zhang","Huaxiu Yao","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2412.06289v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15163v1","updated":"2024-12-19T18:38:13Z","published":"2024-12-19T18:38:13Z","title":"Operationalising Rawlsian Ethics for Fairness in Norm-Learning Agents","summary":"  Social norms are standards of behaviour common in a society. However, when\nagents make decisions without considering how others are impacted, norms can\nemerge that lead to the subjugation of certain agents. We present RAWL-E, a\nmethod to create ethical norm-learning agents. RAWL-E agents operationalise\nmaximin, a fairness principle from Rawlsian ethics, in their decision-making\nprocesses to promote ethical norms by balancing societal well-being with\nindividual goals. We evaluate RAWL-E agents in simulated harvesting scenarios.\nWe find that norms emerging in RAWL-E agent societies enhance social welfare,\nfairness, and robustness, and yield higher minimum experience compared to those\nthat emerge in agent societies that do not implement Rawlsian ethics.\n","authors":["Jessica Woodgate","Paul Marshall","Nirav Ajmeri"],"pdf_url":"https://arxiv.org/pdf/2412.15163v1.pdf","comment":"14 pages, 7 figures, 8 tables (and supplementary material with\n  reproducibility and additional results), accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.15150v1","updated":"2024-12-19T18:28:37Z","published":"2024-12-19T18:28:37Z","title":"Leveraging Color Channel Independence for Improved Unsupervised Object\n  Detection","summary":"  Object-centric architectures can learn to extract distinct object\nrepresentations from visual scenes, enabling downstream applications on the\nobject level. Similarly to autoencoder-based image models, object-centric\napproaches have been trained on the unsupervised reconstruction loss of images\nencoded by RGB color spaces. In our work, we challenge the common assumption\nthat RGB images are the optimal color space for unsupervised learning in\ncomputer vision. We discuss conceptually and empirically that other color\nspaces, such as HSV, bear essential characteristics for object-centric\nrepresentation learning, like robustness to lighting conditions. We further\nshow that models improve when requiring them to predict additional color\nchannels. Specifically, we propose to transform the predicted targets to the\nRGB-S space, which extends RGB with HSV's saturation component and leads to\nmarkedly better reconstruction and disentanglement for five common evaluation\ndatasets. The use of composite color spaces can be implemented with basically\nno computational overhead, is agnostic of the models' architecture, and is\nuniversally applicable across a wide range of visual computing tasks and\ntraining types. The findings of our approach encourage additional\ninvestigations in computer vision tasks beyond object-centric learning.\n","authors":["Bastian Jäckl","Yannick Metz","Udo Schlegel","Daniel A. Keim","Maximilian T. Fischer"],"pdf_url":"https://arxiv.org/pdf/2412.15150v1.pdf","comment":"38 pages incl. references, 16 figures"},{"id":"http://arxiv.org/abs/2412.15129v1","updated":"2024-12-19T18:09:42Z","published":"2024-12-19T18:09:42Z","title":"Jet: A Modern Transformer-Based Normalizing Flow","summary":"  In the past, normalizing generative flows have emerged as a promising class\nof generative models for natural images. This type of model has many modeling\nadvantages: the ability to efficiently compute log-likelihood of the input\ndata, fast generation and simple overall structure. Normalizing flows remained\na topic of active research but later fell out of favor, as visual quality of\nthe samples was not competitive with other model classes, such as GANs,\nVQ-VAE-based approaches or diffusion models. In this paper we revisit the\ndesign of the coupling-based normalizing flow models by carefully ablating\nprior design choices and using computational blocks based on the Vision\nTransformer architecture, not convolutional neural networks. As a result, we\nachieve state-of-the-art quantitative and qualitative performance with a much\nsimpler architecture. While the overall visual quality is still behind the\ncurrent state-of-the-art models, we argue that strong normalizing flow models\ncan help advancing research frontier by serving as building components of more\npowerful generative models.\n","authors":["Alexander Kolesnikov","André Susano Pinto","Michael Tschannen"],"pdf_url":"https://arxiv.org/pdf/2412.15129v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15127v1","updated":"2024-12-19T18:08:04Z","published":"2024-12-19T18:08:04Z","title":"Adaptive Pruning for Large Language Models with Structural Importance\n  Awareness","summary":"  The recent advancements in large language models (LLMs) have significantly\nimproved language understanding and generation capabilities. However, it is\ndifficult to deploy LLMs on resource-constrained edge devices due to their high\ncomputational and storage resource demands. To address this issue, we propose a\nnovel LLM model pruning method, namely structurally-aware adaptive pruning\n(SAAP), to significantly reduce the computational and memory costs while\nmaintaining model performance. We first define an adaptive importance fusion\nmetric to evaluate the importance of all coupled structures in LLMs by\nconsidering their homoscedastic uncertainty. Then, we rank the importance of\nall modules to determine the specific layers that should be pruned to meet\nparticular performance requirements. Furthermore, we develop a new group\nfine-tuning strategy to improve the inference efficiency of LLMs. Finally, we\nevaluate the proposed SAAP method on multiple LLMs across two common tasks,\ni.e., zero-shot classification and text generation. Experimental results show\nthat our SAAP method outperforms several state-of-the-art baseline methods,\nachieving 2.17%, 2.37%, and 2.39% accuracy gains on LLaMA-7B, Vicuna-7B, and\nLLaMA-13B. Additionally, SAAP improves the token generation speed by 5%,\nshowcasing its practical advantages in resource-constrained scenarios.\n","authors":["Haotian Zheng","Jinke Ren","Yushan Sun","Ruichen Zhang","Wenbo Zhang","Zhen Li","Dusit Niyato","Shuguang Cui","Yatong Han"],"pdf_url":"https://arxiv.org/pdf/2412.15127v1.pdf","comment":"12 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2412.15118v1","updated":"2024-12-19T17:59:42Z","published":"2024-12-19T17:59:42Z","title":"Outcome-Refining Process Supervision for Code Generation","summary":"  Large Language Models have demonstrated remarkable capabilities in code\ngeneration, yet they often struggle with complex programming tasks that require\ndeep algorithmic reasoning. While process supervision through learned reward\nmodels shows promise in guiding reasoning steps, it requires expensive training\ndata and suffers from unreliable evaluation. We propose Outcome-Refining\nProcess Supervision, a novel paradigm that treats outcome refinement itself as\nthe process to be supervised. Our framework leverages concrete execution\nsignals to ground the supervision of reasoning steps, while using\ntree-structured exploration to maintain multiple solution trajectories\nsimultaneously. Experiments demonstrate that our approach enables even smaller\nmodels to achieve high success accuracy and performance metrics on competitive\nprogramming tasks, creates more reliable verification than traditional reward\nmodels without requiring training PRMs. Our approach achieves significant\nimprovements across 5 models and 3 datasets: an average of 26.9% increase in\ncorrectness and 42.2% in efficiency. The results suggest that providing\nstructured reasoning space with concrete verification signals is crucial for\nsolving complex programming tasks. We open-source all our code and data at:\nhttps://github.com/zhuohaoyu/ORPS\n","authors":["Zhuohao Yu","Weizheng Gu","Yidong Wang","Zhengran Zeng","Jindong Wang","Wei Ye","Shikun Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.15118v1.pdf","comment":"18 pages, 5 figures, Code: https://github.com/zhuohaoyu/ORPS"},{"id":"http://arxiv.org/abs/2409.18472v2","updated":"2024-12-19T17:57:43Z","published":"2024-09-27T06:18:55Z","title":"URIEL+: Enhancing Linguistic Inclusion and Usability in a Typological\n  and Multilingual Knowledge Base","summary":"  URIEL is a knowledge base offering geographical, phylogenetic, and\ntypological vector representations for 7970 languages. It includes distance\nmeasures between these vectors for 4005 languages, which are accessible via the\nlang2vec tool. Despite being frequently cited, URIEL is limited in terms of\nlinguistic inclusion and overall usability. To tackle these challenges, we\nintroduce URIEL+, an enhanced version of URIEL and lang2vec that addresses\nthese limitations. In addition to expanding typological feature coverage for\n2898 languages, URIEL+ improves the user experience with robust, customizable\ndistance calculations to better suit the needs of users. These upgrades also\noffer competitive performance on downstream tasks and provide distances that\nbetter align with linguistic distance studies.\n","authors":["Aditya Khan","Mason Shipton","David Anugraha","Kaiyao Duan","Phuong H. Hoang","Eric Khiu","A. Seza Doğruöz","En-Shiun Annie Lee"],"pdf_url":"https://arxiv.org/pdf/2409.18472v2.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.04619v3","updated":"2024-12-19T17:51:34Z","published":"2024-12-05T21:12:37Z","title":"Sometimes I am a Tree: Data Drives Unstable Hierarchical Generalization","summary":"  Language models (LMs), like other neural networks, often favor shortcut\nheuristics based on surface-level patterns. Although LMs behave like n-gram\nmodels early in training, they must eventually learn hierarchical syntactic\nrepresentations to correctly apply grammatical rules out-of-distribution (OOD).\nIn this work, we use case studies of English grammar to explore how complex,\ndiverse training data drives models to generalize OOD. We construct a framework\nthat unifies our understanding of random variation with training dynamics, rule\nselection with memorization, and data diversity with complexity. We show that\nthese factors are nuanced, and that intermediate levels of diversity and\ncomplexity lead to inconsistent behavior across random seeds and to unstable\ntraining dynamics. Our findings emphasize the critical role of training data in\nshaping generalization patterns and illuminate how competing model strategies\nlead to inconsistent generalization outcomes across random seeds. Code is\navailable at https://github.com/sunnytqin/concept_comp.git.\n","authors":["Tian Qin","Naomi Saphra","David Alvarez-Melis"],"pdf_url":"https://arxiv.org/pdf/2412.04619v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15100v1","updated":"2024-12-19T17:48:03Z","published":"2024-12-19T17:48:03Z","title":"Tests for model misspecification in simulation-based inference: from\n  local distortions to global model checks","summary":"  Model misspecification analysis strategies, such as anomaly detection, model\nvalidation, and model comparison are a key component of scientific model\ndevelopment. Over the last few years, there has been a rapid rise in the use of\nsimulation-based inference (SBI) techniques for Bayesian parameter estimation,\napplied to increasingly complex forward models. To move towards fully\nsimulation-based analysis pipelines, however, there is an urgent need for a\ncomprehensive simulation-based framework for model misspecification analysis.\nIn this work, we provide a solid and flexible foundation for a wide range of\nmodel discrepancy analysis tasks, using distortion-driven model\nmisspecification tests. From a theoretical perspective, we introduce the\nstatistical framework built around performing many hypothesis tests for\ndistortions of the simulation model. We also make explicit analytic connections\nto classical techniques: anomaly detection, model validation, and\ngoodness-of-fit residual analysis. Furthermore, we introduce an efficient\nself-calibrating training algorithm that is useful for practitioners. We\ndemonstrate the performance of the framework in multiple scenarios, making the\nconnection to classical results where they are valid. Finally, we show how to\nconduct such a distortion-driven model misspecification test for real\ngravitational wave data, specifically on the event GW150914.\n","authors":["Noemi Anau Montel","James Alvey","Christoph Weniger"],"pdf_url":"https://arxiv.org/pdf/2412.15100v1.pdf","comment":"11 pages, 5 figures. Code available on github (NoemiAM/mist) at\n  https://github.com/NoemiAM/mist"},{"id":"http://arxiv.org/abs/2412.15095v1","updated":"2024-12-19T17:45:08Z","published":"2024-12-19T17:45:08Z","title":"A Full Transformer-based Framework for Automatic Pain Estimation using\n  Videos","summary":"  The automatic estimation of pain is essential in designing an optimal pain\nmanagement system offering reliable assessment and reducing the suffering of\npatients. In this study, we present a novel full transformer-based framework\nconsisting of a Transformer in Transformer (TNT) model and a Transformer\nleveraging cross-attention and self-attention blocks. Elaborating on videos\nfrom the BioVid database, we demonstrate state-of-the-art performances, showing\nthe efficacy, efficiency, and generalization capability across all the primary\npain estimation tasks.\n","authors":["Stefanos Gkikas","Manolis Tsiknakis"],"pdf_url":"https://arxiv.org/pdf/2412.15095v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15086v1","updated":"2024-12-19T17:33:56Z","published":"2024-12-19T17:33:56Z","title":"Learning Disentangled Equivariant Representation for Explicitly\n  Controllable 3D Molecule Generation","summary":"  We consider the conditional generation of 3D drug-like molecules with\n\\textit{explicit control} over molecular properties such as drug-like\nproperties (e.g., Quantitative Estimate of Druglikeness or Synthetic\nAccessibility score) and effectively binding to specific protein sites. To\ntackle this problem, we propose an E(3)-equivariant Wasserstein autoencoder and\nfactorize the latent space of our generative model into two disentangled\naspects: molecular properties and the remaining structural context of 3D\nmolecules. Our model ensures explicit control over these molecular attributes\nwhile maintaining equivariance of coordinate representation and invariance of\ndata likelihood. Furthermore, we introduce a novel alignment-based coordinate\nloss to adapt equivariant networks for auto-regressive de-novo 3D molecule\ngeneration from scratch. Extensive experiments validate our model's\neffectiveness on property-guided and context-guided molecule generation, both\nfor de-novo 3D molecule design and structure-based drug discovery against\nprotein targets.\n","authors":["Haoran Liu","Youzhi Luo","Tianxiao Li","James Caverlee","Martin Renqiang Min"],"pdf_url":"https://arxiv.org/pdf/2412.15086v1.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2412.15084v1","updated":"2024-12-19T17:29:44Z","published":"2024-12-19T17:29:44Z","title":"AceMath: Advancing Frontier Math Reasoning with Post-Training and Reward\n  Modeling","summary":"  In this paper, we introduce AceMath, a suite of frontier math models that\nexcel in solving complex math problems, along with highly effective reward\nmodels capable of evaluating generated solutions and reliably identifying the\ncorrect ones. To develop the instruction-tuned math models, we propose a\nsupervised fine-tuning (SFT) process that first achieves competitive\nperformance across general domains, followed by targeted fine-tuning for the\nmath domain using a carefully curated set of prompts and synthetically\ngenerated responses. The resulting model, AceMath-72B-Instruct greatly\noutperforms Qwen2.5-Math-72B-Instruct, GPT-4o and Claude-3.5 Sonnet. To develop\nmath-specialized reward model, we first construct AceMath-RewardBench, a\ncomprehensive and robust benchmark for evaluating math reward models across\ndiverse problems and difficulty levels. After that, we present a systematic\napproach to build our math reward models. The resulting model, AceMath-72B-RM,\nconsistently outperforms state-of-the-art reward models. Furthermore, when\ncombining AceMath-72B-Instruct with AceMath-72B-RM, we achieve the highest\naverage rm@8 score across the math reasoning benchmarks. We will release model\nweights, training data, and evaluation benchmarks at:\nhttps://research.nvidia.com/labs/adlr/acemath\n","authors":["Zihan Liu","Yang Chen","Mohammad Shoeybi","Bryan Catanzaro","Wei Ping"],"pdf_url":"https://arxiv.org/pdf/2412.15084v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15077v1","updated":"2024-12-19T17:26:07Z","published":"2024-12-19T17:26:07Z","title":"Till the Layers Collapse: Compressing a Deep Neural Network through the\n  Lenses of Batch Normalization Layers","summary":"  Today, deep neural networks are widely used since they can handle a variety\nof complex tasks. Their generality makes them very powerful tools in modern\ntechnology. However, deep neural networks are often overparameterized. The\nusage of these large models consumes a lot of computation resources. In this\npaper, we introduce a method called \\textbf{T}ill the \\textbf{L}ayers\n\\textbf{C}ollapse (TLC), which compresses deep neural networks through the\nlenses of batch normalization layers. By reducing the depth of these networks,\nour method decreases deep neural networks' computational requirements and\noverall latency. We validate our method on popular models such as Swin-T,\nMobileNet-V2, and RoBERTa, across both image classification and natural\nlanguage processing (NLP) tasks.\n","authors":["Zhu Liao","Nour Hezbri","Victor Quétu","Van-Tam Nguyen","Enzo Tartaglione"],"pdf_url":"https://arxiv.org/pdf/2412.15077v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.15075v1","updated":"2024-12-19T17:24:15Z","published":"2024-12-19T17:24:15Z","title":"DroughtSet: Understanding Drought Through Spatial-Temporal Learning","summary":"  Drought is one of the most destructive and expensive natural disasters,\nseverely impacting natural resources and risks by depleting water resources and\ndiminishing agricultural yields. Under climate change, accurately predicting\ndrought is critical for mitigating drought-induced risks. However, the\nintricate interplay among the physical and biological drivers that regulate\ndroughts limits the predictability and understanding of drought, particularly\nat a subseasonal to seasonal (S2S) time scale. While deep learning has been\ndemonstrated with potential in addressing climate forecasting challenges, its\napplication to drought prediction has received relatively less attention. In\nthis work, we propose a new dataset, DroughtSet, which integrates relevant\npredictive features and three drought indices from multiple remote sensing and\nreanalysis datasets across the contiguous United States (CONUS). DroughtSet\nspecifically provides the machine learning community with a new real-world\ndataset to benchmark drought prediction models and more generally, time-series\nforecasting methods. Furthermore, we propose a spatial-temporal model SPDrought\nto predict and interpret S2S droughts. Our model learns from the spatial and\ntemporal information of physical and biological features to predict three types\nof droughts simultaneously. Multiple strategies are employed to quantify the\nimportance of physical and biological features for drought prediction. Our\nresults provide insights for researchers to better understand the\npredictability and sensitivity of drought to biological and physical\nconditions. We aim to contribute to the climate field by proposing a new tool\nto predict and understand the occurrence of droughts and provide the AI\ncommunity with a new benchmark to study deep learning applications in climate\nscience.\n","authors":["Xuwei Tan","Qian Zhao","Yanlan Liu","Xueru Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.15075v1.pdf","comment":"Accepted by AAAI25"},{"id":"http://arxiv.org/abs/2408.15165v2","updated":"2024-12-19T17:11:11Z","published":"2024-08-27T16:03:18Z","title":"Latent Ewald summation for machine learning of long-range interactions","summary":"  Machine learning interatomic potentials (MLIPs) often neglect long-range\ninteractions, such as electrostatic and dispersion forces. In this work, we\nintroduce a straightforward and efficient method to account for long-range\ninteractions by learning a latent variable from local atomic descriptors and\napplying an Ewald summation to this variable. We demonstrate that in systems\nincluding charged and polar molecular dimers, bulk water, and water-vapor\ninterface, standard short-ranged MLIPs can lead to unphysical predictions even\nwhen employing message passing. The long-range models effectively eliminate\nthese artifacts, with only about twice the computational cost of short-range\nMLIPs.\n","authors":["Bingqing Cheng"],"pdf_url":"https://arxiv.org/pdf/2408.15165v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15058v1","updated":"2024-12-19T17:06:53Z","published":"2024-12-19T17:06:53Z","title":"MultiverSeg: Scalable Interactive Segmentation of Biomedical Imaging\n  Datasets with In-Context Guidance","summary":"  Medical researchers and clinicians often need to perform novel segmentation\ntasks on a set of related images. Existing methods for segmenting a new dataset\nare either interactive, requiring substantial human effort for each image, or\nrequire an existing set of manually labeled images. We introduce a system,\nMultiverSeg, that enables practitioners to rapidly segment an entire new\ndataset without requiring access to any existing labeled data from that task or\ndomain. Along with the image to segment, the model takes user interactions such\nas clicks, bounding boxes or scribbles as input, and predicts a segmentation.\nAs the user segments more images, those images and segmentations become\nadditional inputs to the model, providing context. As the context set of\nlabeled images grows, the number of interactions required to segment each new\nimage decreases. We demonstrate that MultiverSeg enables users to interactively\nsegment new datasets efficiently, by amortizing the number of interactions per\nimage to achieve an accurate segmentation. Compared to using a state-of-the-art\ninteractive segmentation method, using MultiverSeg reduced the total number of\nscribble steps by 53% and clicks by 36% to achieve 90% Dice on sets of images\nfrom unseen tasks. We release code and model weights at\nhttps://multiverseg.csail.mit.edu\n","authors":["Hallee E. Wong","Jose Javier Gonzalez Ortiz","John Guttag","Adrian V. Dalca"],"pdf_url":"https://arxiv.org/pdf/2412.15058v1.pdf","comment":"Project Website: https://multiverseg.csail.mit.edu Keywords:\n  interactive segmentation, in-context learning, medical image analysis,\n  biomedical imaging, image annotation, visual prompting"},{"id":"http://arxiv.org/abs/2407.17710v2","updated":"2024-12-19T16:48:59Z","published":"2024-07-25T02:05:15Z","title":"Revisiting Machine Unlearning with Dimensional Alignment","summary":"  Machine unlearning, an emerging research topic focusing on compliance with\ndata privacy regulations, enables trained models to remove the information\nlearned from specific data. While many existing methods indirectly address this\nissue by intentionally injecting incorrect supervisions, they can drastically\nand unpredictably alter the decision boundaries and feature spaces, leading to\ntraining instability and undesired side effects. To fundamentally approach this\ntask, we first analyze the changes in latent feature spaces between original\nand retrained models, and observe that the feature representations of samples\nnot involved in training are closely aligned with the feature manifolds of\npreviously seen samples in training. Based on these findings, we introduce a\nnovel evaluation metric for machine unlearning, coined dimensional alignment,\nwhich measures the alignment between the eigenspaces of the forget and retain\nset samples. We employ this metric as a regularizer loss to build a robust and\nstable unlearning framework, which is further enhanced by integrating a\nself-distillation loss and an alternating training scheme. Our framework\neffectively eliminates information from the forget set and preserves knowledge\nfrom the retain set. Lastly, we identify critical flaws in established\nevaluation metrics for machine unlearning, and introduce new evaluation tools\nthat more accurately reflect the fundamental goals of machine unlearning.\n","authors":["Seonguk Seo","Dongwan Kim","Bohyung Han"],"pdf_url":"https://arxiv.org/pdf/2407.17710v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2301.03767v2","updated":"2024-12-19T16:45:52Z","published":"2023-01-10T03:10:32Z","title":"Metric Compatible Training for Online Backfilling in Large-Scale\n  Retrieval","summary":"  Backfilling is the process of re-extracting all gallery embeddings from\nupgraded models in image retrieval systems. It inevitably requires a\nprohibitively large amount of computational cost and even entails the downtime\nof the service. Although backward-compatible learning sidesteps this challenge\nby tackling query-side representations, this leads to suboptimal solutions in\nprinciple because gallery embeddings cannot benefit from model upgrades. We\naddress this dilemma by introducing an online backfilling algorithm, which\nenables us to achieve a progressive performance improvement during the\nbackfilling process while not sacrificing the final performance of new model\nafter the completion of backfilling. To this end, we first propose a simple\ndistance rank merge technique for online backfilling. Then, we incorporate a\nreverse transformation module for more effective and efficient merging, which\nis further enhanced by adopting a metric-compatible contrastive learning\napproach. These two components help to make the distances of old and new models\ncompatible, resulting in desirable merge results during backfilling with no\nextra computational overhead. Extensive experiments show the effectiveness of\nour framework on four standard benchmarks in various settings.\n","authors":["Seonguk Seo","Mustafa Gokhan Uzunbas","Bohyung Han","Sara Cao","Ser-Nam Lim"],"pdf_url":"https://arxiv.org/pdf/2301.03767v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15032v1","updated":"2024-12-19T16:44:01Z","published":"2024-12-19T16:44:01Z","title":"DCTdiff: Intriguing Properties of Image Generative Modeling in the DCT\n  Space","summary":"  This paper explores image modeling from the frequency space and introduces\nDCTdiff, an end-to-end diffusion generative paradigm that efficiently models\nimages in the discrete cosine transform (DCT) space. We investigate the design\nspace of DCTdiff and reveal the key design factors. Experiments on different\nframeworks (UViT, DiT), generation tasks, and various diffusion samplers\ndemonstrate that DCTdiff outperforms pixel-based diffusion models regarding\ngenerative quality and training efficiency. Remarkably, DCTdiff can seamlessly\nscale up to high-resolution generation without using the latent diffusion\nparadigm. Finally, we illustrate several intriguing properties of DCT image\nmodeling. For example, we provide a theoretical proof of why `image diffusion\ncan be seen as spectral autoregression', bridging the gap between diffusion and\nautoregressive models. The effectiveness of DCTdiff and the introduced\nproperties suggest a promising direction for image modeling in the frequency\nspace. The code is at \\url{https://github.com/forever208/DCTdiff}.\n","authors":["Mang Ning","Mingxiao Li","Jianlin Su","Haozhe Jia","Lanmiao Liu","Martin Beneš","Albert Ali Salah","Itir Onal Ertugrul"],"pdf_url":"https://arxiv.org/pdf/2412.15032v1.pdf","comment":"23 pages"},{"id":"http://arxiv.org/abs/2406.14742v2","updated":"2024-12-19T16:37:38Z","published":"2024-06-20T21:13:39Z","title":"Latent Variable Sequence Identification for Cognitive Models with Neural\n  Network Estimators","summary":"  Extracting time-varying latent variables from computational cognitive models\nis a key step in model-based neural analysis, which aims to understand the\nneural correlates of cognitive processes. However, existing methods only allow\nresearchers to infer latent variables that explain subjects' behavior in a\nrelatively small class of cognitive models. For example, a broad class of\nrelevant cognitive models with analytically intractable likelihood is currently\nout of reach from standard techniques, based on Maximum a Posteriori parameter\nestimation. Here, we present an approach that extends neural Bayes estimation\nto learn a direct mapping between experimental data and the targeted latent\nvariable space using recurrent neural networks and simulated datasets. We show\nthat our approach achieves competitive performance in inferring latent variable\nsequences in both tractable and intractable models. Furthermore, the approach\nis generalizable across different computational models and is adaptable for\nboth continuous and discrete latent spaces. We then demonstrate its\napplicability in real world datasets. Our work underscores that combining\nrecurrent neural networks and simulation-based inference to identify latent\nvariable sequences can enable researchers to access a wider class of cognitive\nmodels for model-based neural analyses, and thus test a broader set of\ntheories.\n","authors":["Ti-Fen Pan","Jing-Jing Li","Bill Thompson","Anne Collins"],"pdf_url":"https://arxiv.org/pdf/2406.14742v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15023v1","updated":"2024-12-19T16:37:19Z","published":"2024-12-19T16:37:19Z","title":"Stable-V2A: Synthesis of Synchronized Sound Effects with Temporal and\n  Semantic Controls","summary":"  Sound designers and Foley artists usually sonorize a scene, such as from a\nmovie or video game, by manually annotating and sonorizing each action of\ninterest in the video. In our case, the intent is to leave full creative\ncontrol to sound designers with a tool that allows them to bypass the more\nrepetitive parts of their work, thus being able to focus on the creative\naspects of sound production. We achieve this presenting Stable-V2A, a two-stage\nmodel consisting of: an RMS-Mapper that estimates an envelope representative of\nthe audio characteristics associated with the input video; and Stable-Foley, a\ndiffusion model based on Stable Audio Open that generates audio semantically\nand temporally aligned with the target video. Temporal alignment is guaranteed\nby the use of the envelope as a ControlNet input, while semantic alignment is\nachieved through the use of sound representations chosen by the designer as\ncross-attention conditioning of the diffusion process. We train and test our\nmodel on Greatest Hits, a dataset commonly used to evaluate V2A models. In\naddition, to test our model on a case study of interest, we introduce Walking\nThe Maps, a dataset of videos extracted from video games depicting animated\ncharacters walking in different locations. Samples and code available on our\ndemo page at https://ispamm.github.io/Stable-V2A.\n","authors":["Riccardo Fosco Gramaccioni","Christian Marinoni","Emilian Postolache","Marco Comunità","Luca Cosmo","Joshua D. Reiss","Danilo Comminiello"],"pdf_url":"https://arxiv.org/pdf/2412.15023v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.14512v3","updated":"2024-12-19T16:37:00Z","published":"2024-08-25T04:32:45Z","title":"LLMs as Zero-shot Graph Learners: Alignment of GNN Representations with\n  LLM Token Embeddings","summary":"  Zero-shot graph machine learning, especially with graph neural networks\n(GNNs), has garnered significant interest due to the challenge of scarce\nlabeled data. While methods like self-supervised learning and graph prompt\nlearning have been extensively explored, they often rely on fine-tuning with\ntask-specific labels, limiting their effectiveness in zero-shot scenarios.\nInspired by the zero-shot capabilities of instruction-fine-tuned large language\nmodels (LLMs), we introduce a novel framework named Token Embedding-Aligned\nGraph Language Model (TEA-GLM) that leverages LLMs as cross-dataset and\ncross-task zero-shot learners for graph machine learning. Concretely, we\npretrain a GNN, aligning its representations with token embeddings of an LLM.\nWe then train a linear projector that transforms the GNN's representations into\na fixed number of graph token embeddings without tuning the LLM. A unified\ninstruction is designed for various graph tasks at different levels, such as\nnode classification (node-level) and link prediction (edge-level). These design\nchoices collectively enhance our method's effectiveness in zero-shot learning,\nsetting it apart from existing methods. Experiments show that our graph token\nembeddings help the LLM predictor achieve state-of-the-art performance on\nunseen datasets and tasks compared to other methods using LLMs as predictors.\n","authors":["Duo Wang","Yuan Zuo","Fengzhi Li","Junjie Wu"],"pdf_url":"https://arxiv.org/pdf/2408.14512v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15557v2","updated":"2024-12-19T16:32:43Z","published":"2024-05-24T13:44:30Z","title":"Learning from Linear Algebra: A Graph Neural Network Approach to\n  Preconditioner Design for Conjugate Gradient Solvers","summary":"  Large linear systems are ubiquitous in modern computational science and\nengineering. The main recipe for solving them is the use of Krylov subspace\niterative methods with well-designed preconditioners. Deep learning models can\nbe used as nonlinear preconditioners during the iteration of linear solvers\nsuch as the conjugate gradient (CG) method. Neural network models require an\nenormous number of parameters to approximate well in this setup. Another\napproach is to take advantage of small graph neural networks (GNNs) to\nconstruct preconditioners with predefined sparsity patterns. Recently, GNNs\nhave been shown to be a promising tool for designing preconditioners to reduce\nthe overall computational cost of iterative methods by constructing them more\nefficiently than with classical linear algebra techniques. However,\npreconditioners designed with these approaches cannot outperform those designed\nwith classical methods in terms of the number of iterations in CG. In our work,\nwe recall well-established preconditioners from linear algebra and use them as\na starting point for training the GNN to obtain preconditioners that reduce the\ncondition number of the system more significantly. Numerical experiments show\nthat our approach outperforms both classical and neural network-based methods\nfor an important class of parametric partial differential equations. We also\nprovide a heuristic justification for the loss function used and show that\npreconditioners obtained by learning with this loss function reduce the\ncondition number in a more desirable way for CG.\n","authors":["Vladislav Trifonov","Alexander Rudikov","Oleg Iliev","Yuri M. Laevsky","Ivan Oseledets","Ekaterina Muravleva"],"pdf_url":"https://arxiv.org/pdf/2405.15557v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15010v1","updated":"2024-12-19T16:22:37Z","published":"2024-12-19T16:22:37Z","title":"Robust Federated Learning in the Face of Covariate Shift: A Magnitude\n  Pruning with Hybrid Regularization Framework for Enhanced Model Aggregation","summary":"  The development of highly sophisticated neural networks has allowed for fast\nprogress in every field of computer vision, however, applications where\nannotated data is prohibited due to privacy or security concerns remain\nchallenging. Federated Learning (FL) offers a promising framework for\nindividuals aiming to collaboratively develop a shared model while preserving\ndata privacy. Nevertheless, our findings reveal that variations in data\ndistribution among clients can profoundly affect FL methodologies, primarily\ndue to instabilities in the aggregation process. We also propose a novel FL\nframework to mitigate the adverse effects of covariate shifts among federated\nclients by combining individual parameter pruning and regularization techniques\nto improve the robustness of individual clients' models to aggregate. Each\nclient's model is optimized through magnitude-based pruning and the addition of\ndropout and noise injection layers to build more resilient decision pathways in\nthe networks and improve the robustness of the model's parameter aggregation\nstep. The proposed framework is capable of extracting robust representations\neven in the presence of very large covariate shifts among client data\ndistributions and in the federation of a small number of clients. Empirical\nfindings substantiate the effectiveness of our proposed methodology across\ncommon benchmark datasets, including CIFAR10, MNIST, SVHN, and Fashion MNIST.\nFurthermore, we introduce the CelebA-Gender dataset, specifically designed to\nevaluate performance on a more realistic domain. The proposed method is capable\nof extracting robust representations even in the presence of both high and low\ncovariate shifts among client data distributions.\n","authors":["Ozgu Goksu","Nicolas Pugeault"],"pdf_url":"https://arxiv.org/pdf/2412.15010v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.15005v1","updated":"2024-12-19T16:20:42Z","published":"2024-12-19T16:20:42Z","title":"DisCo: Graph-Based Disentangled Contrastive Learning for Cold-Start\n  Cross-Domain Recommendation","summary":"  Recommender systems are widely used in various real-world applications, but\nthey often encounter the persistent challenge of the user cold-start problem.\nCross-domain recommendation (CDR), which leverages user interactions from one\ndomain to improve prediction performance in another, has emerged as a promising\nsolution. However, users with similar preferences in the source domain may\nexhibit different interests in the target domain. Therefore, directly\ntransferring embeddings may introduce irrelevant source-domain collaborative\ninformation. In this paper, we propose a novel graph-based disentangled\ncontrastive learning framework to capture fine-grained user intent and filter\nout irrelevant collaborative information, thereby avoiding negative transfer.\nSpecifically, for each domain, we use a multi-channel graph encoder to capture\ndiverse user intents. We then construct the affinity graph in the embedding\nspace and perform multi-step random walks to capture high-order user similarity\nrelationships. Treating one domain as the target, we propose a disentangled\nintent-wise contrastive learning approach, guided by user similarity, to refine\nthe bridging of user intents across domains. Extensive experiments on four\nbenchmark CDR datasets demonstrate that DisCo consistently outperforms existing\nstate-of-the-art baselines, thereby validating the effectiveness of both DisCo\nand its components.\n","authors":["Hourun Li","Yifan Wang","Zhiping Xiao","Jia Yang","Changling Zhou","Ming Zhang","Wei Ju"],"pdf_url":"https://arxiv.org/pdf/2412.15005v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2401.12012v5","updated":"2024-12-19T16:15:27Z","published":"2024-01-22T14:59:11Z","title":"TurboSVM-FL: Boosting Federated Learning through SVM Aggregation for\n  Lazy Clients","summary":"  Federated learning is a distributed collaborative machine learning paradigm\nthat has gained strong momentum in recent years. In federated learning, a\ncentral server periodically coordinates models with clients and aggregates the\nmodels trained locally by clients without necessitating access to local data.\nDespite its potential, the implementation of federated learning continues to\nencounter several challenges, predominantly the slow convergence that is\nlargely due to data heterogeneity. The slow convergence becomes particularly\nproblematic in cross-device federated learning scenarios where clients may be\nstrongly limited by computing power and storage space, and hence counteracting\nmethods that induce additional computation or memory cost on the client side\nsuch as auxiliary objective terms and larger training iterations can be\nimpractical. In this paper, we propose a novel federated aggregation strategy,\nTurboSVM-FL, that poses no additional computation burden on the client side and\ncan significantly accelerate convergence for federated classification task,\nespecially when clients are \"lazy\" and train their models solely for few epochs\nfor next global aggregation. TurboSVM-FL extensively utilizes support vector\nmachine to conduct selective aggregation and max-margin spread-out\nregularization on class embeddings. We evaluate TurboSVM-FL on multiple\ndatasets including FEMNIST, CelebA, and Shakespeare using user-independent\nvalidation with non-iid data distribution. Our results show that TurboSVM-FL\ncan significantly outperform existing popular algorithms on convergence rate\nand reduce communication rounds while delivering better test metrics including\naccuracy, F1 score, and MCC.\n","authors":["Mengdi Wang","Anna Bodonhelyi","Efe Bozkir","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2401.12012v5.pdf","comment":"Proceedings of the AAAI Conference on Artificial Intelligence 2024\n  (AAAI'24)"},{"id":"http://arxiv.org/abs/2405.08044v2","updated":"2024-12-19T16:08:31Z","published":"2024-05-13T13:55:34Z","title":"Mitigating federated learning contribution allocation instability\n  through randomized aggregation","summary":"  Federated learning (FL) is a collaborative and privacy-preserving Machine\nLearning paradigm, allowing the development of robust models without the need\nto centralise sensitive data. A critical challenge in FL lies in fairly and\naccurately allocating contributions from diverse participants. Inaccurate\nallocation can undermine trust, lead to unfair compensation, and thus\nparticipants may lack the incentive to join or actively contribute to the\nfederation.\n  Various remuneration strategies have been proposed to date, including\nauction-based approaches and Shapley-value based methods, the latter offering a\nmeans to quantify the contribution of each participant. However, little to no\nwork has studied the stability of these contribution evaluation methods.\n  In this paper, we focus on calculating contributions using gradient-based\nmodel reconstruction techniques with Shapley values. We first show that\nbaseline Shapley values do not accurately reflect clients' contributions,\nleading to unstable reward allocations amongst participants in a cross-silo\nfederation. We then introduce \\textsc{FedRandom}, a new method that mitigates\nthese shortcomings with additional data samplings, and show its efficacy at\nincreasing the stability of contribution evaluation in federated learning.\n","authors":["Arno Geimer","Beltran Fiz","Radu State"],"pdf_url":"https://arxiv.org/pdf/2405.08044v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2402.08606v2","updated":"2024-12-19T16:05:31Z","published":"2024-02-13T17:12:01Z","title":"Arbitrary Polynomial Separations in Trainable Quantum Machine Learning","summary":"  Recent theoretical results in quantum machine learning have demonstrated a\ngeneral trade-off between the expressive power of quantum neural networks\n(QNNs) and their trainability; as a corollary of these results, practical\nexponential separations in expressive power over classical machine learning\nmodels are believed to be infeasible as such QNNs take a time to train that is\nexponential in the model size. We here circumvent these negative results by\nconstructing a hierarchy of efficiently trainable QNNs that exhibit\nunconditionally provable, polynomial memory separations of arbitrary constant\ndegree over classical neural networks -- including state-of-the-art models,\nsuch as Transformers -- in performing a classical sequence modeling task. This\nconstruction is also computationally efficient, as each unit cell of the\nintroduced class of QNNs only has constant gate complexity. We show that\ncontextuality -- informally, a quantitative notion of semantic ambiguity -- is\nthe source of the expressivity separation, suggesting that other learning tasks\nwith this property may be a natural setting for the use of quantum learning\nalgorithms.\n","authors":["Eric R. Anschuetz","Xun Gao"],"pdf_url":"https://arxiv.org/pdf/2402.08606v2.pdf","comment":"24 pages, 3 figures, strengthened and simplified results and\n  presentation"},{"id":"http://arxiv.org/abs/2412.14988v1","updated":"2024-12-19T16:00:10Z","published":"2024-12-19T16:00:10Z","title":"Stitch Contrast and Segment_Learning a Human Action Segmentation Model\n  Using Trimmed Skeleton Videos","summary":"  Existing skeleton-based human action classification models rely on\nwell-trimmed action-specific skeleton videos for both training and testing,\nprecluding their scalability to real-world applications where untrimmed videos\nexhibiting concatenated actions are predominant. To overcome this limitation,\nrecently introduced skeleton action segmentation models involve un-trimmed\nskeleton videos into end-to-end training. The model is optimized to provide\nframe-wise predictions for any length of testing videos, simultaneously\nrealizing action localization and classification. Yet, achieving such an\nimprovement im-poses frame-wise annotated skeleton videos, which remains\ntime-consuming in practice. This paper features a novel framework for\nskeleton-based action segmentation trained on short trimmed skeleton videos,\nbut that can run on longer un-trimmed videos. The approach is implemented in\nthree steps: Stitch, Contrast, and Segment. First, Stitch proposes a tem-poral\nskeleton stitching scheme that treats trimmed skeleton videos as elementary\nhuman motions that compose a semantic space and can be sampled to generate\nmulti-action stitched se-quences. Contrast learns contrastive representations\nfrom stitched sequences with a novel discrimination pretext task that enables a\nskeleton encoder to learn meaningful action-temporal contexts to improve action\nsegmentation. Finally, Segment relates the proposed method to action\nsegmentation by learning a segmentation layer while handling particular da-ta\navailability. Experiments involve a trimmed source dataset and an untrimmed\ntarget dataset in an adaptation formulation for real-world skeleton-based human\naction segmentation to evaluate the effectiveness of the proposed method.\n","authors":["Haitao Tian","Pierre Payeur"],"pdf_url":"https://arxiv.org/pdf/2412.14988v1.pdf","comment":"Accepted as AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08941v3","updated":"2024-12-19T15:59:19Z","published":"2024-12-12T05:08:05Z","title":"Optimized Gradient Clipping for Noisy Label Learning","summary":"  Previous research has shown that constraining the gradient of loss function\nwith respect to model-predicted probabilities can enhance the model robustness\nagainst noisy labels. These methods typically specify a fixed optimal threshold\nfor gradient clipping through validation data to obtain the desired robustness\nagainst noise. However, this common practice overlooks the dynamic distribution\nof gradients from both clean and noisy-labeled samples at different stages of\ntraining, significantly limiting the model capability to adapt to the variable\nnature of gradients throughout the training process. To address this issue, we\npropose a simple yet effective approach called Optimized Gradient Clipping\n(OGC), which dynamically adjusts the clipping threshold based on the ratio of\nnoise gradients to clean gradients after clipping, estimated by modeling the\ndistributions of clean and noisy samples. This approach allows us to modify the\nclipping threshold at each training step, effectively controlling the influence\nof noise gradients. Additionally, we provide statistical analysis to certify\nthe noise-tolerance ability of OGC. Our extensive experiments across various\ntypes of label noise, including symmetric, asymmetric, instance-dependent, and\nreal-world noise, demonstrate the effectiveness of our approach.\n","authors":["Xichen Ye","Yifan Wu","Weizhong Zhang","Xiaoqiang Li","Yifan Chen","Cheng Jin"],"pdf_url":"https://arxiv.org/pdf/2412.08941v3.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2404.15379v3","updated":"2024-12-19T15:54:17Z","published":"2024-04-23T07:16:13Z","title":"Clustering of timed sequences -- Application to the analysis of care\n  pathways","summary":"  Improving the future of healthcare starts by better understanding the current\nactual practices in hospital settings. This motivates the objective of\ndiscovering typical care pathways from patient data. Revealing typical care\npathways can be achieved through clustering. The difficulty in clustering care\npathways, represented by sequences of timestamped events, lies in defining a\nsemantically appropriate metric and clustering algorithms. In this article, we\nadapt two methods developed for time series to the clustering of timed\nsequences: the drop-DTW metric and the DBA approach for the construction of\naveraged time sequences. These methods are then applied in clustering\nalgorithms to propose original and sound clustering algorithms for timed\nsequences. This approach is experimented with and evaluated on synthetic and\nreal-world data.\n","authors":["Thomas Guyet","Pierre Pinson","Enoal Gesny"],"pdf_url":"https://arxiv.org/pdf/2404.15379v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.01420v2","updated":"2024-12-19T15:51:33Z","published":"2024-12-02T12:00:27Z","title":"Task Adaptation of Reinforcement Learning-based NAS Agents through\n  Transfer Learning","summary":"  Recently, a novel paradigm has been proposed for reinforcement learning-based\nNAS agents, that revolves around the incremental improvement of a given\narchitecture. We assess the abilities of such reinforcement learning agents to\ntransfer between different tasks. We perform our evaluation using the\nTrans-NASBench-101 benchmark, and consider the efficacy of the transferred\nagents, as well as how quickly they can be trained. We find that pretraining an\nagent on one task benefits the performance of the agent in another task in all\nbut 1 task when considering final performance. We also show that the training\nprocedure for an agent can be shortened significantly by pretraining it on\nanother task. Our results indicate that these effects occur regardless of the\nsource or target task, although they are more pronounced for some tasks than\nfor others. Our results show that transfer learning can be an effective tool in\nmitigating the computational cost of the initial training procedure for\nreinforcement learning-based NAS agents.\n","authors":["Amber Cassimon","Siegfried Mercelis","Kevin Mets"],"pdf_url":"https://arxiv.org/pdf/2412.01420v2.pdf","comment":"15 Pages, 13 Figures, Corrected data in Figure 5"},{"id":"http://arxiv.org/abs/2412.14964v1","updated":"2024-12-19T15:44:01Z","published":"2024-12-19T15:44:01Z","title":"Knowledge Injection via Prompt Distillation","summary":"  In many practical applications, large language models (LLMs) need to\nincorporate new knowledge not present in their pre-training data. The primary\nmethods for this are fine-tuning and retrieval-augmented generation (RAG).\nAlthough RAG has emerged as the industry standard for knowledge injection,\nfine-tuning has not yet achieved comparable success. In this paper, we propose\na new fine-tuning technique for learning new knowledge and show that it can\nreach the performance of RAG. The proposed method is based on the\nself-distillation approach, which we call prompt distillation. First, we\ngenerate question-answer pairs about the new knowledge. Then, we fine-tune a\nstudent model on the question-answer pairs to imitate the output distributions\nof a teacher model, which additionally receives the new knowledge in its\nprompt. The student model is identical to the teacher, except it is equipped\nwith a LoRA adapter. This training procedure facilitates distilling the new\nknowledge from the teacher's prompt into the student's weights.\n","authors":["Kalle Kujanpää","Harri Valpola","Alexander Ilin"],"pdf_url":"https://arxiv.org/pdf/2412.14964v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.14963v1","updated":"2024-12-19T15:43:05Z","published":"2024-12-19T15:43:05Z","title":"IDOL: Instant Photorealistic 3D Human Creation from a Single Image","summary":"  Creating a high-fidelity, animatable 3D full-body avatar from a single image\nis a challenging task due to the diverse appearance and poses of humans and the\nlimited availability of high-quality training data. To achieve fast and\nhigh-quality human reconstruction, this work rethinks the task from the\nperspectives of dataset, model, and representation. First, we introduce a\nlarge-scale HUman-centric GEnerated dataset, HuGe100K, consisting of 100K\ndiverse, photorealistic sets of human images. Each set contains 24-view frames\nin specific human poses, generated using a pose-controllable\nimage-to-multi-view model. Next, leveraging the diversity in views, poses, and\nappearances within HuGe100K, we develop a scalable feed-forward transformer\nmodel to predict a 3D human Gaussian representation in a uniform space from a\ngiven human image. This model is trained to disentangle human pose, body shape,\nclothing geometry, and texture. The estimated Gaussians can be animated without\npost-processing. We conduct comprehensive experiments to validate the\neffectiveness of the proposed dataset and method. Our model demonstrates the\nability to efficiently reconstruct photorealistic humans at 1K resolution from\na single input image using a single GPU instantly. Additionally, it seamlessly\nsupports various applications, as well as shape and texture editing tasks.\n","authors":["Yiyu Zhuang","Jiaxi Lv","Hao Wen","Qing Shuai","Ailing Zeng","Hao Zhu","Shifeng Chen","Yujiu Yang","Xun Cao","Wei Liu"],"pdf_url":"https://arxiv.org/pdf/2412.14963v1.pdf","comment":"21 pages, 15 figures, includes main content, supplementary materials,\n  and references"},{"id":"http://arxiv.org/abs/2412.03795v2","updated":"2024-12-19T15:43:00Z","published":"2024-12-05T01:25:34Z","title":"Samudra: An AI Global Ocean Emulator for Climate","summary":"  AI emulators for forecasting have emerged as powerful tools that can\noutperform conventional numerical predictions. The next frontier is to build\nemulators for long climate simulations with skill across a range of\nspatiotemporal scales, a particularly important goal for the ocean. Our work\nbuilds a skillful global emulator of the ocean component of a state-of-the-art\nclimate model. We emulate key ocean variables, sea surface height, horizontal\nvelocities, temperature, and salinity, across their full depth. We use a\nmodified ConvNeXt UNet architecture trained on multidepth levels of ocean data.\nWe show that the ocean emulator - Samudra - which exhibits no drift relative to\nthe truth, can reproduce the depth structure of ocean variables and their\ninterannual variability. Samudra is stable for centuries and 150 times faster\nthan the original ocean model. Samudra struggles to capture the correct\nmagnitude of the forcing trends and simultaneously remains stable, requiring\nfurther work.\n","authors":["Surya Dheeshjith","Adam Subel","Alistair Adcroft","Julius Busecke","Carlos Fernandez-Granda","Shubham Gupta","Laure Zanna"],"pdf_url":"https://arxiv.org/pdf/2412.03795v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.00641v2","updated":"2024-12-19T15:42:00Z","published":"2024-08-01T15:30:43Z","title":"Enhancing Ethereum Fraud Detection via Generative and Contrastive\n  Self-supervision","summary":"  The rampant fraudulent activities on Ethereum hinder the healthy development\nof the blockchain ecosystem, necessitating the reinforcement of regulations.\nHowever, multiple imbalances involving account interaction frequencies and\ninteraction types in the Ethereum transaction environment pose significant\nchallenges to data mining-based fraud detection research. To address this, we\nfirst propose the concept of meta-interactions to refine interaction behaviors\nin Ethereum, and based on this, we present a dual self-supervision enhanced\nEthereum fraud detection framework, named Meta-IFD. This framework initially\nintroduces a generative self-supervision mechanism to augment the interaction\nfeatures of accounts, followed by a contrastive self-supervision mechanism to\ndifferentiate various behavior patterns, and ultimately characterizes the\nbehavioral representations of accounts and mines potential fraud risks through\nmulti-view interaction feature learning. Extensive experiments on real Ethereum\ndatasets demonstrate the effectiveness and superiority of our framework in\ndetecting common Ethereum fraud behaviors such as Ponzi schemes and phishing\nscams. Additionally, the generative module can effectively alleviate the\ninteraction distribution imbalance in Ethereum data, while the contrastive\nmodule significantly enhances the framework's ability to distinguish different\nbehavior patterns. The source code will be available in\nhttps://github.com/GISec-Team/Meta-IFD.\n","authors":["Chenxiang Jin","Jiajun Zhou","Chenxuan Xie","Shanqing Yu","Qi Xuan","Xiaoniu Yang"],"pdf_url":"https://arxiv.org/pdf/2408.00641v2.pdf","comment":"Accepted by IEEE Transactions on Information Forensics & Security"},{"id":"http://arxiv.org/abs/2412.14954v1","updated":"2024-12-19T15:36:30Z","published":"2024-12-19T15:36:30Z","title":"Corn Ear Detection and Orientation Estimation Using Deep Learning","summary":"  Monitoring growth behavior of maize plants such as the development of ears\ncan give key insights into the plant's health and development. Traditionally,\nthe measurement of the angle of ears is performed manually, which can be\ntime-consuming and prone to human error. To address these challenges, this\npaper presents a computer vision-based system for detecting and tracking ears\nof corn in an image sequence. The proposed system could accurately detect,\ntrack, and predict the ear's orientation, which can be useful in monitoring\ntheir growth behavior. This can significantly save time compared to manual\nmeasurement and enables additional areas of ear orientation research and\npotential increase in efficiencies for maize production. Using an object\ndetector with keypoint detection, the algorithm proposed could detect 90\npercent of all ears. The cardinal estimation had a mean absolute error (MAE) of\n18 degrees, compared to a mean 15 degree difference between two people\nmeasuring by hand. These results demonstrate the feasibility of using computer\nvision techniques for monitoring maize growth and can lead to further research\nin this area.\n","authors":["Nathan Sprague","John Evans","Michael Mardikes"],"pdf_url":"https://arxiv.org/pdf/2412.14954v1.pdf","comment":"22 pages;15 figures"},{"id":"http://arxiv.org/abs/2411.10958v2","updated":"2024-12-19T15:26:20Z","published":"2024-11-17T04:35:49Z","title":"SageAttention2: Efficient Attention with Thorough Outlier Smoothing and\n  Per-thread INT4 Quantization","summary":"  Although quantization for linear layers has been widely used, its application\nto accelerate the attention process remains limited. To further enhance the\nefficiency of attention computation compared to SageAttention while maintaining\nprecision, we propose SageAttention2, which utilizes significantly faster 4-bit\nmatrix multiplication (Matmul) alongside additional precision-enhancing\ntechniques. First, we propose to quantize matrixes $(Q, K)$ to INT4 in a\nhardware-friendly thread-level granularity and quantize matrixes $(\\widetilde\nP, V)$ to FP8. Second, we propose a method to smooth $Q$, enhancing the\naccuracy of INT4 $QK$. Third, we propose to use an FP32 Matmul buffer for $PV$\nto enhance the accuracy of FP8 $\\widetilde PV$. The operations per second (OPS)\nof SageAttention2 surpass FlashAttention2 and xformers by about 3x and 5x on\nRTX4090, respectively. Comprehensive experiments confirm that our approach\nincurs negligible end-to-end metrics loss across diverse models, including\nthose for large language processing, image generation, and video generation.\nThe codes are available at https://github.com/thu-ml/SageAttention.\n","authors":["Jintao Zhang","Haofeng Huang","Pengle Zhang","Jia Wei","Jun Zhu","Jianfei Chen"],"pdf_url":"https://arxiv.org/pdf/2411.10958v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.10839v2","updated":"2024-12-19T15:25:41Z","published":"2024-08-20T13:34:17Z","title":"Benchmarking Large Language Models for Math Reasoning Tasks","summary":"  The use of Large Language Models (LLMs) in mathematical reasoning has become\na cornerstone of related research, demonstrating the intelligence of these\nmodels and enabling potential practical applications through their advanced\nperformance, such as in educational settings. Despite the variety of datasets\nand in-context learning algorithms designed to improve the ability of LLMs to\nautomate mathematical problem solving, the lack of comprehensive benchmarking\nacross different datasets makes it complicated to select an appropriate model\nfor specific tasks. In this project, we present a benchmark that fairly\ncompares seven state-of-the-art in-context learning algorithms for mathematical\nproblem solving across five widely used mathematical datasets on four powerful\nfoundation models. Furthermore, we explore the trade-off between efficiency and\nperformance, highlighting the practical applications of LLMs for mathematical\nreasoning. Our results indicate that larger foundation models like GPT-4o and\nLLaMA 3-70B can solve mathematical reasoning independently from the concrete\nprompting strategy, while for smaller models the in-context learning approach\nsignificantly influences the performance. Moreover, the optimal prompt depends\non the chosen foundation model. We open-source our benchmark code to support\nthe integration of additional models in future research.\n","authors":["Kathrin Seßler","Yao Rong","Emek Gözlüklü","Enkelejda Kasneci"],"pdf_url":"https://arxiv.org/pdf/2408.10839v2.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2302.11947v2","updated":"2024-12-19T15:13:46Z","published":"2023-02-23T11:44:43Z","title":"Real-Time Damage Detection in Fiber Lifting Ropes Using Lightweight\n  Convolutional Neural Networks","summary":"  The health and safety hazards posed by worn crane lifting ropes mandate\nperiodic inspection for damage. This task is time-consuming, prone to human\nerror, halts operation, and may result in the premature disposal of ropes.\nTherefore, we propose using efficient deep learning and computer vision methods\nto automate the process of detecting damaged ropes. Specifically, we present a\nvision-based system for detecting damage in synthetic fiber rope images using\nlightweight convolutional neural networks. We develop a camera-based apparatus\nto photograph the lifting rope's surface, while in operation, and capture the\nprogressive wear-and-tear as well as the more significant degradation in the\nrope's health state. Experts from Konecranes annotate the collected images in\naccordance with the rope's condition; normal or damaged. Then, we pre-process\nthe images, systematically design a deep learning model, evaluate its detection\nand prediction performance, analyze its computational complexity, and compare\nit with various other models. Experimental results show the proposed model\noutperforms other similar techniques with 96.5% accuracy, 94.8% precision,\n98.3% recall, 96.5% F1-score, and 99.3% AUC. Besides, they demonstrate the\nmodel's real-time operation, low memory footprint, robustness to various\nenvironmental and operational conditions, and adequacy for deployment in\nindustrial applications such as lifting, mooring, towing, climbing, and\nsailing.\n","authors":["Tuomas Jalonen","Mohammad Al-Sa'd","Roope Mellanen","Serkan Kiranyaz","Moncef Gabbouj"],"pdf_url":"https://arxiv.org/pdf/2302.11947v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2307.09423v3","updated":"2024-12-19T15:10:18Z","published":"2023-07-18T16:43:03Z","title":"Scaling Laws for Imitation Learning in Single-Agent Games","summary":"  Imitation Learning (IL) is one of the most widely used methods in machine\nlearning. Yet, many works find it is often unable to fully recover the\nunderlying expert behavior, even in constrained environments like single-agent\ngames. However, none of these works deeply investigate the role of scaling up\nthe model and data size. Inspired by recent work in Natural Language Processing\n(NLP) where \"scaling up\" has resulted in increasingly more capable LLMs, we\ninvestigate whether carefully scaling up model and data size can bring similar\nimprovements in the imitation learning setting for single-agent games. We first\ndemonstrate our findings on a variety of Atari games, and thereafter focus on\nthe extremely challenging game of NetHack. In all games, we find that IL loss\nand mean return scale smoothly with the compute budget (FLOPs) and are strongly\ncorrelated, resulting in power laws for training compute-optimal IL agents.\nFinally, we forecast and train several NetHack agents with IL and find they\noutperform prior state-of-the-art by 1.5x in all settings. Our work both\ndemonstrates the scaling behavior of imitation learning in a variety of\nsingle-agent games, as well as the viability of scaling up current approaches\nfor increasingly capable agents in NetHack, a game that remains elusively hard\nfor current AI systems.\n","authors":["Jens Tuyls","Dhruv Madeka","Kari Torkkola","Dean Foster","Karthik Narasimhan","Sham Kakade"],"pdf_url":"https://arxiv.org/pdf/2307.09423v3.pdf","comment":"Accepted at TMLR 2024"},{"id":"http://arxiv.org/abs/2412.14916v1","updated":"2024-12-19T14:50:10Z","published":"2024-12-19T14:50:10Z","title":"From Point to probabilistic gradient boosting for claim frequency and\n  severity prediction","summary":"  Gradient boosting for decision tree algorithms are increasingly used in\nactuarial applications as they show superior predictive performance over\ntraditional generalized linear models. Many improvements and sophistications to\nthe first gradient boosting machine algorithm exist. We present in a unified\nnotation, and contrast, all the existing point and probabilistic gradient\nboosting for decision tree algorithms: GBM, XGBoost, DART, LightGBM, CatBoost,\nEGBM, PGBM, XGBoostLSS, cyclic GBM, and NGBoost. In this comprehensive\nnumerical study, we compare their performance on five publicly available\ndatasets for claim frequency and severity, of various size and comprising\ndifferent number of (high cardinality) categorical variables. We explain how\nvarying exposure-to-risk can be handled with boosting in frequency models. We\ncompare the algorithms on the basis of computational efficiency, predictive\nperformance, and model adequacy. LightGBM and XGBoostLSS win in terms of\ncomputational efficiency. The fully interpretable EGBM achieves competitive\npredictive performance compared to the black box algorithms considered. We find\nthat there is no trade-off between model adequacy and predictive accuracy: both\nare achievable simultaneously.\n","authors":["Dominik Chevalier","Marie-Pier Côté"],"pdf_url":"https://arxiv.org/pdf/2412.14916v1.pdf","comment":"26 pages, 4 figures, 26 tables, 7 algorithms"},{"id":"http://arxiv.org/abs/2311.18512v2","updated":"2024-12-19T14:46:05Z","published":"2023-11-30T12:40:23Z","title":"Union-over-Intersections: Object Detection beyond Winner-Takes-All","summary":"  This paper revisits the problem of predicting box locations in object\ndetection architectures. Typically, each box proposal or box query aims to\ndirectly maximize the intersection-over-union score with the ground truth,\nfollowed by a winner-takes-all non-maximum suppression where only the highest\nscoring box in each region is retained. We observe that both steps are\nsub-optimal: the first involves regressing proposals to the entire ground\ntruth, which is a difficult task even with large receptive fields, and the\nsecond neglects valuable information from boxes other than the top candidate.\nInstead of regressing proposals to the whole ground truth, we propose a simpler\napproach: regress only to the area of intersection between the proposal and the\nground truth. This avoids the need for proposals to extrapolate beyond their\nvisual scope, improving localization accuracy. Rather than adopting a\nwinner-takes-all strategy, we take the union over the regressed intersections\nof all boxes in a region to generate the final box outputs. Our plug-and-play\nmethod integrates seamlessly into proposal-based, grid-based, and query-based\ndetection architectures with minimal modifications, consistently improving\nobject localization and instance segmentation. We demonstrate its broad\napplicability and versatility across various detection and segmentation tasks.\n","authors":["Aritra Bhowmik","Pascal Mettes","Martin R. Oswald","Cees G. M. Snoek"],"pdf_url":"https://arxiv.org/pdf/2311.18512v2.pdf","comment":"17 pages, 6 figures, 12 tables"},{"id":"http://arxiv.org/abs/2412.14075v2","updated":"2024-12-19T14:41:03Z","published":"2024-12-18T17:19:55Z","title":"Online MDP with Transition Prototypes: A Robust Adaptive Approach","summary":"  In this work, we consider an online robust Markov Decision Process (MDP)\nwhere we have the information of finitely many prototypes of the underlying\ntransition kernel. We consider an adaptively updated ambiguity set of the\nprototypes and propose an algorithm that efficiently identifies the true\nunderlying transition kernel while guaranteeing the performance of the\ncorresponding robust policy. To be more specific, we provide a sublinear regret\nof the subsequent optimal robust policy. We also provide an early stopping\nmechanism and a worst-case performance bound of the value function. In\nnumerical experiments, we demonstrate that our method outperforms existing\napproaches, particularly in the early stage with limited data. This work\ncontributes to robust MDPs by considering possible prior information about the\nunderlying transition probability and online learning, offering both\ntheoretical insights and practical algorithms for improved decision-making\nunder uncertainty.\n","authors":["Shuo Sun","Meng Qi","Zuo-Jun Max Shen"],"pdf_url":"https://arxiv.org/pdf/2412.14075v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2406.11544v4","updated":"2024-12-19T14:33:00Z","published":"2024-06-17T13:42:28Z","title":"Do Parameters Reveal More than Loss for Membership Inference?","summary":"  Membership inference attacks are used as a key tool for disclosure auditing.\nThey aim to infer whether an individual record was used to train a model. While\nsuch evaluations are useful to demonstrate risk, they are computationally\nexpensive and often make strong assumptions about potential adversaries' access\nto models and training environments, and thus do not provide tight bounds on\nleakage from potential attacks. We show how prior claims around black-box\naccess being sufficient for optimal membership inference do not hold for\nstochastic gradient descent, and that optimal membership inference indeed\nrequires white-box access. Our theoretical results lead to a new white-box\ninference attack, IHA (Inverse Hessian Attack), that explicitly uses model\nparameters by taking advantage of computing inverse-Hessian vector products.\nOur results show that both auditors and adversaries may be able to benefit from\naccess to model parameters, and we advocate for further research into white-box\nmethods for membership inference.\n","authors":["Anshuman Suri","Xiao Zhang","David Evans"],"pdf_url":"https://arxiv.org/pdf/2406.11544v4.pdf","comment":"Accepted to Transactions on Machine Learning Research (TMLR)"},{"id":"http://arxiv.org/abs/2412.14897v1","updated":"2024-12-19T14:28:00Z","published":"2024-12-19T14:28:00Z","title":"Diffusion priors for Bayesian 3D reconstruction from incomplete\n  measurements","summary":"  Many inverse problems are ill-posed and need to be complemented by prior\ninformation that restricts the class of admissible models. Bayesian approaches\nencode this information as prior distributions that impose generic properties\non the model such as sparsity, non-negativity or smoothness. However, in case\nof complex structured models such as images, graphs or three-dimensional (3D)\nobjects,generic prior distributions tend to favor models that differ largely\nfrom those observed in the real world. Here we explore the use of diffusion\nmodels as priors that are combined with experimental data within a Bayesian\nframework. We use 3D point clouds to represent 3D objects such as household\nitems or biomolecular complexes formed from proteins and nucleic acids. We\ntrain diffusion models that generate coarse-grained 3D structures at a medium\nresolution and integrate these with incomplete and noisy experimental data. To\ndemonstrate the power of our approach, we focus on the reconstruction of\nbiomolecular assemblies from cryo-electron microscopy (cryo-EM) images, which\nis an important inverse problem in structural biology. We find that posterior\nsampling with diffusion model priors allows for 3D reconstruction from very\nsparse, low-resolution and partial observations.\n","authors":["Julian L. Möbius","Michael Habeck"],"pdf_url":"https://arxiv.org/pdf/2412.14897v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.01519v3","updated":"2024-12-19T14:26:22Z","published":"2024-09-03T01:26:21Z","title":"Hybridization of Persistent Homology with Neural Networks for\n  Time-Series Prediction: A Case Study in Wave Height","summary":"  Time-series prediction is an active area of research across various fields,\noften challenged by the fluctuating influence of short-term and long-term\nfactors. In this study, we introduce a feature engineering method that enhances\nthe predictive performance of neural network models. Specifically, we leverage\ncomputational topology techniques to derive valuable topological features from\ninput data, boosting the predictive accuracy of our models. Our focus is on\npredicting wave heights, utilizing models based on topological features within\nfeedforward neural networks (FNNs), recurrent neural networks (RNNs), long\nshort-term memory networks (LSTM), and RNNs with gated recurrent units (GRU).\nFor time-ahead predictions, the enhancements in $R^2$ score were significant\nfor FNNs, RNNs, LSTM, and GRU models. Additionally, these models also showed\nsignificant reductions in maximum errors and mean squared errors.\n","authors":["Zixin Lin","Nur Fariha Syaqina Zulkepli","Mohd Shareduwan Mohd Kasihmuddin","R. U. Gobithaasan"],"pdf_url":"https://arxiv.org/pdf/2409.01519v3.pdf","comment":"the paper contain errors"},{"id":"http://arxiv.org/abs/2405.14573v4","updated":"2024-12-19T14:19:02Z","published":"2024-05-23T13:48:54Z","title":"AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents","summary":"  Autonomous agents that execute human tasks by controlling computers can\nenhance human productivity and application accessibility. However, progress in\nthis field will be driven by realistic and reproducible benchmarks. We present\nAndroidWorld, a fully functional Android environment that provides reward\nsignals for 116 programmatic tasks across 20 real-world Android apps. Unlike\nexisting interactive environments, which provide a static test set,\nAndroidWorld dynamically constructs tasks that are parameterized and expressed\nin natural language in unlimited ways, thus enabling testing on a much larger\nand more realistic suite of tasks. To ensure reproducibility, each task\nincludes dedicated initialization, success-checking, and tear-down logic, which\nmodifies and inspects the device's system state. We experiment with baseline\nagents to test AndroidWorld and provide initial results on the benchmark. Our\nbest agent can complete 30.6% of AndroidWorld's tasks, leaving ample room for\nfuture work. Furthermore, we adapt a popular desktop web agent to work on\nAndroid, which we find to be less effective on mobile, suggesting future\nresearch is needed to achieve universal, cross-platform agents. Finally, we\nalso conduct a robustness analysis, showing that task variations can\nsignificantly affect agent performance, demonstrating that without such\ntesting, agent performance metrics may not fully reflect practical challenges.\nAndroidWorld and the experiments in this paper are available at\ngithub.com/google-research/android_world.\n","authors":["Christopher Rawles","Sarah Clinckemaillie","Yifan Chang","Jonathan Waltz","Gabrielle Lau","Marybeth Fair","Alice Li","William Bishop","Wei Li","Folawiyo Campbell-Ajala","Daniel Toyama","Robert Berry","Divya Tyamagundlu","Timothy Lillicrap","Oriana Riva"],"pdf_url":"https://arxiv.org/pdf/2405.14573v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2409.16684v2","updated":"2024-12-19T14:18:15Z","published":"2024-09-25T07:20:59Z","title":"Erase then Rectify: A Training-Free Parameter Editing Approach for\n  Cost-Effective Graph Unlearning","summary":"  Graph unlearning, which aims to eliminate the influence of specific nodes,\nedges, or attributes from a trained Graph Neural Network (GNN), is essential in\napplications where privacy, bias, or data obsolescence is a concern. However,\nexisting graph unlearning techniques often necessitate additional training on\nthe remaining data, leading to significant computational costs, particularly\nwith large-scale graphs. To address these challenges, we propose a two-stage\ntraining-free approach, Erase then Rectify (ETR), designed for efficient and\nscalable graph unlearning while preserving the model utility. Specifically, we\nfirst build a theoretical foundation showing that masking parameters critical\nfor unlearned samples enables effective unlearning. Building on this insight,\nthe Erase stage strategically edits model parameters to eliminate the impact of\nunlearned samples and their propagated influence on intercorrelated nodes. To\nfurther ensure the GNN's utility, the Rectify stage devises a gradient\napproximation method to estimate the model's gradient on the remaining dataset,\nwhich is then used to enhance model performance. Overall, ETR achieves graph\nunlearning without additional training or full training data access,\nsignificantly reducing computational overhead and preserving data privacy.\nExtensive experiments on seven public datasets demonstrate the consistent\nsuperiority of ETR in model utility, unlearning efficiency, and unlearning\neffectiveness, establishing it as a promising solution for real-world graph\nunlearning challenges.\n","authors":["Zhe-Rui Yang","Jindong Han","Chang-Dong Wang","Hao Liu"],"pdf_url":"https://arxiv.org/pdf/2409.16684v2.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2412.14869v1","updated":"2024-12-19T14:06:44Z","published":"2024-12-19T14:06:44Z","title":"AI-Powered Intracranial Hemorrhage Detection: A Co-Scale Convolutional\n  Attention Model with Uncertainty-Based Fuzzy Integral Operator and Feature\n  Screening","summary":"  Intracranial hemorrhage (ICH) refers to the leakage or accumulation of blood\nwithin the skull, which occurs due to the rupture of blood vessels in or around\nthe brain. If this condition is not diagnosed in a timely manner and\nappropriately treated, it can lead to serious complications such as decreased\nconsciousness, permanent neurological disabilities, or even death.The primary\naim of this study is to detect the occurrence or non-occurrence of ICH,\nfollowed by determining the type of subdural hemorrhage (SDH). These tasks are\nframed as two separate binary classification problems. By adding two layers to\nthe co-scale convolutional attention (CCA) classifier architecture, we\nintroduce a novel approach for ICH detection. In the first layer, after\nextracting features from different slices of computed tomography (CT) scan\nimages, we combine these features and select the 50 components that capture the\nhighest variance in the data, considering them as informative features. We then\nassess the discriminative power of these features using the bootstrap forest\nalgorithm, discarding those that lack sufficient discriminative ability between\ndifferent classes. This algorithm explicitly determines the contribution of\neach feature to the final prediction, assisting us in developing an explainable\nAI model. The features feed into a boosting neural network as a latent feature\nspace. In the second layer, we introduce a novel uncertainty-based fuzzy\nintegral operator to fuse information from different CT scan slices. This\noperator, by accounting for the dependencies between consecutive slices,\nsignificantly improves detection accuracy.\n","authors":["Mehdi Hosseini Chagahi","Md. Jalil Piran","Niloufar Delfan","Behzad Moshiri","Jaber Hatam Parikhan"],"pdf_url":"https://arxiv.org/pdf/2412.14869v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14865v1","updated":"2024-12-19T14:00:03Z","published":"2024-12-19T14:00:03Z","title":"Hierarchical Subspaces of Policies for Continual Offline Reinforcement\n  Learning","summary":"  In dynamic domains such as autonomous robotics and video game simulations,\nagents must continuously adapt to new tasks while retaining previously acquired\nskills. This ongoing process, known as Continual Reinforcement Learning,\npresents significant challenges, including the risk of forgetting past\nknowledge and the need for scalable solutions as the number of tasks increases.\nTo address these issues, we introduce HIerarchical LOW-rank Subspaces of\nPolicies (HILOW), a novel framework designed for continual learning in offline\nnavigation settings. HILOW leverages hierarchical policy subspaces to enable\nflexible and efficient adaptation to new tasks while preserving existing\nknowledge. We demonstrate, through a careful experimental study, the\neffectiveness of our method in both classical MuJoCo maze environments and\ncomplex video game-like simulations, showcasing competitive performance and\nsatisfying adaptability according to classical continual learning metrics, in\nparticular regarding memory usage. Our work provides a promising framework for\nreal-world applications where continuous learning from pre-collected data is\nessential.\n","authors":["Anthony Kobanda","Rémy Portelas","Odalric-Ambrym Maillard","Ludovic Denoyer"],"pdf_url":"https://arxiv.org/pdf/2412.14865v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14854v1","updated":"2024-12-19T13:48:49Z","published":"2024-12-19T13:48:49Z","title":"Surrogate-assisted multi-objective design of complex multibody systems","summary":"  The optimization of large-scale multibody systems is a numerically\nchallenging task, in particular when considering multiple conflicting criteria\nat the same time. In this situation, we need to approximate the Pareto set of\noptimal compromises, which is significantly more expensive than finding a\nsingle optimum in single-objective optimization. To prevent large costs, the\nusage of surrogate models, constructed from a small but informative number of\nexpensive model evaluations, is a very popular and widely studied approach. The\ncentral challenge then is to ensure a high quality (that is, near-optimality)\nof the solutions that were obtained using the surrogate model, which can be\nhard to guarantee with a single pre-computed surrogate. We present a\nback-and-forth approach between surrogate modeling and multi-objective\noptimization to improve the quality of the obtained solutions. Using the\nexample of an expensive-to-evaluate multibody system, we compare different\nstrategies regarding multi-objective optimization, sampling and also surrogate\nmodeling, to identify the most promising approach in terms of computational\nefficiency and solution quality.\n","authors":["Augustina C. Amakor","Manuel B. Berkemeier","Meike Wohlleben","Walter Sextro","Sebastian Peitz"],"pdf_url":"https://arxiv.org/pdf/2412.14854v1.pdf","comment":"arXiv admin note: text overlap with arXiv:2412.01566"},{"id":"http://arxiv.org/abs/2410.10929v6","updated":"2024-12-19T13:39:55Z","published":"2024-10-14T16:35:27Z","title":"ASTM :Autonomous Smart Traffic Management System Using Artificial\n  Intelligence CNN and LSTM","summary":"  In the modern world, the development of Artificial Intelligence (AI) has\ncontributed to improvements in various areas, including automation, computer\nvision, fraud detection, and more. AI can be leveraged to enhance the\nefficiency of Autonomous Smart Traffic Management (ASTM) systems and reduce\ntraffic congestion rates. This paper presents an Autonomous Smart Traffic\nManagement (STM) system that uses AI to improve traffic flow rates. The system\nemploys the YOLO V5 Convolutional Neural Network to detect vehicles in traffic\nmanagement images. Additionally, it predicts the number of vehicles for the\nnext 12 hours using a Recurrent Neural Network with Long Short-Term Memory\n(RNN-LSTM). The Smart Traffic Management Cycle Length Analysis manages the\ntraffic cycle length based on these vehicle predictions, aided by AI. From the\nresults of the RNN-LSTM model for predicting vehicle numbers over the next 12\nhours, we observe that the model predicts traffic with a Mean Squared Error\n(MSE) of 4.521 vehicles and a Root Mean Squared Error (RMSE) of 2.232 vehicles.\nAfter simulating the STM system in the CARLA simulation environment, we found\nthat the Traffic Management Congestion Flow Rate with ASTM (21 vehicles per\nminute) is 50\\% higher than the rate without STM (around 15 vehicles per\nminute). Additionally, the Traffic Management Vehicle Pass Delay with STM (5\nseconds per vehicle) is 70\\% lower than without STM (around 12 seconds per\nvehicle). These results demonstrate that the STM system using AI can increase\ntraffic flow by 50\\% and reduce vehicle pass delays by 70\\%.\n","authors":["Christofel Rio Goenawan"],"pdf_url":"https://arxiv.org/pdf/2410.10929v6.pdf","comment":"In process to IEEE Intelligent Vehicle Symposium 2025"},{"id":"http://arxiv.org/abs/2408.11778v2","updated":"2024-12-19T13:34:56Z","published":"2024-08-21T17:08:05Z","title":"Sum of Squares Circuits","summary":"  Designing expressive generative models that support exact and efficient\ninference is a core question in probabilistic ML. Probabilistic circuits (PCs)\noffer a framework where this tractability-vs-expressiveness trade-off can be\nanalyzed theoretically. Recently, squared PCs encoding subtractive mixtures via\nnegative parameters have emerged as tractable models that can be exponentially\nmore expressive than monotonic PCs, i.e., PCs with positive parameters only. In\nthis paper, we provide a more precise theoretical characterization of the\nexpressiveness relationships among these models. First, we prove that squared\nPCs can be less expressive than monotonic ones. Second, we formalize a novel\nclass of PCs -- sum of squares PCs -- that can be exponentially more expressive\nthan both squared and monotonic PCs. Around sum of squares PCs, we build an\nexpressiveness hierarchy that allows us to precisely unify and separate\ndifferent tractable model classes such as Born Machines and PSD models, and\nother recently introduced tractable probabilistic models by using complex\nparameters. Finally, we empirically show the effectiveness of sum of squares\ncircuits in performing distribution estimation.\n","authors":["Lorenzo Loconte","Stefan Mengel","Antonio Vergari"],"pdf_url":"https://arxiv.org/pdf/2408.11778v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09116v3","updated":"2024-12-19T13:27:49Z","published":"2024-12-12T09:51:18Z","title":"How to Re-enable PDE Loss for Physical Systems Modeling Under Partial\n  Observation","summary":"  In science and engineering, machine learning techniques are increasingly\nsuccessful in physical systems modeling (predicting future states of physical\nsystems). Effectively integrating PDE loss as a constraint of system transition\ncan improve the model's prediction by overcoming generalization issues due to\ndata scarcity, especially when data acquisition is costly. However, in many\nreal-world scenarios, due to sensor limitations, the data we can obtain is\noften only partial observation, making the calculation of PDE loss seem to be\ninfeasible, as the PDE loss heavily relies on high-resolution states. We\ncarefully study this problem and propose a novel framework named Re-enable PDE\nLoss under Partial Observation (RPLPO). The key idea is that although enabling\nPDE loss to constrain system transition solely is infeasible, we can re-enable\nPDE loss by reconstructing the learnable high-resolution state and constraining\nsystem transition simultaneously. Specifically, RPLPO combines an encoding\nmodule for reconstructing learnable high-resolution states with a transition\nmodule for predicting future states. The two modules are jointly trained by\ndata and PDE loss. We conduct experiments in various physical systems to\ndemonstrate that RPLPO has significant improvement in generalization, even when\nobservation is sparse, irregular, noisy, and PDE is inaccurate.\n","authors":["Haodong Feng","Yue Wang","Dixia Fan"],"pdf_url":"https://arxiv.org/pdf/2412.09116v3.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2305.09565v2","updated":"2024-12-19T13:27:40Z","published":"2023-05-16T16:02:18Z","title":"Toward Falsifying Causal Graphs Using a Permutation-Based Test","summary":"  Understanding causal relationships among the variables of a system is\nparamount to explain and control its behavior. For many real-world systems,\nhowever, the true causal graph is not readily available and one must resort to\npredictions made by algorithms or domain experts. Therefore, metrics that\nquantitatively assess the goodness of a causal graph provide helpful checks\nbefore using it in downstream tasks. Existing metrics provide an\n$\\textit{absolute}$ number of inconsistencies between the graph and the\nobserved data, and without a baseline, practitioners are left to answer the\nhard question of how many such inconsistencies are acceptable or expected.\nHere, we propose a novel consistency metric by constructing a baseline through\nnode permutations. By comparing the number of inconsistencies with those on the\nbaseline, we derive an interpretable metric that captures whether the graph is\nsignificantly better than random. Evaluating on both simulated and real data\nsets from various domains, including biology and cloud monitoring, we\ndemonstrate that the true graph is not falsified by our metric, whereas the\nwrong graphs given by a hypothetical user are likely to be falsified.\n","authors":["Elias Eulig","Atalanti A. Mastakouri","Patrick Blöbaum","Michaela Hardt","Dominik Janzing"],"pdf_url":"https://arxiv.org/pdf/2305.09565v2.pdf","comment":"Camera-ready version for AAAI 2025"},{"id":"http://arxiv.org/abs/2412.14834v1","updated":"2024-12-19T13:24:01Z","published":"2024-12-19T13:24:01Z","title":"Entropy Regularized Task Representation Learning for Offline\n  Meta-Reinforcement Learning","summary":"  Offline meta-reinforcement learning aims to equip agents with the ability to\nrapidly adapt to new tasks by training on data from a set of different tasks.\nContext-based approaches utilize a history of state-action-reward transitions\n-- referred to as the context -- to infer representations of the current task,\nand then condition the agent, i.e., the policy and value function, on the task\nrepresentations. Intuitively, the better the task representations capture the\nunderlying tasks, the better the agent can generalize to new tasks.\nUnfortunately, context-based approaches suffer from distribution mismatch, as\nthe context in the offline data does not match the context at test time,\nlimiting their ability to generalize to the test tasks. This leads to the task\nrepresentations overfitting to the offline training data. Intuitively, the task\nrepresentations should be independent of the behavior policy used to collect\nthe offline data. To address this issue, we approximately minimize the mutual\ninformation between the distribution over the task representations and behavior\npolicy by maximizing the entropy of behavior policy conditioned on the task\nrepresentations. We validate our approach in MuJoCo environments, showing that\ncompared to baselines, our task representations more faithfully represent the\nunderlying tasks, leading to outperforming prior methods in both\nin-distribution and out-of-distribution tasks.\n","authors":["Mohammadreza nakhaei","Aidan Scannell","Joni Pajarinen"],"pdf_url":"https://arxiv.org/pdf/2412.14834v1.pdf","comment":"7 Pages, Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2406.02765v5","updated":"2024-12-19T13:16:21Z","published":"2024-06-04T20:33:29Z","title":"Discovering Continuous-Time Memory-Based Symbolic Policies using Genetic\n  Programming","summary":"  Artificial intelligence techniques are increasingly being applied to solve\ncontrol problems, but often rely on black-box methods without transparent\noutput generation. To improve the interpretability and transparency in control\nsystems, models can be defined as white-box symbolic policies described by\nmathematical expressions. For better performance in partially observable and\nvolatile environments, the symbolic policies are extended with memory\nrepresented by continuous-time latent variables, governed by differential\nequations. Genetic programming is used for optimisation, resulting in\ninterpretable policies consisting of symbolic expressions. Our results show\nthat symbolic policies with memory compare with black-box policies on a variety\nof control tasks. Furthermore, the benefit of the memory in symbolic policies\nis demonstrated on experiments where memory-less policies fall short. Overall,\nwe present a method for evolving high-performing symbolic policies that offer\ninterpretability and transparency, which lacks in black-box models.\n","authors":["Sigur de Vries","Sander Keemink","Marcel van Gerven"],"pdf_url":"https://arxiv.org/pdf/2406.02765v5.pdf","comment":"21 pages including references and appendix, 5 figures, 1 algorithm, 5\n  tables"},{"id":"http://arxiv.org/abs/2412.14814v1","updated":"2024-12-19T13:09:06Z","published":"2024-12-19T13:09:06Z","title":"Answer Set Networks: Casting Answer Set Programming into Deep Learning","summary":"  Although Answer Set Programming (ASP) allows constraining neural-symbolic\n(NeSy) systems, its employment is hindered by the prohibitive costs of\ncomputing stable models and the CPU-bound nature of state-of-the-art solvers.\nTo this end, we propose Answer Set Networks (ASN), a NeSy solver. Based on\nGraph Neural Networks (GNN), ASNs are a scalable approach to ASP-based Deep\nProbabilistic Logic Programming (DPPL). Specifically, we show how to translate\nASPs into ASNs and demonstrate how ASNs can efficiently solve the encoded\nproblem by leveraging GPU's batching and parallelization capabilities. Our\nexperimental evaluations demonstrate that ASNs outperform state-of-the-art\nCPU-bound NeSy systems on multiple tasks. Simultaneously, we make the following\ntwo contributions based on the strengths of ASNs. Namely, we are the first to\nshow the finetuning of Large Language Models (LLM) with DPPLs, employing ASNs\nto guide the training with logic. Further, we show the \"constitutional\nnavigation\" of drones, i.e., encoding public aviation laws in an ASN for\nrouting Unmanned Aerial Vehicles in uncertain environments.\n","authors":["Arseny Skryagin","Daniel Ochs","Phillip Deibert","Simon Kohaut","Devendra Singh Dhami","Kristian Kersting"],"pdf_url":"https://arxiv.org/pdf/2412.14814v1.pdf","comment":"16 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.10341v2","updated":"2024-12-19T13:03:10Z","published":"2024-12-13T18:38:47Z","title":"Shape error prediction in 5-axis machining using graph neural networks","summary":"  This paper presents an innovative method for predicting shape errors in\n5-axis machining using graph neural networks. The graph structure is defined\nwith nodes representing workpiece surface points and edges denoting the\nneighboring relationships. The dataset encompasses data from a material removal\nsimulation, process data, and post-machining quality information. Experimental\nresults show that the presented approach can generalize the shape error\nprediction for the investigated workpiece geometry. Moreover, by modelling\nspatial and temporal connections within the workpiece, the approach handles a\nlow number of labels compared to non-graphical methods such as Support Vector\nMachines.\n","authors":["Julia Huuk","Abheek Dhingra","Eirini Ntoutsi","Berend Denkena"],"pdf_url":"https://arxiv.org/pdf/2412.10341v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14810v1","updated":"2024-12-19T13:00:03Z","published":"2024-12-19T13:00:03Z","title":"MARIA: a Multimodal Transformer Model for Incomplete Healthcare Data","summary":"  In healthcare, the integration of multimodal data is pivotal for developing\ncomprehensive diagnostic and predictive models. However, managing missing data\nremains a significant challenge in real-world applications. We introduce MARIA\n(Multimodal Attention Resilient to Incomplete datA), a novel transformer-based\ndeep learning model designed to address these challenges through an\nintermediate fusion strategy. Unlike conventional approaches that depend on\nimputation, MARIA utilizes a masked self-attention mechanism, which processes\nonly the available data without generating synthetic values. This approach\nenables it to effectively handle incomplete datasets, enhancing robustness and\nminimizing biases introduced by imputation methods. We evaluated MARIA against\n10 state-of-the-art machine learning and deep learning models across 8\ndiagnostic and prognostic tasks. The results demonstrate that MARIA outperforms\nexisting methods in terms of performance and resilience to varying levels of\ndata incompleteness, underscoring its potential for critical healthcare\napplications.\n","authors":["Camillo Maria Caruso","Paolo Soda","Valerio Guarrasi"],"pdf_url":"https://arxiv.org/pdf/2412.14810v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14802v1","updated":"2024-12-19T12:48:17Z","published":"2024-12-19T12:48:17Z","title":"Stack Trace Deduplication: Faster, More Accurately, and in More\n  Realistic Scenarios","summary":"  In large-scale software systems, there are often no fully-fledged bug reports\nwith human-written descriptions when an error occurs. In this case, developers\nrely on stack traces, i.e., series of function calls that led to the error.\nSince there can be tens and hundreds of thousands of them describing the same\nissue from different users, automatic deduplication into categories is\nnecessary to allow for processing. Recent works have proposed powerful deep\nlearning-based approaches for this, but they are evaluated and compared in\nisolation from real-life workflows, and it is not clear whether they will\nactually work well at scale.\n  To overcome this gap, this work presents three main contributions: a novel\nmodel, an industry-based dataset, and a multi-faceted evaluation. Our model\nconsists of two parts - (1) an embedding model with byte-pair encoding and\napproximate nearest neighbor search to quickly find the most relevant stack\ntraces to the incoming one, and (2) a reranker that re-ranks the most fitting\nstack traces, taking into account the repeated frames between them. To\ncomplement the existing datasets collected from open-source projects, we share\nwith the community SlowOps - a dataset of stack traces from IntelliJ-based\nproducts developed by JetBrains, which has an order of magnitude more stack\ntraces per category. Finally, we carry out an evaluation that strives to be\nrealistic: measuring not only the accuracy of categorization, but also the\noperation time and the ability to create new categories. The evaluation shows\nthat our model strikes a good balance - it outperforms other models on both\nopen-source datasets and SlowOps, while also being faster on time than most. We\nrelease all of our code and data, and hope that our work can pave the way to\nfurther practice-oriented research in the area.\n","authors":["Egor Shibaev","Denis Sushentsev","Yaroslav Golubev","Aleksandr Khvorov"],"pdf_url":"https://arxiv.org/pdf/2412.14802v1.pdf","comment":"Published at SANER'25. 11 pages, 2 figures"},{"id":"http://arxiv.org/abs/2412.14801v1","updated":"2024-12-19T12:47:21Z","published":"2024-12-19T12:47:21Z","title":"Extending TWIG: Zero-Shot Predictive Hyperparameter Selection for KGEs\n  based on Graph Structure","summary":"  Knowledge Graphs (KGs) have seen increasing use across various domains --\nfrom biomedicine and linguistics to general knowledge modelling. In order to\nfacilitate the analysis of knowledge graphs, Knowledge Graph Embeddings (KGEs)\nhave been developed to automatically analyse KGs and predict new facts based on\nthe information in a KG, a task called \"link prediction\". Many existing studies\nhave documented that the structure of a KG, KGE model components, and KGE\nhyperparameters can significantly change how well KGEs perform and what\nrelationships they are able to learn. Recently, the Topologically-Weighted\nIntelligence Generation (TWIG) model has been proposed as a solution to\nmodelling how each of these elements relate. In this work, we extend the\nprevious research on TWIG and evaluate its ability to simulate the output of\nthe KGE model ComplEx in the cross-KG setting. Our results are twofold. First,\nTWIG is able to summarise KGE performance on a wide range of hyperparameter\nsettings and KGs being learned, suggesting that it represents a general\nknowledge of how to predict KGE performance from KG structure. Second, we show\nthat TWIG can successfully predict hyperparameter performance on unseen KGs in\nthe zero-shot setting. This second observation leads us to propose that, with\nadditional research, optimal hyperparameter selection for KGE models could be\ndetermined in a pre-hoc manner using TWIG-like methods, rather than by using a\nfull hyperparameter search.\n","authors":["Jeffrey Sardina","John D. Kelleher","Declan O'Sullivan"],"pdf_url":"https://arxiv.org/pdf/2412.14801v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11448v3","updated":"2024-12-19T12:46:27Z","published":"2024-12-16T05:02:50Z","title":"TRAIL: Trust-Aware Client Scheduling for Semi-Decentralized Federated\n  Learning","summary":"  Due to the sensitivity of data, Federated Learning (FL) is employed to enable\ndistributed machine learning while safeguarding data privacy and accommodating\nthe requirements of various devices. However, in the context of\nsemi-decentralized FL, clients' communication and training states are dynamic.\nThis variability arises from local training fluctuations, heterogeneous data\ndistributions, and intermittent client participation. Most existing studies\nprimarily focus on stable client states, neglecting the dynamic challenges\ninherent in real-world scenarios. To tackle this issue, we propose a\nTRust-Aware clIent scheduLing mechanism called TRAIL, which assesses client\nstates and contributions, enhancing model training efficiency through selective\nclient participation. We focus on a semi-decentralized FL framework where edge\nservers and clients train a shared global model using unreliable intra-cluster\nmodel aggregation and inter-cluster model consensus. First, we propose an\nadaptive hidden semi-Markov model to estimate clients' communication states and\ncontributions. Next, we address a client-server association optimization\nproblem to minimize global training loss. Using convergence analysis, we\npropose a greedy client scheduling algorithm. Finally, our experiments\nconducted on real-world datasets demonstrate that TRAIL outperforms\nstate-of-the-art baselines, achieving an improvement of 8.7% in test accuracy\nand a reduction of 15.3% in training loss.\n","authors":["Gangqiang Hu","Jianfeng Lu","Jianmin Han","Shuqin Cao","Jing Liu","Hao Fu"],"pdf_url":"https://arxiv.org/pdf/2412.11448v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.05317v3","updated":"2024-12-19T12:38:23Z","published":"2024-10-05T03:47:06Z","title":"Accelerating Diffusion Transformers with Token-wise Feature Caching","summary":"  Diffusion transformers have shown significant effectiveness in both image and\nvideo synthesis at the expense of huge computation costs. To address this\nproblem, feature caching methods have been introduced to accelerate diffusion\ntransformers by caching the features in previous timesteps and reusing them in\nthe following timesteps. However, previous caching methods ignore that\ndifferent tokens exhibit different sensitivities to feature caching, and\nfeature caching on some tokens may lead to 10$\\times$ more destruction to the\noverall generation quality compared with other tokens. In this paper, we\nintroduce token-wise feature caching, allowing us to adaptively select the most\nsuitable tokens for caching, and further enable us to apply different caching\nratios to neural layers in different types and depths. Extensive experiments on\nPixArt-$\\alpha$, OpenSora, and DiT demonstrate our effectiveness in both image\nand video generation with no requirements for training. For instance,\n2.36$\\times$ and 1.93$\\times$ acceleration are achieved on OpenSora and\nPixArt-$\\alpha$ with almost no drop in generation quality.\n","authors":["Chang Zou","Xuyang Liu","Ting Liu","Siteng Huang","Linfeng Zhang"],"pdf_url":"https://arxiv.org/pdf/2410.05317v3.pdf","comment":"In this version, we achieved a nearly lossless acceleration of 1.51\n  times for ToCa on FLUX in the appendix"},{"id":"http://arxiv.org/abs/2406.05666v9","updated":"2024-12-19T12:13:26Z","published":"2024-06-09T06:49:22Z","title":"Probability Distribution Learning and Its Application in Deep Learning","summary":"  This paper introduces a novel theoretical learning framework, termed\nprobability distribution learning (PD learning). Departing from the traditional\nstatistical learning framework, PD learning focuses on learning the underlying\nprobability distribution, which is modeled as a random variable within the\nprobability simplex. In this framework, the optimization objective is the\nlearning error, which quantifies the posterior expected discrepancy between the\nmodel's predicted distribution and the underlying true distribution, given\navailable sample data and prior knowledge. To optimize the learning error, this\npaper proposes the necessary conditions for loss functions, models, and\noptimization algorithms, ensuring that these conditions are met in real-world\nmachine learning scenarios. Based on these conditions, the non-convex\noptimization mechanism corresponding to model training can be theoretically\nresolved. Moreover, this paper provides model-dependent and model-independent\nbounds on learning error, offering new insights into the model's fitting and\ngeneralization capabilities. Furthermore, the paper applies the PD learning\nframework to elucidate the mechanisms by which various techniques, including\nrandom parameter initialization, over-parameterization, and dropout, influence\ndeep model training. Finally, the paper substantiates the key conclusions of\nthe proposed framework through experimental results.\n","authors":["Binchuan Qi"],"pdf_url":"https://arxiv.org/pdf/2406.05666v9.pdf","comment":"arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors. arXiv admin note: text overlap with arXiv:2105.04026 by other\n  authors"},{"id":"http://arxiv.org/abs/2412.09265v4","updated":"2024-12-19T12:11:13Z","published":"2024-12-12T13:22:02Z","title":"Score and Distribution Matching Policy: Advanced Accelerated Visuomotor\n  Policies via Matched Distillation","summary":"  Visual-motor policy learning has advanced with architectures like\ndiffusion-based policies, known for modeling complex robotic trajectories.\nHowever, their prolonged inference times hinder high-frequency control tasks\nrequiring real-time feedback. While consistency distillation (CD) accelerates\ninference, it introduces errors that compromise action quality. To address\nthese limitations, we propose the Score and Distribution Matching Policy (SDM\nPolicy), which transforms diffusion-based policies into single-step generators\nthrough a two-stage optimization process: score matching ensures alignment with\ntrue action distributions, and distribution matching minimizes KL divergence\nfor consistency. A dual-teacher mechanism integrates a frozen teacher for\nstability and an unfrozen teacher for adversarial training, enhancing\nrobustness and alignment with target distributions. Evaluated on a 57-task\nsimulation benchmark, SDM Policy achieves a 6x inference speedup while having\nstate-of-the-art action quality, providing an efficient and reliable framework\nfor high-frequency robotic tasks.\n","authors":["Bofang Jia","Pengxiang Ding","Can Cui","Mingyang Sun","Pengfang Qian","Siteng Huang","Zhaoxin Fan","Donglin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.09265v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.09826v4","updated":"2024-12-19T12:07:06Z","published":"2023-02-20T08:19:19Z","title":"On the Expressivity of Persistent Homology in Graph Learning","summary":"  Persistent homology, a technique from computational topology, has recently\nshown strong empirical performance in the context of graph classification.\nBeing able to capture long range graph properties via higher-order topological\nfeatures, such as cycles of arbitrary length, in combination with multi-scale\ntopological descriptors, has improved predictive performance for data sets with\nprominent topological structures, such as molecules. At the same time, the\ntheoretical properties of persistent homology have not been formally assessed\nin this context. This paper intends to bridge the gap between computational\ntopology and graph machine learning by providing a brief introduction to\npersistent homology in the context of graphs, as well as a theoretical\ndiscussion and empirical analysis of its expressivity for graph learning tasks.\n","authors":["Rubén Ballester","Bastian Rieck"],"pdf_url":"https://arxiv.org/pdf/2302.09826v4.pdf","comment":"Accepted at the 3rd Learning on Graphs Conference (LoG) 2024"},{"id":"http://arxiv.org/abs/2412.14779v1","updated":"2024-12-19T12:05:13Z","published":"2024-12-19T12:05:13Z","title":"Agent-Temporal Credit Assignment for Optimal Policy Preservation in\n  Sparse Multi-Agent Reinforcement Learning","summary":"  In multi-agent environments, agents often struggle to learn optimal policies\ndue to sparse or delayed global rewards, particularly in long-horizon tasks\nwhere it is challenging to evaluate actions at intermediate time steps. We\nintroduce Temporal-Agent Reward Redistribution (TAR$^2$), a novel approach\ndesigned to address the agent-temporal credit assignment problem by\nredistributing sparse rewards both temporally and across agents. TAR$^2$\ndecomposes sparse global rewards into time-step-specific rewards and calculates\nagent-specific contributions to these rewards. We theoretically prove that\nTAR$^2$ is equivalent to potential-based reward shaping, ensuring that the\noptimal policy remains unchanged. Empirical results demonstrate that TAR$^2$\nstabilizes and accelerates the learning process. Additionally, we show that\nwhen TAR$^2$ is integrated with single-agent reinforcement learning algorithms,\nit performs as well as or better than traditional multi-agent reinforcement\nlearning methods.\n","authors":["Aditya Kapoor","Sushant Swamy","Kale-ab Tessera","Mayank Baranwal","Mingfei Sun","Harshad Khadilkar","Stefano V. Albrecht"],"pdf_url":"https://arxiv.org/pdf/2412.14779v1.pdf","comment":"12 pages, 1 figure"},{"id":"http://arxiv.org/abs/2408.05428v2","updated":"2024-12-19T11:57:19Z","published":"2024-08-10T04:21:04Z","title":"Generalized Encouragement-Based Instrumental Variables for\n  Counterfactual Regression","summary":"  In causal inference, encouragement designs (EDs) are widely used to analyze\ncausal effects, when randomized controlled trials (RCTs) are impractical or\ncompliance to treatment cannot be perfectly enforced. Unlike RCTs, which\ndirectly allocate treatments, EDs randomly assign encouragement policies that\npositively motivate individuals to engage in a specific treatment. These random\nencouragements act as instrumental variables (IVs), facilitating the\nidentification of causal effects through leveraging exogenous perturbations in\ndiscrete treatment scenarios. However, real-world applications of encouragement\ndesigns often face challenges such as incomplete randomization, limited\nexperimental data, and significantly fewer encouragements compared to\ntreatments, hindering precise causal effect estimation. To address this, this\npaper introduces novel theories and algorithms for identifying the Conditional\nAverage Treatment Effect (CATE) using variations in encouragement. Further, by\nleveraging both observational and encouragement data, we propose a generalized\nIV estimator, named Encouragement-based Counterfactual Regression (EnCounteR),\nto effectively estimate the causal effects. Extensive experiments on both\nsynthetic and real-world datasets demonstrate the superiority of EnCounteR over\nexisting methods.\n","authors":["Anpeng Wu","Kun Kuang","Ruoxuan Xiong","Xiangwei Chen","Zexu Sun","Fei Wu","Kun Zhang"],"pdf_url":"https://arxiv.org/pdf/2408.05428v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14771v1","updated":"2024-12-19T11:55:51Z","published":"2024-12-19T11:55:51Z","title":"ALKAFI-LLAMA3: Fine-Tuning LLMs for Precise Legal Understanding in\n  Palestine","summary":"  Large Language Models (LLMs) have demonstrated remarkable potential in\ndiverse domains, yet their application in the legal sector, particularly in\nlow-resource contexts, remains limited. This study addresses the challenges of\nadapting LLMs to the Palestinian legal domain, where political instability,\nfragmented legal frameworks, and limited AI resources hinder effective\nmachine-learning applications. We present a fine-tuned model based on a\nquantized version of Llama-3.2-1B-Instruct, trained on a synthetic data set\nderived from Palestinian legal texts. Using smaller-scale models and\nstrategically generated question-answer pairs, we achieve a cost-effective,\nlocally sustainable solution that provides accurate and contextually relevant\nlegal guidance. Our experiments demonstrate promising performance on various\nquery types, ranging from yes/no questions and narrative explanations to\ncomplex legal differentiations, while highlighting areas for improvement, such\nas handling calculation-based inquiries and structured list formatting. This\nwork provides a pathway for the deployment of AI-driven legal assistance tools\ntailored to the needs of resource-constrained environments.\n","authors":["Rabee Qasem","Mohannad Hendi","Banan Tantour"],"pdf_url":"https://arxiv.org/pdf/2412.14771v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11654v2","updated":"2024-12-19T11:47:34Z","published":"2024-12-16T10:56:58Z","title":"Smoothness Really Matters: A Simple Yet Effective Approach for\n  Unsupervised Graph Domain Adaptation","summary":"  Unsupervised Graph Domain Adaptation (UGDA) seeks to bridge distribution\nshifts between domains by transferring knowledge from labeled source graphs to\ngiven unlabeled target graphs. Existing UGDA methods primarily focus on\naligning features in the latent space learned by graph neural networks (GNNs)\nacross domains, often overlooking structural shifts, resulting in limited\neffectiveness when addressing structurally complex transfer scenarios. Given\nthe sensitivity of GNNs to local structural features, even slight discrepancies\nbetween source and target graphs could lead to significant shifts in node\nembeddings, thereby reducing the effectiveness of knowledge transfer. To\naddress this issue, we introduce a novel approach for UGDA called Target-Domain\nStructural Smoothing (TDSS). TDSS is a simple and effective method designed to\nperform structural smoothing directly on the target graph, thereby mitigating\nstructural distribution shifts and ensuring the consistency of node\nrepresentations. Specifically, by integrating smoothing techniques with\nneighborhood sampling, TDSS maintains the structural coherence of the target\ngraph while mitigating the risk of over-smoothing. Our theoretical analysis\nshows that TDSS effectively reduces target risk by improving model smoothness.\nEmpirical results on three real-world datasets demonstrate that TDSS\noutperforms recent state-of-the-art baselines, achieving significant\nimprovements across six transfer scenarios. The code is available in\nhttps://github.com/cwei01/TDSS.\n","authors":["Wei Chen","Guo Ye","Yakun Wang","Zhao Zhang","Libang Zhang","Daxin Wang","Zhiqiang Zhang","Fuzhen Zhuang"],"pdf_url":"https://arxiv.org/pdf/2412.11654v2.pdf","comment":"11 pages, Accpected by AAAI2025"},{"id":"http://arxiv.org/abs/2311.07326v2","updated":"2024-12-19T11:41:28Z","published":"2023-11-13T13:27:59Z","title":"MetaSymNet: A Tree-like Symbol Network with Adaptive Architecture and\n  Activation Functions","summary":"  Mathematical formulas serve as the means of communication between humans and\nnature, encapsulating the operational laws governing natural phenomena. The\nconcise formulation of these laws is a crucial objective in scientific research\nand an important challenge for artificial intelligence (AI). While traditional\nartificial neural networks (MLP) excel at data fitting, they often yield\nuninterpretable black box results that hinder our understanding of the\nrelationship between variables x and predicted values y. Moreover, the fixed\nnetwork architecture in MLP often gives rise to redundancy in both network\nstructure and parameters. To address these issues, we propose MetaSymNet, a\nnovel neural network that dynamically adjusts its structure in real-time,\nallowing for both expansion and contraction. This adaptive network employs the\nPANGU meta function as its activation function, which is a unique type capable\nof evolving into various basic functions during training to compose\nmathematical formulas tailored to specific needs. We then evolve the neural\nnetwork into a concise, interpretable mathematical expression. To evaluate\nMetaSymNet's performance, we compare it with four state-of-the-art symbolic\nregression algorithms across more than 10 public datasets comprising 222\nformulas. Our experimental results demonstrate that our algorithm outperforms\nothers consistently regardless of noise presence or absence. Furthermore, we\nassess MetaSymNet against MLP and SVM regarding their fitting ability and\nextrapolation capability, these are two essential aspects of machine learning\nalgorithms. The findings reveal that our algorithm excels in both areas.\nFinally, we compared MetaSymNet with MLP using iterative pruning in network\nstructure complexity. The results show that MetaSymNet's network structure\ncomplexity is obviously less than MLP under the same goodness of fit.\n","authors":["Yanjie Li","Weijun Li","Lina Yu","Min Wu","Jinyi Liu","Wenqiang Li","Meilan Hao","Shu Wei","Yusong Deng"],"pdf_url":"https://arxiv.org/pdf/2311.07326v2.pdf","comment":"This work has been accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2412.14753v1","updated":"2024-12-19T11:34:22Z","published":"2024-12-19T11:34:22Z","title":"Opportunities and limitations of explaining quantum machine learning","summary":"  A common trait of many machine learning models is that it is often difficult\nto understand and explain what caused the model to produce the given output.\nWhile the explainability of neural networks has been an active field of\nresearch in the last years, comparably little is known for quantum machine\nlearning models. Despite a few recent works analyzing some specific aspects of\nexplainability, as of now there is no clear big picture perspective as to what\ncan be expected from quantum learning models in terms of explainability. In\nthis work, we address this issue by identifying promising research avenues in\nthis direction and lining out the expected future results. We additionally\npropose two explanation methods designed specifically for quantum machine\nlearning models, as first of their kind to the best of our knowledge. Next to\nour pre-view of the field, we compare both existing and novel methods to\nexplain the predictions of quantum learning models. By studying explainability\nin quantum machine learning, we can contribute to the sustainable development\nof the field, preventing trust issues in the future.\n","authors":["Elies Gil-Fuster","Jonas R. Naujoks","Grégoire Montavon","Thomas Wiegand","Wojciech Samek","Jens Eisert"],"pdf_url":"https://arxiv.org/pdf/2412.14753v1.pdf","comment":"16+16 pages, 3+4 figures"},{"id":"http://arxiv.org/abs/2412.14750v1","updated":"2024-12-19T11:29:57Z","published":"2024-12-19T11:29:57Z","title":"Deep Learning Based Recalibration of SDSS and DESI BAO Alleviates Hubble\n  and Clustering Tensions","summary":"  Conventional calibration of Baryon Acoustic Oscillations (BAO) data relies on\nestimation of the sound horizon at drag epoch $r_d$ from early universe\nobservations by assuming a cosmological model. We present a recalibration of\ntwo independent BAO datasets, SDSS and DESI, by employing deep learning\ntechniques for model-independent estimation of $r_d$, and explore the impacts\non $\\Lambda$CDM cosmological parameters. Significant reductions in both Hubble\n($H_0$) and clustering ($S_8$) tensions are observed for both the recalibrated\ndatasets. Moderate shifts in some other parameters hint towards further\nexploration of such data-driven approaches.\n","authors":["Rahul Shah","Purba Mukherjee","Soumadeep Saha","Utpal Garain","Supratik Pal"],"pdf_url":"https://arxiv.org/pdf/2412.14750v1.pdf","comment":"5 pages, 2 figures, 2 tables. Comments are welcome"},{"id":"http://arxiv.org/abs/2412.14744v1","updated":"2024-12-19T11:22:52Z","published":"2024-12-19T11:22:52Z","title":"A parametric algorithm is optimal for non-parametric regression of\n  smooth functions","summary":"  We address the regression problem for a general function $f:[-1,1]^d\\to\n\\mathbb R$ when the learner selects the training points $\\{x_i\\}_{i=1}^n$ to\nachieve a uniform error bound across the entire domain. In this setting, known\nhistorically as nonparametric regression, we aim to establish a sample\ncomplexity bound that depends solely on the function's degree of smoothness.\nAssuming periodicity at the domain boundaries, we introduce PADUA, an algorithm\nthat, with high probability, provides performance guarantees optimal up to\nconstant or logarithmic factors across all problem parameters. Notably, PADUA\nis the first parametric algorithm with optimal sample complexity for this\nsetting. Due to this feature, we prove that, differently from the\nnon-parametric state of the art, PADUA enjoys optimal space complexity in the\nprediction phase. To validate these results, we perform numerical experiments\nover functions coming from real audio data, where PADUA shows comparable\nperformance to state-of-the-art methods, while requiring only a fraction of the\ncomputational time.\n","authors":["Davide Maran","Marcello Restelli"],"pdf_url":"https://arxiv.org/pdf/2412.14744v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14741v1","updated":"2024-12-19T11:17:31Z","published":"2024-12-19T11:17:31Z","title":"Active Inference and Human--Computer Interaction","summary":"  Active Inference is a closed-loop computational theoretical basis for\nunderstanding behaviour, based on agents with internal probabilistic generative\nmodels that encode their beliefs about how hidden states in their environment\ncause their sensations. We review Active Inference and how it could be applied\nto model the human-computer interaction loop. Active Inference provides a\ncoherent framework for managing generative models of humans, their\nenvironments, sensors and interface components. It informs off-line design and\nsupports real-time, online adaptation. It provides model-based explanations for\nbehaviours observed in HCI, and new tools to measure important concepts such as\nagency and engagement. We discuss how Active Inference offers a new basis for a\ntheory of interaction in HCI, tools for design of modern, complex sensor-based\nsystems, and integration of artificial intelligence technologies, enabling it\nto cope with diversity in human users and contexts. We discuss the practical\nchallenges in implementing such Active Inference-based systems.\n","authors":["Roderick Murray-Smith","John H. Williamson","Sebastian Stein"],"pdf_url":"https://arxiv.org/pdf/2412.14741v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14739v1","updated":"2024-12-19T11:15:02Z","published":"2024-12-19T11:15:02Z","title":"On the Use of Deep Learning Models for Semantic Clone Detection","summary":"  Detecting and tracking code clones can ease various software development and\nmaintenance tasks when changes in a code fragment should be propagated over all\nits copies. Several deep learning-based clone detection models have appeared in\nthe literature for detecting syntactic and semantic clones, widely evaluated\nwith the BigCloneBench dataset. However, class imbalance and the small number\nof semantic clones make BigCloneBench less ideal for interpreting model\nperformance. Researchers also use other datasets such as GoogleCodeJam,\nOJClone, and SemanticCloneBench to understand model generalizability. To\novercome the limitations of existing datasets, the GPT-assisted semantic and\ncross-language clone dataset GPTCloneBench has been released. However, how\nthese models compare across datasets remains unclear. In this paper, we propose\na multi-step evaluation approach for five state-of-the-art clone detection\nmodels leveraging existing benchmark datasets, including GPTCloneBench, and\nusing mutation operators to study model ability. Specifically, we examine three\nhighly-performing single-language models (ASTNN, GMN, CodeBERT) on\nBigCloneBench, SemanticCloneBench, and GPTCloneBench, testing their robustness\nwith mutation operations. Additionally, we compare them against cross-language\nmodels (C4, CLCDSA) known for detecting semantic clones. While single-language\nmodels show high F1 scores for BigCloneBench, their performance on\nSemanticCloneBench varies (up to 20%). Interestingly, the cross-language model\n(C4) shows superior performance (around 7%) on SemanticCloneBench over other\nmodels and performs similarly on BigCloneBench and GPTCloneBench. On\nmutation-based datasets, C4 has more robust performance (less than 1%\ndifference) compared to single-language models, which show high variability.\n","authors":["Subroto Nag Pinku","Debajyoti Mondal","Chanchal K. Roy"],"pdf_url":"https://arxiv.org/pdf/2412.14739v1.pdf","comment":"Accepted at the 40th IEEE International Conference on Software\n  Maintenance and Evolution (ICSME 2024)"},{"id":"http://arxiv.org/abs/2409.11383v2","updated":"2024-12-19T11:12:30Z","published":"2024-09-17T17:34:24Z","title":"Training Datasets Generation for Machine Learning: Application to Vision\n  Based Navigation","summary":"  Vision Based Navigation consists in utilizing cameras as precision sensors\nfor GNC after extracting information from images. To enable the adoption of\nmachine learning for space applications, one of obstacles is the demonstration\nthat available training datasets are adequate to validate the algorithms. The\nobjective of the study is to generate datasets of images and metadata suitable\nfor training machine learning algorithms. Two use cases were selected and a\nrobust methodology was developed to validate the datasets including the ground\ntruth. The first use case is in-orbit rendezvous with a man-made object: a\nmockup of satellite ENVISAT. The second use case is a Lunar landing scenario.\nDatasets were produced from archival datasets (Chang'e 3), from the laboratory\nat DLR TRON facility and at Airbus Robotic laboratory, from SurRender software\nhigh fidelity image simulator using Model Capture and from Generative\nAdversarial Networks. The use case definition included the selection of\nalgorithms as benchmark: an AI-based pose estimation algorithm and a dense\noptical flow algorithm were selected. Eventually it is demonstrated that\ndatasets produced with SurRender and selected laboratory facilities are\nadequate to train machine learning algorithms.\n","authors":["Jérémy Lebreton","Ingo Ahrns","Roland Brochard","Christoph Haskamp","Hans Krüger","Matthieu Le Goff","Nicolas Menga","Nicolas Ollagnier","Ralf Regele","Francesco Capolupo","Massimo Casasco"],"pdf_url":"https://arxiv.org/pdf/2409.11383v2.pdf","comment":"6 pages, 4 figures, preprint of the proceedings of ESA SPAICE\n  conference 2024"},{"id":"http://arxiv.org/abs/2412.14738v1","updated":"2024-12-19T11:10:48Z","published":"2024-12-19T11:10:48Z","title":"Boosting GNN Performance via Training Sample Selection Based on\n  Adversarial Robustness Evaluation","summary":"  Graph Neural Networks (GNNs) have established themselves as one of the most\npowerful neural network architectures, excelling in leveraging graph topology\nand node features for various tasks. However, GNNs are inherently vulnerable to\nnoise in their inputs. Such noise can significantly degrade their performance.\nTo address this challenge, we propose a novel approach that employs adversarial\nrobustness evaluation techniques to identify nodes in the graph that are most\nsusceptible to noise. By selecting and constructing a training set composed of\nthese particularly noise-prone nodes, we then use them to train a Graph\nConvolutional Network (GCN). Our experimental results demonstrate that this\nstrategy leads to substantial improvements in the GCN's performance.\n","authors":["Yongyu Wang"],"pdf_url":"https://arxiv.org/pdf/2412.14738v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2404.10099v2","updated":"2024-12-19T11:06:39Z","published":"2024-04-15T19:15:32Z","title":"Feature selection in linear SVMs via a hard cardinality constraint: a\n  scalable SDP decomposition approach","summary":"  In this paper, we study the embedded feature selection problem in linear\nSupport Vector Machines (SVMs), in which a cardinality constraint is employed,\nleading to an interpretable classification model. The problem is NP-hard due to\nthe presence of the cardinality constraint, even though the original linear SVM\namounts to a problem solvable in polynomial time. To handle the hard problem,\nwe first introduce two mixed-integer formulations for which novel semidefinite\nrelaxations are proposed. Exploiting the sparsity pattern of the relaxations,\nwe decompose the problems and obtain equivalent relaxations in a much smaller\ncone, making the conic approaches scalable. To make the best usage of the\ndecomposed relaxations, we propose heuristics using the information of its\noptimal solution. Moreover, an exact procedure is proposed by solving a\nsequence of mixed-integer decomposed semidefinite optimization problems.\nNumerical results on classical benchmarking datasets are reported, showing the\nefficiency and effectiveness of our approach.\n","authors":["Immanuel Bomze","Federico D'Onofrio","Laura Palagi","Bo Peng"],"pdf_url":"https://arxiv.org/pdf/2404.10099v2.pdf","comment":"Submitted to European Journal of Operational Research. arXiv admin\n  note: text overlap with arXiv:1808.02435 by other authors"},{"id":"http://arxiv.org/abs/2309.11036v2","updated":"2024-12-19T10:58:39Z","published":"2023-09-20T03:31:11Z","title":"Scalable Acceleration for Classification-Based Derivative-Free\n  Optimization","summary":"  Derivative-free optimization algorithms play an important role in scientific\nand engineering design optimization problems, especially when derivative\ninformation is not accessible. In this paper, we study the framework of\nsequential classification-based derivative-free optimization algorithms. By\nintroducing learning theoretic concept hypothesis-target shattering rate, we\nrevisit the computational complexity upper bound of SRACOS (Hu, Qian, and Yu\n2017). Inspired by the revisited upper bound, we propose an algorithm named\nRACE-CARS, which adds a random region-shrinking step compared with SRACOS. We\nfurther establish theorems showing the acceleration by region shrinking.\nExperiments on the synthetic functions as well as black-box tuning for\nlanguage-model-as-a-service demonstrate empirically the efficiency of\nRACE-CARS. An ablation experiment on the introduced hyperparameters is also\nconducted, revealing the mechanism of RACE-CARS and putting forward an\nempirical hyper-parameter tuning guidance.\n","authors":["Tianyi Han","Jingya Li","Zhipeng Guo","Yuan Jin"],"pdf_url":"https://arxiv.org/pdf/2309.11036v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14730v1","updated":"2024-12-19T10:56:18Z","published":"2024-12-19T10:56:18Z","title":"Generative AI for Banks: Benchmarks and Algorithms for Synthetic\n  Financial Transaction Data","summary":"  The banking sector faces challenges in using deep learning due to data\nsensitivity and regulatory constraints, but generative AI may offer a solution.\nThus, this study identifies effective algorithms for generating synthetic\nfinancial transaction data and evaluates five leading models - Conditional\nTabular Generative Adversarial Networks (CTGAN), DoppelGANger (DGAN),\nWasserstein GAN, Financial Diffusion (FinDiff), and Tabular Variational\nAutoEncoders (TVAE) - across five criteria: fidelity, synthesis quality,\nefficiency, privacy, and graph structure. While none of the algorithms is able\nto replicate the real data's graph structure, each excels in specific areas:\nDGAN is ideal for privacy-sensitive tasks, FinDiff and TVAE excel in data\nreplication and augmentation, and CTGAN achieves a balance across all five\ncriteria, making it suitable for general applications with moderate privacy\nconcerns. As a result, our findings offer valuable insights for choosing the\nmost suitable algorithm.\n","authors":["Fabian Sven Karst","Sook-Yee Chong","Abigail A. Antenor","Enyu Lin","Mahei Manhai Li","Jan Marco Leimeister"],"pdf_url":"https://arxiv.org/pdf/2412.14730v1.pdf","comment":"Presented at the 34th Workshop on Information Technologies and\n  Systems (WITS 2024)"},{"id":"http://arxiv.org/abs/2412.14724v1","updated":"2024-12-19T10:47:31Z","published":"2024-12-19T10:47:31Z","title":"FROC: Building Fair ROC from a Trained Classifier","summary":"  This paper considers the problem of fair probabilistic binary classification\nwith binary protected groups. The classifier assigns scores, and a practitioner\npredicts labels using a certain cut-off threshold based on the desired\ntrade-off between false positives vs. false negatives. It derives these\nthresholds from the ROC of the classifier. The resultant classifier may be\nunfair to one of the two protected groups in the dataset. It is desirable that\nno matter what threshold the practitioner uses, the classifier should be fair\nto both the protected groups; that is, the $\\mathcal{L}_p$ norm between FPRs\nand TPRs of both the protected groups should be at most $\\varepsilon$. We call\nsuch fairness on ROCs of both the protected attributes\n$\\varepsilon_p$-Equalized ROC. Given a classifier not satisfying\n$\\varepsilon_1$-Equalized ROC, we aim to design a post-processing method to\ntransform the given (potentially unfair) classifier's output (score) to a\nsuitable randomized yet fair classifier. That is, the resultant classifier must\nsatisfy $\\varepsilon_1$-Equalized ROC. First, we introduce a threshold query\nmodel on the ROC curves for each protected group. The resulting classifier is\nbound to face a reduction in AUC. With the proposed query model, we provide a\nrigorous theoretical analysis of the minimal AUC loss to achieve\n$\\varepsilon_1$-Equalized ROC. To achieve this, we design a linear time\nalgorithm, namely \\texttt{FROC}, to transform a given classifier's output to a\nprobabilistic classifier that satisfies $\\varepsilon_1$-Equalized ROC. We prove\nthat under certain theoretical conditions, \\texttt{FROC}\\ achieves the\ntheoretical optimal guarantees. We also study the performance of our\n\\texttt{FROC}\\ on multiple real-world datasets with many trained classifiers.\n","authors":["Avyukta Manjunatha Vummintala","Shantanu Das","Sujit Gujar"],"pdf_url":"https://arxiv.org/pdf/2412.14724v1.pdf","comment":"51 pages, The 39th Annual AAAI Conference on Artificial Intelligence"},{"id":"http://arxiv.org/abs/2406.02507v3","updated":"2024-12-19T10:43:11Z","published":"2024-06-04T17:25:59Z","title":"Guiding a Diffusion Model with a Bad Version of Itself","summary":"  The primary axes of interest in image-generating diffusion models are image\nquality, the amount of variation in the results, and how well the results align\nwith a given condition, e.g., a class label or a text prompt. The popular\nclassifier-free guidance approach uses an unconditional model to guide a\nconditional model, leading to simultaneously better prompt alignment and\nhigher-quality images at the cost of reduced variation. These effects seem\ninherently entangled, and thus hard to control. We make the surprising\nobservation that it is possible to obtain disentangled control over image\nquality without compromising the amount of variation by guiding generation\nusing a smaller, less-trained version of the model itself rather than an\nunconditional model. This leads to significant improvements in ImageNet\ngeneration, setting record FIDs of 1.01 for 64x64 and 1.25 for 512x512, using\npublicly available networks. Furthermore, the method is also applicable to\nunconditional diffusion models, drastically improving their quality.\n","authors":["Tero Karras","Miika Aittala","Tuomas Kynkäänniemi","Jaakko Lehtinen","Timo Aila","Samuli Laine"],"pdf_url":"https://arxiv.org/pdf/2406.02507v3.pdf","comment":"NeurIPS 2024"},{"id":"http://arxiv.org/abs/2412.14719v1","updated":"2024-12-19T10:41:24Z","published":"2024-12-19T10:41:24Z","title":"Prototypical Calibrating Ambiguous Samples for Micro-Action Recognition","summary":"  Micro-Action Recognition (MAR) has gained increasing attention due to its\ncrucial role as a form of non-verbal communication in social interactions, with\npromising potential for applications in human communication and emotion\nanalysis. However, current approaches often overlook the inherent ambiguity in\nmicro-actions, which arises from the wide category range and subtle visual\ndifferences between categories. This oversight hampers the accuracy of\nmicro-action recognition. In this paper, we propose a novel Prototypical\nCalibrating Ambiguous Network (\\textbf{PCAN}) to unleash and mitigate the\nambiguity of MAR. \\textbf{Firstly}, we employ a hierarchical action-tree to\nidentify the ambiguous sample, categorizing them into distinct sets of\nambiguous samples of false negatives and false positives, considering both\nbody- and action-level categories. \\textbf{Secondly}, we implement an ambiguous\ncontrastive refinement module to calibrate these ambiguous samples by\nregulating the distance between ambiguous samples and their corresponding\nprototypes. This calibration process aims to pull false negative\n($\\mathbb{FN}$) samples closer to their respective prototypes and push false\npositive ($\\mathbb{FP}$) samples apart from their affiliated prototypes. In\naddition, we propose a new prototypical diversity amplification loss to\nstrengthen the model's capacity by amplifying the differences between different\nprototypes. \\textbf{Finally}, we propose a prototype-guided rectification to\nrectify prediction by incorporating the representability of prototypes.\nExtensive experiments conducted on the benchmark dataset demonstrate the\nsuperior performance of our method compared to existing approaches. The code is\navailable at https://github.com/kunli-cs/PCAN.\n","authors":["Kun Li","Dan Guo","Guoliang Chen","Chunxiao Fan","Jingyuan Xu","Zhiliang Wu","Hehe Fan","Meng Wang"],"pdf_url":"https://arxiv.org/pdf/2412.14719v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.14718v1","updated":"2024-12-19T10:33:19Z","published":"2024-12-19T10:33:19Z","title":"A Comprehensive Forecasting Framework based on Multi-Stage Hierarchical\n  Forecasting Reconciliation and Adjustment","summary":"  Ads demand forecasting for Walmart's ad products plays a critical role in\nenabling effective resource planning, allocation, and management of ads\nperformance. In this paper, we introduce a comprehensive demand forecasting\nsystem that tackles hierarchical time series forecasting in business settings.\nThough traditional hierarchical reconciliation methods ensure forecasting\ncoherence, they often trade off accuracy for coherence especially at lower\nlevels and fail to capture the seasonality unique to each time-series in the\nhierarchy. Thus, we propose a novel framework \"Multi-Stage Hierarchical\nForecasting Reconciliation and Adjustment (Multi-Stage HiFoReAd)\" to address\nthe challenges of preserving seasonality, ensuring coherence, and improving\naccuracy. Our system first utilizes diverse models, ensembled through Bayesian\nOptimization (BO), achieving base forecasts. The generated base forecasts are\nthen passed into the Multi-Stage HiFoReAd framework. The initial stage refines\nthe hierarchy using Top-Down forecasts and \"harmonic alignment.\" The second\nstage aligns the higher levels' forecasts using MinTrace algorithm, following\nwhich the last two levels undergo \"harmonic alignment\" and \"stratified\nscaling\", to eventually achieve accurate and coherent forecasts across the\nwhole hierarchy. Our experiments on Walmart's internal Ads-demand dataset and 3\nother public datasets, each with 4 hierarchical levels, demonstrate that the\naverage Absolute Percentage Error from the cross-validation sets improve from\n3% to 40% across levels against BO-ensemble of models (LGBM, MSTL+ETS, Prophet)\nas well as from 1.2% to 92.9% against State-Of-The-Art models. In addition, the\nforecasts at all hierarchical levels are proved to be coherent. The proposed\nframework has been deployed and leveraged by Walmart's ads, sales and\noperations teams to track future demands, make informed decisions and plan\nresources.\n","authors":["Zhengchao Yang","Mithun Ghosh","Anish Saha","Dong Xu","Konstantin Shmakov","Kuang-chih Lee"],"pdf_url":"https://arxiv.org/pdf/2412.14718v1.pdf","comment":"Published in 2024 IEEE International Conference on Big Data (BigData)"},{"id":"http://arxiv.org/abs/2412.11242v2","updated":"2024-12-19T10:33:13Z","published":"2024-12-15T16:47:16Z","title":"TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs","summary":"  Specializing large language models (LLMs) for local deployment in\ndomain-specific use cases is necessary for strong performance while meeting\nlatency and privacy constraints. However, conventional task-specific adaptation\napproaches do not show simultaneous memory saving and inference speedup at\ndeployment time. Practical compression techniques like quantization and pruning\nrequire dedicated hardware or kernel support to achieve measured inference\nspeedup. We develop TrimLLM based on the layer-wise specialization phenomenon\nwe empirically observed and verified on contemporary LLMs. TrimLLM reduces the\ndepth of LLMs via progressive layer dropping. We show it retains LLMs' capacity\nin specific domains and achieves inference speedup irrespective of hardware and\ndeep learning frameworks. We evaluated TrimLLM on LLMs of various sizes for\ninference; models adapted on medical, legal, and financial datasets all\ndemonstrate $2.1-5.7\\times$ inference speedup on consumer GPUs and up to\n$3.1\\times$ speedup on A100 when compared to state-of-the-art model compression\nalgorithms, with no loss in accuracy at 50$\\sim$60\\% model compression ratio.\n","authors":["Lanxiang Hu","Tajana Rosing","Hao Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.11242v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14717v1","updated":"2024-12-19T10:31:25Z","published":"2024-12-19T10:31:25Z","title":"Computing Gram Matrix for SMILES Strings using RDKFingerprint and\n  Sinkhorn-Knopp Algorithm","summary":"  In molecular structure data, SMILES (Simplified Molecular Input Line Entry\nSystem) strings are used to analyze molecular structure design. Numerical\nfeature representation of SMILES strings is a challenging task. This work\nproposes a kernel-based approach for encoding and analyzing molecular\nstructures from SMILES strings. The proposed approach involves computing a\nkernel matrix using the Sinkhorn-Knopp algorithm while using kernel principal\ncomponent analysis (PCA) for dimensionality reduction. The resulting\nlow-dimensional embeddings are then used for classification and regression\nanalysis. The kernel matrix is computed by converting the SMILES strings into\nmolecular structures using the Morgan Fingerprint, which computes a fingerprint\nfor each molecule. The distance matrix is computed using the pairwise kernels\nfunction. The Sinkhorn-Knopp algorithm is used to compute the final kernel\nmatrix that satisfies the constraints of a probability distribution. This is\nachieved by iteratively adjusting the kernel matrix until the marginal\ndistributions of the rows and columns match the desired marginal distributions.\nWe provided a comprehensive empirical analysis of the proposed kernel method to\nevaluate its goodness with greater depth. The suggested method is assessed for\ndrug subcategory prediction (classification task) and solubility AlogPS\n``Aqueous solubility and Octanol/Water partition coefficient\" (regression task)\nusing the benchmark SMILES string dataset. The outcomes show the proposed\nmethod outperforms several baseline methods in terms of supervised analysis and\nhas potential uses in molecular design and drug discovery. Overall, the\nsuggested method is a promising avenue for kernel methods-based molecular\nstructure analysis and design.\n","authors":["Sarwan Ali","Haris Mansoor","Prakash Chourasia","Imdad Ullah Khan","Murray Patterson"],"pdf_url":"https://arxiv.org/pdf/2412.14717v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14714v1","updated":"2024-12-19T10:25:21Z","published":"2024-12-19T10:25:21Z","title":"Holistic Adversarially Robust Pruning","summary":"  Neural networks can be drastically shrunk in size by removing redundant\nparameters. While crucial for the deployment on resource-constraint hardware,\noftentimes, compression comes with a severe drop in accuracy and lack of\nadversarial robustness. Despite recent advances, counteracting both aspects has\nonly succeeded for moderate compression rates so far. We propose a novel\nmethod, HARP, that copes with aggressive pruning significantly better than\nprior work. For this, we consider the network holistically. We learn a global\ncompression strategy that optimizes how many parameters (compression rate) and\nwhich parameters (scoring connections) to prune specific to each layer\nindividually. Our method fine-tunes an existing model with dynamic\nregularization, that follows a step-wise incremental function balancing the\ndifferent objectives. It starts by favoring robustness before shifting focus on\nreaching the target compression rate and only then handles the objectives\nequally. The learned compression strategies allow us to maintain the\npre-trained model natural accuracy and its adversarial robustness for a\nreduction by 99% of the network original size. Moreover, we observe a crucial\ninfluence of non-uniform compression across layers.\n","authors":["Qi Zhao","Christian Wressnegger"],"pdf_url":"https://arxiv.org/pdf/2412.14714v1.pdf","comment":"Accepted by ICLR 2023"},{"id":"http://arxiv.org/abs/2412.14711v1","updated":"2024-12-19T10:21:20Z","published":"2024-12-19T10:21:20Z","title":"ReMoE: Fully Differentiable Mixture-of-Experts with ReLU Routing","summary":"  Sparsely activated Mixture-of-Experts (MoE) models are widely adopted to\nscale up model capacity without increasing the computation budget. However,\nvanilla TopK routers are trained in a discontinuous, non-differentiable way,\nlimiting their performance and scalability. To address this issue, we propose\nReMoE, a fully differentiable MoE architecture that offers a simple yet\neffective drop-in replacement for the conventional TopK+Softmax routing,\nutilizing ReLU as the router instead. We further propose methods to regulate\nthe router's sparsity while balancing the load among experts. ReMoE's\ncontinuous nature enables efficient dynamic allocation of computation across\ntokens and layers, while also exhibiting domain specialization. Our experiments\ndemonstrate that ReMoE consistently outperforms vanilla TopK-routed MoE across\nvarious model sizes, expert counts, and levels of granularity. Furthermore,\nReMoE exhibits superior scalability with respect to the number of experts,\nsurpassing traditional MoE architectures. The implementation based on\nMegatron-LM is available at https://github.com/thu-ml/ReMoE.\n","authors":["Ziteng Wang","Jianfei Chen","Jun Zhu"],"pdf_url":"https://arxiv.org/pdf/2412.14711v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.11479v2","updated":"2024-12-19T10:21:11Z","published":"2024-08-21T09:44:43Z","title":"Learning Deep Dissipative Dynamics","summary":"  This study challenges strictly guaranteeing ``dissipativity'' of a dynamical\nsystem represented by neural networks learned from given time-series data.\nDissipativity is a crucial indicator for dynamical systems that generalizes\nstability and input-output stability, known to be valid across various systems\nincluding robotics, biological systems, and molecular dynamics. By analytically\nproving the general solution to the nonlinear Kalman-Yakubovich-Popov (KYP)\nlemma, which is the necessary and sufficient condition for dissipativity, we\npropose a differentiable projection that transforms any dynamics represented by\nneural networks into dissipative ones and a learning method for the transformed\ndynamics. Utilizing the generality of dissipativity, our method strictly\nguarantee stability, input-output stability, and energy conservation of trained\ndynamical systems. Finally, we demonstrate the robustness of our method against\nout-of-domain input through applications to robotic arms and fluid dynamics.\nCode is https://github.com/kojima-r/DeepDissipativeModel\n","authors":["Yuji Okamoto","Ryosuke Kojima"],"pdf_url":"https://arxiv.org/pdf/2408.11479v2.pdf","comment":"AAAI 2025"},{"id":"http://arxiv.org/abs/2412.08555v2","updated":"2024-12-19T10:12:38Z","published":"2024-12-11T17:17:02Z","title":"Grimm: A Plug-and-Play Perturbation Rectifier for Graph Neural Networks\n  Defending against Poisoning Attacks","summary":"  Recent studies have revealed the vulnerability of graph neural networks\n(GNNs) to adversarial poisoning attacks on node classification tasks. Current\ndefensive methods require substituting the original GNNs with defense models,\nregardless of the original's type. This approach, while targeting adversarial\nrobustness, compromises the enhancements developed in prior research to boost\nGNNs' practical performance. Here we introduce Grimm, the first plug-and-play\ndefense model. With just a minimal interface requirement for extracting\nfeatures from any layer of the protected GNNs, Grimm is thus enabled to\nseamlessly rectify perturbations. Specifically, we utilize the feature\ntrajectories (FTs) generated by GNNs, as they evolve through epochs, to reflect\nthe training status of the networks. We then theoretically prove that the FTs\nof victim nodes will inevitably exhibit discriminable anomalies. Consequently,\ninspired by the natural parallelism between the biological nervous and immune\nsystems, we construct Grimm, a comprehensive artificial immune system for GNNs.\nGrimm not only detects abnormal FTs and rectifies adversarial edges during\ntraining but also operates efficiently in parallel, thereby mirroring the\nconcurrent functionalities of its biological counterparts. We experimentally\nconfirm that Grimm offers four empirically validated advantages: 1)\nHarmlessness, as it does not actively interfere with GNN training; 2)\nParallelism, ensuring monitoring, detection, and rectification functions\noperate independently of the GNN training process; 3) Generalizability,\ndemonstrating compatibility with mainstream GNNs such as GCN, GAT, and\nGraphSAGE; and 4) Transferability, as the detectors for abnormal FTs can be\nefficiently transferred across different systems for one-step rectification.\n","authors":["Ao Liu","Wenshan Li","Beibei Li","Wengang Ma","Tao Li","Pan Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.08555v2.pdf","comment":"19 pages, 13 figures"},{"id":"http://arxiv.org/abs/2202.06374v5","updated":"2024-12-19T10:12:00Z","published":"2022-02-13T18:04:00Z","title":"Holdouts set for safe predictive model updating","summary":"  Predictive risk scores for adverse outcomes are increasingly crucial in\nguiding health interventions. Such scores may need to be periodically updated\ndue to change in the distributions they model. However, directly updating risk\nscores used to guide intervention can lead to biased risk estimates. To address\nthis, we propose updating using a `holdout set' - a subset of the population\nthat does not receive interventions guided by the risk score. Balancing the\nholdout set size is essential to ensure good performance of the updated risk\nscore whilst minimising the number of held out samples. We prove that this\napproach reduces adverse outcome frequency to an asymptotically optimal level\nand argue that often there is no competitive alternative. We describe\nconditions under which an optimal holdout size (OHS) can be readily identified,\nand introduce parametric and semi-parametric algorithms for OHS estimation. We\napply our methods to the ASPRE risk score for pre-eclampsia to recommend a plan\nfor updating it in the presence of change in the underlying data distribution.\nWe show that, in order to minimise the number of pre-eclampsia cases over time,\nthis is best achieved using a holdout set of around 10,000 individuals.\n","authors":["Sami Haidar-Wehbe","Samuel R Emerson","Louis J M Aslett","James Liley"],"pdf_url":"https://arxiv.org/pdf/2202.06374v5.pdf","comment":"Manuscript includes supplementary materials and figures"},{"id":"http://arxiv.org/abs/2412.07675v3","updated":"2024-12-19T10:11:42Z","published":"2024-12-10T17:02:58Z","title":"RAZOR: Sharpening Knowledge by Cutting Bias with Unsupervised Text\n  Rewriting","summary":"  Despite the widespread use of LLMs due to their superior performance in\nvarious tasks, their high computational costs often lead potential users to opt\nfor the pretraining-finetuning pipeline. However, biases prevalent in manually\nconstructed datasets can introduce spurious correlations between tokens and\nlabels, creating so-called shortcuts and hindering the generalizability of\nfine-tuned models. Existing debiasing methods often rely on prior knowledge of\nspecific dataset biases, which is challenging to acquire a priori. We propose\nRAZOR (Rewriting And Zero-bias Optimization Refinement), a novel, unsupervised,\nand data-focused debiasing approach based on text rewriting for shortcut\nmitigation. RAZOR leverages LLMs to iteratively rewrite potentially biased text\nsegments by replacing them with heuristically selected alternatives in a\nshortcut space defined by token statistics and positional information. This\nprocess aims to align surface-level text features more closely with diverse\nlabel distributions, thereby promoting the learning of genuine linguistic\npatterns. Compared with unsupervised SoTA models, RAZOR improves by 3.5% on the\nFEVER and 6.5% on MNLI and SNLI datasets according to the F1 score.\nAdditionally, RAZOR effectively mitigates specific known biases, reducing\nbias-related terms by x2 without requiring prior bias information, a result\nthat is on par with SoTA models that leverage prior information. Our work\nprioritizes data manipulation over architectural modifications, emphasizing the\npivotal role of data quality in enhancing model performance and fairness. This\nresearch contributes to developing more robust evaluation benchmarks for\ndebiasing methods by incorporating metrics for bias reduction and overall model\nefficacy.\n","authors":["Shuo Yang","Bardh Prenkaj","Gjergji Kasneci"],"pdf_url":"https://arxiv.org/pdf/2412.07675v3.pdf","comment":"Shuo and Bardh contributed equally. Accepted to AAAI'25, Paper #17117"},{"id":"http://arxiv.org/abs/2412.14701v1","updated":"2024-12-19T10:10:57Z","published":"2024-12-19T10:10:57Z","title":"Taming the Memory Beast: Strategies for Reliable ML Training on\n  Kubernetes","summary":"  Kubernetes offers a powerful orchestration platform for machine learning\ntraining, but memory management can be challenging due to specialized needs and\nresource constraints. This paper outlines how Kubernetes handles memory\nrequests, limits, Quality of Service classes, and eviction policies for ML\nworkloads, with special focus on GPU memory and ephemeral storage. Common\npitfalls such as overcommitment, memory leaks, and ephemeral volume exhaustion\nare examined. We then provide best practices for stable, scalable memory\nutilization to help ML practitioners prevent out-of-memory events and ensure\nhigh-performance ML training pipelines.\n","authors":["Jaideep Ray"],"pdf_url":"https://arxiv.org/pdf/2412.14701v1.pdf","comment":"4 pages"},{"id":"http://arxiv.org/abs/2412.08160v4","updated":"2024-12-19T10:01:27Z","published":"2024-12-11T07:32:38Z","title":"DG-Mamba: Robust and Efficient Dynamic Graph Structure Learning with\n  Selective State Space Models","summary":"  Dynamic graphs exhibit intertwined spatio-temporal evolutionary patterns,\nwidely existing in the real world. Nevertheless, the structure incompleteness,\nnoise, and redundancy result in poor robustness for Dynamic Graph Neural\nNetworks (DGNNs). Dynamic Graph Structure Learning (DGSL) offers a promising\nway to optimize graph structures. However, aside from encountering unacceptable\nquadratic complexity, it overly relies on heuristic priors, making it hard to\ndiscover underlying predictive patterns. How to efficiently refine the dynamic\nstructures, capture intrinsic dependencies, and learn robust representations,\nremains under-explored. In this work, we propose the novel DG-Mamba, a robust\nand efficient Dynamic Graph structure learning framework with the Selective\nState Space Models (Mamba). To accelerate the spatio-temporal structure\nlearning, we propose a kernelized dynamic message-passing operator that reduces\nthe quadratic time complexity to linear. To capture global intrinsic dynamics,\nwe establish the dynamic graph as a self-contained system with State Space\nModel. By discretizing the system states with the cross-snapshot graph\nadjacency, we enable the long-distance dependencies capturing with the\nselective snapshot scan. To endow learned dynamic structures more expressive\nwith informativeness, we propose the self-supervised Principle of Relevant\nInformation for DGSL to regularize the most relevant yet least redundant\ninformation, enhancing global robustness. Extensive experiments demonstrate the\nsuperiority of the robustness and efficiency of our DG-Mamba compared with the\nstate-of-the-art baselines against adversarial attacks.\n","authors":["Haonan Yuan","Qingyun Sun","Zhaonan Wang","Xingcheng Fu","Cheng Ji","Yongjian Wang","Bo Jin","Jianxin Li"],"pdf_url":"https://arxiv.org/pdf/2412.08160v4.pdf","comment":"Accepted by the Main Technical Track of the 39th Annual AAAI\n  Conference on Artificial Intelligence (AAAI-2025)"},{"id":"http://arxiv.org/abs/2412.14695v1","updated":"2024-12-19T09:56:01Z","published":"2024-12-19T09:56:01Z","title":"Lorentzian Residual Neural Networks","summary":"  Hyperbolic neural networks have emerged as a powerful tool for modeling\nhierarchical data structures prevalent in real-world datasets. Notably,\nresidual connections, which facilitate the direct flow of information across\nlayers, have been instrumental in the success of deep neural networks. However,\ncurrent methods for constructing hyperbolic residual networks suffer from\nlimitations such as increased model complexity, numerical instability, and\nerrors due to multiple mappings to and from the tangent space. To address these\nlimitations, we introduce LResNet, a novel Lorentzian residual neural network\nbased on the weighted Lorentzian centroid in the Lorentz model of hyperbolic\ngeometry. Our method enables the efficient integration of residual connections\nin Lorentz hyperbolic neural networks while preserving their hierarchical\nrepresentation capabilities. We demonstrate that our method can theoretically\nderive previous methods while offering improved stability, efficiency, and\neffectiveness. Extensive experiments on both graph and vision tasks showcase\nthe superior performance and robustness of our method compared to\nstate-of-the-art Euclidean and hyperbolic alternatives. Our findings highlight\nthe potential of \\method for building more expressive neural networks in\nhyperbolic embedding space as a generally applicable method to multiple\narchitectures, including CNNs, GNNs, and graph Transformers.\n","authors":["Neil He","Menglin Yang","Rex Ying"],"pdf_url":"https://arxiv.org/pdf/2412.14695v1.pdf","comment":"12 pages, 3 figures, KDD 2025"},{"id":"http://arxiv.org/abs/2410.05016v2","updated":"2024-12-19T09:49:25Z","published":"2024-10-07T13:15:07Z","title":"T-JEPA: Augmentation-Free Self-Supervised Learning for Tabular Data","summary":"  Self-supervision is often used for pre-training to foster performance on a\ndownstream task by constructing meaningful representations of samples.\nSelf-supervised learning (SSL) generally involves generating different views of\nthe same sample and thus requires data augmentations that are challenging to\nconstruct for tabular data. This constitutes one of the main challenges of\nself-supervision for structured data. In the present work, we propose a novel\naugmentation-free SSL method for tabular data. Our approach, T-JEPA, relies on\na Joint Embedding Predictive Architecture (JEPA) and is akin to mask\nreconstruction in the latent space. It involves predicting the latent\nrepresentation of one subset of features from the latent representation of a\ndifferent subset within the same sample, thereby learning rich representations\nwithout augmentations. We use our method as a pre-training technique and train\nseveral deep classifiers on the obtained representation. Our experimental\nresults demonstrate a substantial improvement in both classification and\nregression tasks, outperforming models trained directly on samples in their\noriginal data space. Moreover, T-JEPA enables some methods to consistently\noutperform or match the performance of traditional methods likes Gradient\nBoosted Decision Trees. To understand why, we extensively characterize the\nobtained representations and show that T-JEPA effectively identifies relevant\nfeatures for downstream tasks without access to the labels. Additionally, we\nintroduce regularization tokens, a novel regularization method critical for\ntraining of JEPA-based models on structured data.\n","authors":["Hugo Thimonier","José Lucas De Melo Costa","Fabrice Popineau","Arpad Rimmel","Bich-Liên Doan"],"pdf_url":"https://arxiv.org/pdf/2410.05016v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14689v1","updated":"2024-12-19T09:43:39Z","published":"2024-12-19T09:43:39Z","title":"How to Synthesize Text Data without Model Collapse?","summary":"  Model collapse in synthetic data indicates that iterative training on\nself-generated data leads to a gradual decline in performance. With the\nproliferation of AI models, synthetic data will fundamentally reshape the web\ndata ecosystem. Future GPT-$\\{n\\}$ models will inevitably be trained on a blend\nof synthetic and human-produced data. In this paper, we focus on two questions:\nwhat is the impact of synthetic data on language model training, and how to\nsynthesize data without model collapse? We first pre-train language models\nacross different proportions of synthetic data, revealing a negative\ncorrelation between the proportion of synthetic data and model performance. We\nfurther conduct statistical analysis on synthetic data to uncover\ndistributional shift phenomenon and over-concentration of n-gram features.\nInspired by the above findings, we propose token editing on human-produced data\nto obtain semi-synthetic data. As a proof of concept, we theoretically\ndemonstrate that token-level editing can prevent model collapse, as the test\nerror is constrained by a finite upper bound. We conduct extensive experiments\non pre-training from scratch, continual pre-training, and supervised\nfine-tuning. The results validate our theoretical proof that token-level\nediting improves data quality and enhances model performance.\n","authors":["Xuekai Zhu","Daixuan Cheng","Hengli Li","Kaiyan Zhang","Ermo Hua","Xingtai Lv","Ning Ding","Zhouhan Lin","Zilong Zheng","Bowen Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.14689v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12327v2","updated":"2024-12-19T09:34:30Z","published":"2024-12-16T19:54:57Z","title":"Leveraging Group Classification with Descending Soft Labeling for Deep\n  Imbalanced Regression","summary":"  Deep imbalanced regression (DIR), where the target values have a highly\nskewed distribution and are also continuous, is an intriguing yet\nunder-explored problem in machine learning.\n  While recent works have already shown that incorporating various\nclassification-based regularizers can produce enhanced outcomes, the role of\nclassification remains elusive in DIR.\n  Moreover, such regularizers (e.g., contrastive penalties) merely focus on\nlearning discriminative features of data, which inevitably results in ignorance\nof either continuity or similarity across the data.\n  To address these issues, we first bridge the connection between the\nobjectives of DIR and classification from a Bayesian perspective.\n  Consequently, this motivates us to decompose the objective of DIR into a\ncombination of classification and regression tasks, which naturally guides us\ntoward a divide-and-conquer manner to solve the DIR problem.\n  Specifically, by aggregating the data at nearby labels into the same groups,\nwe introduce an ordinal group-aware contrastive learning loss along with a\nmulti-experts regressor to tackle the different groups of data thereby\nmaintaining the data continuity.\n  Meanwhile, considering the similarity between the groups, we also propose a\nsymmetric descending soft labeling strategy to exploit the intrinsic similarity\nacross the data, which allows classification to facilitate regression more\neffectively.\n  Extensive experiments on real-world datasets also validate the effectiveness\nof our method.\n","authors":["Ruizhi Pu","Gezheng Xu","Ruiyi Fang","Binkun Bao","Charles X. Ling","Boyu Wang"],"pdf_url":"https://arxiv.org/pdf/2412.12327v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2408.06401v2","updated":"2024-12-19T09:30:05Z","published":"2024-08-12T12:09:25Z","title":"Langevin dynamics for high-dimensional optimization: the case of\n  multi-spiked tensor PCA","summary":"  We study nonconvex optimization in high dimensions through Langevin dynamics,\nfocusing on the multi-spiked tensor PCA problem. This tensor estimation problem\ninvolves recovering $r$ hidden signal vectors (spikes) from noisy Gaussian\ntensor observations using maximum likelihood estimation. We study the number of\nsamples required for Langevin dynamics to efficiently recover the spikes and\ndetermine the necessary separation condition on the signal-to-noise ratios\n(SNRs) for exact recovery, distinguishing the cases $p \\ge 3$ and $p=2$, where\n$p$ denotes the order of the tensor. In particular, we show that the sample\ncomplexity required for recovering the spike associated with the largest SNR\nmatches the well-known algorithmic threshold for the single-spike case, while\nthis threshold degrades when recovering all $r$ spikes. As a key step, we\nprovide a detailed characterization of the trajectory and interactions of\nlow-dimensional projections that capture the high-dimensional dynamics.\n","authors":["Gérard Ben Arous","Cédric Gerbelot","Vanessa Piccolo"],"pdf_url":"https://arxiv.org/pdf/2408.06401v2.pdf","comment":"65 pages"},{"id":"http://arxiv.org/abs/2412.06926v3","updated":"2024-12-19T09:24:39Z","published":"2024-12-09T19:11:54Z","title":"When Every Token Counts: Optimal Segmentation for Low-Resource Language\n  Models","summary":"  Traditional greedy tokenization methods have been a critical step in Natural\nLanguage Processing (NLP), influencing how text is converted into tokens and\ndirectly impacting model performance. While subword tokenizers like Byte-Pair\nEncoding (BPE) are widely used, questions remain about their optimality across\nmodel scales and languages. In this work, we demonstrate through extensive\nexperiments that an optimal BPE configuration significantly reduces token count\ncompared to greedy segmentation, yielding improvements in token-saving\npercentages and performance benefits, particularly for smaller models. We\nevaluate tokenization performance across various intrinsic and extrinsic tasks,\nincluding generation and classification. Our findings suggest that\ncompression-optimized tokenization strategies could provide substantial\nadvantages for multilingual and low-resource language applications,\nhighlighting a promising direction for further research and inclusive NLP.\n","authors":["Bharath Raj S","Garvit Suri","Vikrant Dewangan","Raghav Sonavane"],"pdf_url":"https://arxiv.org/pdf/2412.06926v3.pdf","comment":"LoResLM @ COLING 2025"},{"id":"http://arxiv.org/abs/2412.14668v1","updated":"2024-12-19T09:20:27Z","published":"2024-12-19T09:20:27Z","title":"LoLaFL: Low-Latency Federated Learning via Forward-only Propagation","summary":"  Federated learning (FL) has emerged as a widely adopted paradigm for enabling\nedge learning with distributed data while ensuring data privacy. However, the\ntraditional FL with deep neural networks trained via backpropagation can hardly\nmeet the low-latency learning requirements in the sixth generation (6G) mobile\nnetworks. This challenge mainly arises from the high-dimensional model\nparameters to be transmitted and the numerous rounds of communication required\nfor convergence due to the inherent randomness of the training process. To\naddress this issue, we adopt the state-of-the-art principle of maximal coding\nrate reduction to learn linear discriminative features and extend the resultant\nwhite-box neural network into FL, yielding the novel framework of Low-Latency\nFederated Learning (LoLaFL) via forward-only propagation. LoLaFL enables\nlayer-wise transmissions and aggregation with significantly fewer communication\nrounds, thereby considerably reducing latency. Additionally, we propose two\n\\emph{nonlinear} aggregation schemes for LoLaFL. The first scheme is based on\nthe proof that the optimal NN parameter aggregation in LoLaFL should be\nharmonic-mean-like. The second scheme further exploits the low-rank structures\nof the features and transmits the low-rank-approximated covariance matrices of\nfeatures to achieve additional latency reduction. Theoretic analysis and\nexperiments are conducted to evaluate the performance of LoLaFL. In comparison\nwith traditional FL, the two nonlinear aggregation schemes for LoLaFL can\nachieve reductions in latency of over 91\\% and 98\\%, respectively, while\nmaintaining comparable accuracies.\n","authors":["Jierui Zhang","Jianhao Huang","Kaibin Huang"],"pdf_url":"https://arxiv.org/pdf/2412.14668v1.pdf","comment":"14 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.14660v1","updated":"2024-12-19T09:10:07Z","published":"2024-12-19T09:10:07Z","title":"Unveiling Uncertainty: A Deep Dive into Calibration and Performance of\n  Multimodal Large Language Models","summary":"  Multimodal large language models (MLLMs) combine visual and textual data for\ntasks such as image captioning and visual question answering. Proper\nuncertainty calibration is crucial, yet challenging, for reliable use in areas\nlike healthcare and autonomous driving. This paper investigates representative\nMLLMs, focusing on their calibration across various scenarios, including before\nand after visual fine-tuning, as well as before and after multimodal training\nof the base LLMs. We observed miscalibration in their performance, and at the\nsame time, no significant differences in calibration across these scenarios. We\nalso highlight how uncertainty differs between text and images and how their\nintegration affects overall uncertainty. To better understand MLLMs'\nmiscalibration and their ability to self-assess uncertainty, we construct the\nIDK (I don't know) dataset, which is key to evaluating how they handle\nunknowns. Our findings reveal that MLLMs tend to give answers rather than admit\nuncertainty, but this self-assessment improves with proper prompt adjustments.\nFinally, to calibrate MLLMs and enhance model reliability, we propose\ntechniques such as temperature scaling and iterative prompt optimization. Our\nresults provide insights into improving MLLMs for effective and responsible\ndeployment in multimodal applications. Code and IDK dataset:\n\\href{https://github.com/hfutml/Calibration-MLLM}{https://github.com/hfutml/Calibration-MLLM}.\n","authors":["Zijun Chen","Wenbo Hu","Guande He","Zhijie Deng","Zheng Zhang","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2412.14660v1.pdf","comment":"Accepted to COLING 2025"},{"id":"http://arxiv.org/abs/2412.14655v1","updated":"2024-12-19T09:06:39Z","published":"2024-12-19T09:06:39Z","title":"Trainable Adaptive Activation Function Structure (TAAFS) Enhances Neural\n  Network Force Field Performance with Only Dozens of Additional Parameters","summary":"  At the heart of neural network force fields (NNFFs) is the architecture of\nneural networks, where the capacity to model complex interactions is typically\nenhanced through widening or deepening multilayer perceptrons (MLPs) or by\nincreasing layers of graph neural networks (GNNs). These enhancements, while\nimproving the model's performance, often come at the cost of a substantial\nincrease in the number of parameters. By applying the Trainable Adaptive\nActivation Function Structure (TAAFS), we introduce a method that selects\ndistinct mathematical formulations for non-linear activations, thereby\nincreasing the precision of NNFFs with an insignificant addition to the\nparameter count. In this study, we integrate TAAFS into a variety of neural\nnetwork models, resulting in observed accuracy improvements, and further\nvalidate these enhancements through molecular dynamics (MD) simulations using\nDeepMD.\n","authors":["Enji Li"],"pdf_url":"https://arxiv.org/pdf/2412.14655v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.15031v2","updated":"2024-12-19T09:00:34Z","published":"2024-03-22T08:26:31Z","title":"Image Classification with Rotation-Invariant Variational Quantum\n  Circuits","summary":"  Variational quantum algorithms are gaining attention as an early application\nof Noisy Intermediate-Scale Quantum (NISQ) devices. One of the main problems of\nvariational methods lies in the phenomenon of Barren Plateaus, present in the\noptimization of variational parameters. Adding geometric inductive bias to the\nquantum models has been proposed as a potential solution to mitigate this\nproblem, leading to a new field called Geometric Quantum Machine Learning. In\nthis work, an equivariant architecture for variational quantum classifiers is\nintroduced to create a label-invariant model for image classification with\n$C_4$ rotational label symmetry. The equivariant circuit is benchmarked against\ntwo different architectures, and it is experimentally observed that the\ngeometric approach boosts the model's performance. Finally, a classical\nequivariant convolution operation is proposed to extend the quantum model for\nthe processing of larger images, employing the resources available in NISQ\ndevices.\n","authors":["Paul San Sebastian","Mikel Cañizo","Román Orús"],"pdf_url":"https://arxiv.org/pdf/2403.15031v2.pdf","comment":"13 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.14650v1","updated":"2024-12-19T08:59:49Z","published":"2024-12-19T08:59:49Z","title":"Permutation recovery of spikes in noisy high-dimensional tensor\n  estimation","summary":"  We study the dynamics of gradient flow in high dimensions for the\nmulti-spiked tensor problem, where the goal is to estimate $r$ unknown signal\nvectors (spikes) from noisy Gaussian tensor observations. Specifically, we\nanalyze the maximum likelihood estimation procedure, which involves optimizing\na highly nonconvex random function. We determine the sample complexity required\nfor gradient flow to efficiently recover all spikes, without imposing any\nassumptions on the separation of the signal-to-noise ratios (SNRs). More\nprecisely, our results provide the sample complexity required to guarantee\nrecovery of the spikes up to a permutation. Our work builds on our companion\npaper [Ben Arous, Gerbelot, Piccolo 2024], which studies Langevin dynamics and\ndetermines the sample complexity and separation conditions for the SNRs\nnecessary for ensuring exact recovery of the spikes (where the recovered\npermutation matches the identity). During the recovery process, the\ncorrelations between the estimators and the hidden vectors increase in a\nsequential manner. The order in which these correlations become significant\ndepends on their initial values and the corresponding SNRs, which ultimately\ndetermines the permutation of the recovered spikes.\n","authors":["Gérard Ben Arous","CĆedric Gerbelot","Vanessa Piccolo"],"pdf_url":"https://arxiv.org/pdf/2412.14650v1.pdf","comment":"29 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2408.06401"},{"id":"http://arxiv.org/abs/2406.16606v2","updated":"2024-12-19T08:53:52Z","published":"2024-06-24T12:46:16Z","title":"Cherry on the Cake: Fairness is NOT an Optimization Problem","summary":"  In Fair AI literature, the practice of maliciously creating unfair models\nthat nevertheless satisfy fairness constraints is known as \"cherry-picking\". A\ncherry-picking model is a model that makes mistakes on purpose, selecting bad\nindividuals from a minority class instead of better candidates from the same\nminority. The model literally cherry-picks whom to select to superficially meet\nthe fairness constraints while making minimal changes to the unfair model. This\npractice has been described as \"blatantly unfair\" and has a negative impact on\nalready marginalized communities, undermining the intended purpose of fairness\nmeasures specifically designed to protect these communities. A common\nassumption is that cherry-picking arises solely from malicious intent and that\nmodels designed only to optimize fairness metrics would avoid this behavior. We\nshow that this is not the case: models optimized to minimize fairness metrics\nwhile maximizing performance are often forced to cherry-pick to some degree. In\nother words, cherry-picking might be an inevitable outcome of the optimization\nprocess itself. To demonstrate this, we use tools from fair cake-cutting, a\nmathematical subfield that studies the problem of fairly dividing a resource,\nreferred to as the \"cake,\" among a number of participants. This concept is\nconnected to supervised multi-label classification: any dataset can be thought\nof as a cake that needs to be distributed among different labels, and the model\nis the function that divides the cake. We adapt these classical results for\nmachine learning and demonstrate how this connection can be prolifically used\nfor fairness and classification in general.\n","authors":["Marco Favier","Toon Calders"],"pdf_url":"https://arxiv.org/pdf/2406.16606v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14640v1","updated":"2024-12-19T08:51:01Z","published":"2024-12-19T08:51:01Z","title":"Adaptive Prompt Tuning: Vision Guided Prompt Tuning with Cross-Attention\n  for Fine-Grained Few-Shot Learning","summary":"  Few-shot, fine-grained classification in computer vision poses significant\nchallenges due to the need to differentiate subtle class distinctions with\nlimited data. This paper presents a novel method that enhances the Contrastive\nLanguage-Image Pre-Training (CLIP) model through adaptive prompt tuning, guided\nby real-time visual inputs. Unlike existing techniques such as Context\nOptimization (CoOp) and Visual Prompt Tuning (VPT), which are constrained by\nstatic prompts or visual token reliance, the proposed approach leverages a\ncross-attention mechanism to dynamically refine text prompts for the image at\nhand. This enables an image-specific alignment of textual features with image\npatches extracted from the Vision Transformer, making the model more effective\nfor datasets with high intra-class variance and low inter-class differences.\nThe method is evaluated on several datasets, including CUBirds, Oxford Flowers,\nand FGVC Aircraft, showing significant performance gains over static prompt\ntuning approaches. To ensure these performance gains translate into trustworthy\npredictions, we integrate Monte-Carlo Dropout in our approach to improve the\nreliability of the model predictions and uncertainty estimates. This\nintegration provides valuable insights into the model's predictive confidence,\nhelping to identify when predictions can be trusted and when additional\nverification is necessary. This dynamic approach offers a robust solution,\nadvancing the state-of-the-art for few-shot fine-grained classification.\n","authors":["Eric Brouwer","Jan Erik van Woerden","Gertjan Burghouts","Matias Valedenegro-Toro","Marco Zullich"],"pdf_url":"https://arxiv.org/pdf/2412.14640v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.14492v2","updated":"2024-12-19T08:46:02Z","published":"2024-05-23T12:25:22Z","title":"Iterative Methods for Full-Scale Gaussian Process Approximations for\n  Large Spatial Data","summary":"  Gaussian processes are flexible probabilistic regression models which are\nwidely used in statistics and machine learning. However, a drawback is their\nlimited scalability to large data sets. To alleviate this, we consider\nfull-scale approximations (FSAs) that combine predictive process methods and\ncovariance tapering, thus approximating both global and local structures. We\nshow how iterative methods can be used to reduce the computational costs for\ncalculating likelihoods, gradients, and predictive distributions with FSAs. We\nintroduce a novel preconditioner and show that it accelerates the conjugate\ngradient method's convergence speed and mitigates its sensitivity with respect\nto the FSA parameters and the eigenvalue structure of the original covariance\nmatrix, and we demonstrate empirically that it outperforms a state-of-the-art\npivoted Cholesky preconditioner. Further, we present a novel, accurate, and\nfast way to calculate predictive variances relying on stochastic estimations\nand iterative methods. In both simulated and real-world data experiments, we\nfind that our proposed methodology achieves the same accuracy as Cholesky-based\ncomputations with a substantial reduction in computational time. Finally, we\nalso compare different approaches for determining inducing points in predictive\nprocess and FSA models. All methods are implemented in a free C++ software\nlibrary with high-level Python and R packages.\n","authors":["Tim Gyger","Reinhard Furrer","Fabio Sigrist"],"pdf_url":"https://arxiv.org/pdf/2405.14492v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.16149v3","updated":"2024-12-19T08:34:15Z","published":"2024-03-24T13:43:43Z","title":"Analyzing Consumer IoT Traffic from Security and Privacy Perspectives: a\n  Comprehensive Survey","summary":"  The Consumer Internet of Things (CIoT), a notable segment within the IoT\ndomain, involves the integration of IoT technology into consumer electronics\nand devices, such as smart homes and smart wearables. Compared to traditional\nIoT fields, CIoT differs notably in target users, product types, and design\napproaches. While offering convenience to users, it also raises new security\nand privacy concerns. Network traffic analysis, a widely used technique in the\nsecurity community, has been extensively applied to investigate these concerns\nabout CIoT. Compared to network traffic analysis in other fields such as mobile\napps and websites, CIoT presents unique characteristics, introducing new\nchallenges and research opportunities. Researchers have made significant\ncontributions in this area. To aid researchers in understanding the application\nof traffic analysis tools for studying CIoT security and privacy risks, this\nsurvey reviews 303 publications on traffic analysis within the CIoT security\nand privacy domain from January 2018 to June 2024, focusing on three research\nquestions. Our work: 1) outlines the CIoT traffic analysis process and\nhighlights its differences from general network traffic analysis. 2) summarizes\nand classifies existing research into four categories according to its\napplication objectives: device fingerprinting, user activity inference,\nmalicious traffic detection, and measurement. 3) explores emerging challenges\nand potential future research directions based on each step of the CIoT traffic\nanalysis process. This will provide new insights to the community and guide the\nindustry towards safer product designs.\n","authors":["Yan Jia","Yuxin Song","Zihou Liu","Qingyin Tan","Yang Song","Yu Zhang","Zheli Liu"],"pdf_url":"https://arxiv.org/pdf/2403.16149v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14629v1","updated":"2024-12-19T08:31:42Z","published":"2024-12-19T08:31:42Z","title":"Robust PCA Based on Adaptive Weighted Least Squares and Low-Rank Matrix\n  Factorization","summary":"  Robust Principal Component Analysis (RPCA) is a fundamental technique for\ndecomposing data into low-rank and sparse components, which plays a critical\nrole for applications such as image processing and anomaly detection.\nTraditional RPCA methods commonly use $\\ell_1$ norm regularization to enforce\nsparsity, but this approach can introduce bias and result in suboptimal\nestimates, particularly in the presence of significant noise or outliers.\nNon-convex regularization methods have been proposed to mitigate these\nchallenges, but they tend to be complex to optimize and sensitive to initial\nconditions, leading to potential instability in solutions. To overcome these\nchallenges, in this paper, we propose a novel RPCA model that integrates\nadaptive weighted least squares (AWLS) and low-rank matrix factorization\n(LRMF). The model employs a {self-attention-inspired} mechanism in its weight\nupdate process, allowing the weight matrix to dynamically adjust and emphasize\nsignificant components during each iteration. By employing a weighted F-norm\nfor the sparse component, our method effectively reduces bias while simplifying\nthe computational process compared to traditional $\\ell_1$-norm-based methods.\nWe use an alternating minimization algorithm, where each subproblem has an\nexplicit solution, thereby improving computational efficiency. Despite its\nsimplicity, numerical experiments demonstrate that our method outperforms\nexisting non-convex regularization approaches, offering superior performance\nand stability, as well as enhanced accuracy and robustness in practical\napplications.\n","authors":["Kexin Li","You-wei Wen","Xu Xiao","Mingchao Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.14629v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14628v1","updated":"2024-12-19T08:30:54Z","published":"2024-12-19T08:30:54Z","title":"Qua$^2$SeDiMo: Quantifiable Quantization Sensitivity of Diffusion Models","summary":"  Diffusion Models (DM) have democratized AI image generation through an\niterative denoising process. Quantization is a major technique to alleviate the\ninference cost and reduce the size of DM denoiser networks. However, as\ndenoisers evolve from variants of convolutional U-Nets toward newer Transformer\narchitectures, it is of growing importance to understand the quantization\nsensitivity of different weight layers, operations and architecture types to\nperformance. In this work, we address this challenge with Qua$^2$SeDiMo, a\nmixed-precision Post-Training Quantization framework that generates explainable\ninsights on the cost-effectiveness of various model weight quantization methods\nfor different denoiser operation types and block structures. We leverage these\ninsights to make high-quality mixed-precision quantization decisions for a\nmyriad of diffusion models ranging from foundational U-Nets to state-of-the-art\nTransformers. As a result, Qua$^2$SeDiMo can construct 3.4-bit, 3.9-bit,\n3.65-bit and 3.7-bit weight quantization on PixArt-${\\alpha}$,\nPixArt-${\\Sigma}$, Hunyuan-DiT and SDXL, respectively. We further pair our\nweight-quantization configurations with 6-bit activation quantization and\noutperform existing approaches in terms of quantitative metrics and generative\nimage quality.\n","authors":["Keith G. Mills","Mohammad Salameh","Ruichen Chen","Negar Hassanpour","Wei Lu","Di Niu"],"pdf_url":"https://arxiv.org/pdf/2412.14628v1.pdf","comment":"AAAI 2025; version includes supplementary material; 22 Pages, 18\n  Figures, 8 Tables"},{"id":"http://arxiv.org/abs/2302.09526v4","updated":"2024-12-19T08:22:30Z","published":"2023-02-19T09:55:18Z","title":"Mixed Semi-Supervised Generalized-Linear-Regression with Applications to\n  Deep-Learning and Interpolators","summary":"  We present a methodology for using unlabeled data to design semi supervised\nlearning (SSL) methods that improve the prediction performance of supervised\nlearning for regression tasks. The main idea is to design different mechanisms\nfor integrating the unlabeled data, and include in each of them a mixing\nparameter $\\alpha$, controlling the weight given to the unlabeled data.\nFocusing on Generalized Linear Models (GLM) and linear interpolators classes of\nmodels, we analyze the characteristics of different mixing mechanisms, and\nprove that in all cases, it is invariably beneficial to integrate the unlabeled\ndata with some nonzero mixing ratio $\\alpha>0$, in terms of predictive\nperformance. Moreover, we provide a rigorous framework to estimate the best\nmixing ratio $\\alpha^*$ where mixed SSL delivers the best predictive\nperformance, while using the labeled and unlabeled data on hand.\n  The effectiveness of our methodology in delivering substantial improvement\ncompared to the standard supervised models, in a variety of settings, is\ndemonstrated empirically through extensive simulation, in a manner that\nsupports the theoretical analysis. We also demonstrate the applicability of our\nmethodology (with some intuitive modifications) to improve more complex models,\nsuch as deep neural networks, in real-world regression tasks.\n","authors":["Oren Yuval","Saharon Rosset"],"pdf_url":"https://arxiv.org/pdf/2302.09526v4.pdf","comment":"58 pages, 10 figures"},{"id":"http://arxiv.org/abs/2412.14031v2","updated":"2024-12-19T08:21:15Z","published":"2024-12-18T16:51:47Z","title":"Gauss-Newton Dynamics for Neural Networks: A Riemannian Optimization\n  Perspective","summary":"  We analyze the convergence of Gauss-Newton dynamics for training neural\nnetworks with smooth activation functions. In the underparameterized regime,\nthe Gauss-Newton gradient flow induces a Riemannian gradient flow on a\nlow-dimensional, smooth, embedded submanifold of the Euclidean output space.\nUsing tools from Riemannian optimization, we prove \\emph{last-iterate}\nconvergence of the Riemannian gradient flow to the optimal in-class predictor\nat an \\emph{exponential rate} that is independent of the conditioning of the\nGram matrix, \\emph{without} requiring explicit regularization. We further\ncharacterize the critical impacts of the neural network scaling factor and the\ninitialization on the convergence behavior. In the overparameterized regime, we\nshow that the Levenberg-Marquardt dynamics with an appropriately chosen damping\nfactor yields robustness to ill-conditioned kernels, analogous to the\nunderparameterized regime. These findings demonstrate the potential of\nGauss-Newton methods for efficiently optimizing neural networks, particularly\nin ill-conditioned problems where kernel and Gram matrices have small singular\nvalues.\n","authors":["Semih Cayci"],"pdf_url":"https://arxiv.org/pdf/2412.14031v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14620v1","updated":"2024-12-19T08:13:20Z","published":"2024-12-19T08:13:20Z","title":"Continuous latent representations for modeling precipitation with deep\n  learning","summary":"  The sparse and spatio-temporally discontinuous nature of precipitation data\npresents significant challenges for simulation and statistical processing for\nbias correction and downscaling. These include incorrect representation of\nintermittency and extreme values (critical for hydrology applications), Gibbs\nphenomenon upon regridding, and lack of fine scales details. To address these\nchallenges, a common approach is to transform the precipitation variable\nnonlinearly into one that is more malleable. In this work, we explore how deep\nlearning can be used to generate a smooth, spatio-temporally continuous\nvariable as a proxy for simulation of precipitation data. We develop a normally\ndistributed field called pseudo-precipitation (PP) as an alternative for\nsimulating precipitation. The practical applicability of this variable is\ninvestigated by applying it for downscaling precipitation from \\(1\\degree\\)\n(\\(\\sim\\) 100 km) to \\(0.25\\degree\\) (\\(\\sim\\) 25 km).\n","authors":["Gokul Radhakrishnan","Rahul Sundar","Nishant Parashar","Antoine Blanchard","Daiwei Wang","Boyko Dodov"],"pdf_url":"https://arxiv.org/pdf/2412.14620v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14619v1","updated":"2024-12-19T08:11:42Z","published":"2024-12-19T08:11:42Z","title":"Pitfalls of topology-aware image segmentation","summary":"  Topological correctness, i.e., the preservation of structural integrity and\nspecific characteristics of shape, is a fundamental requirement for medical\nimaging tasks, such as neuron or vessel segmentation. Despite the recent surge\nin topology-aware methods addressing this challenge, their real-world\napplicability is hindered by flawed benchmarking practices. In this paper, we\nidentify critical pitfalls in model evaluation that include inadequate\nconnectivity choices, overlooked topological artifacts in ground truth\nannotations, and inappropriate use of evaluation metrics. Through detailed\nempirical analysis, we uncover these issues' profound impact on the evaluation\nand ranking of segmentation methods. Drawing from our findings, we propose a\nset of actionable recommendations to establish fair and robust evaluation\nstandards for topology-aware medical image segmentation methods.\n","authors":["Alexander H. Berger","Laurin Lux","Alexander Weers","Martin Menten","Daniel Rueckert","Johannes C. Paetzold"],"pdf_url":"https://arxiv.org/pdf/2412.14619v1.pdf","comment":"Code is available at\n  https://github.com/AlexanderHBerger/topo-pitfalls"},{"id":"http://arxiv.org/abs/2412.14602v1","updated":"2024-12-19T07:48:14Z","published":"2024-12-19T07:48:14Z","title":"Towards Scalable and Deep Graph Neural Networks via Noise Masking","summary":"  In recent years, Graph Neural Networks (GNNs) have achieved remarkable\nsuccess in many graph mining tasks. However, scaling them to large graphs is\nchallenging due to the high computational and storage costs of repeated feature\npropagation and non-linear transformation during training. One commonly\nemployed approach to address this challenge is model-simplification, which only\nexecutes the Propagation (P) once in the pre-processing, and Combine (C) these\nreceptive fields in different ways and then feed them into a simple model for\nbetter performance. Despite their high predictive performance and scalability,\nthese methods still face two limitations. First, existing approaches mainly\nfocus on exploring different C methods from the model perspective, neglecting\nthe crucial problem of performance degradation with increasing P depth from the\ndata-centric perspective, known as the over-smoothing problem. Second,\npre-processing overhead takes up most of the end-to-end processing time,\nespecially for large-scale graphs. To address these limitations, we present\nrandom walk with noise masking (RMask), a plug-and-play module compatible with\nthe existing model-simplification works. This module enables the exploration of\ndeeper GNNs while preserving their scalability. Unlike the previous\nmodel-simplification works, we focus on continuous P and found that the noise\nexisting inside each P is the cause of the over-smoothing issue, and use the\nefficient masking mechanism to eliminate them. Experimental results on six\nreal-world datasets demonstrate that model-simplification works equipped with\nRMask yield superior performance compared to their original version and can\nmake a good trade-off between accuracy and efficiency.\n","authors":["Yuxuan Liang","Wentao Zhang","Zeang Sheng","Ling Yang","Quanqing Xu","Jiawei Jiang","Yunhai Tong","Bin Cu"],"pdf_url":"https://arxiv.org/pdf/2412.14602v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14599v1","updated":"2024-12-19T07:42:07Z","published":"2024-12-19T07:42:07Z","title":"Fast inverse lithography based on a model-driven block stacking\n  convolutional neural network","summary":"  In the realm of lithography, Optical Proximity Correction (OPC) is a crucial\nresolution enhancement technique that optimizes the transmission function of\nphotomasks on a pixel-based to effectively counter Optical Proximity Effects\n(OPE). However, conventional pixel-based OPC methods often generate patterns\nthat pose manufacturing challenges, thereby leading to the increased cost in\npractical scenarios. This paper presents a novel inverse lithographic approach\nto OPC, employing a model-driven, block stacking deep learning framework that\nexpedites the generation of masks conducive to manufacturing. This method is\nfounded on vector lithography modelling and streamlines the training process by\neliminating the requirement for extensive labeled datasets. Furthermore,\ndiversity of mask patterns is enhanced by employing a wave function collapse\nalgorithm, which facilitates the random generation of a multitude of target\npatterns, therefore significantly expanding the range of mask paradigm.\nNumerical experiments have substantiated the efficacy of the proposed\nend-to-end approach, highlighting its superior capability to manage mask\ncomplexity within the context of advanced OPC lithography. This advancement is\nanticipated to enhance the feasibility and economic viability of OPC technology\nwithin actual manufacturing environments.\n","authors":["Ruixiang Chen","Yang Zhao","Haoqin Li","Rui Chen"],"pdf_url":"https://arxiv.org/pdf/2412.14599v1.pdf","comment":"21 pages, 7 figures"},{"id":"http://arxiv.org/abs/2401.04979v3","updated":"2024-12-19T07:33:48Z","published":"2024-01-10T07:51:02Z","title":"DualDynamics: Synergizing Implicit and Explicit Methods for Robust\n  Irregular Time Series Analysis","summary":"  Real-world time series analysis faces significant challenges when dealing\nwith irregular and incomplete data. While Neural Differential Equation (NDE)\nbased methods have shown promise, they struggle with limited expressiveness,\nscalability issues, and stability concerns. Conversely, Neural Flows offer\nstability but falter with irregular data. We introduce 'DualDynamics', a novel\nframework that synergistically combines NDE-based method and Neural Flow-based\nmethod. This approach enhances expressive power while balancing computational\ndemands, addressing critical limitations of existing techniques. We demonstrate\nDualDynamics' effectiveness across diverse tasks: classification of robustness\nto dataset shift, irregularly-sampled series analysis, interpolation of missing\ndata, and forecasting with partial observations. Our results show consistent\noutperformance over state-of-the-art methods, indicating DualDynamics'\npotential to advance irregular time series analysis significantly.\n","authors":["YongKyung Oh","Dongyoung Lim","Sungil Kim"],"pdf_url":"https://arxiv.org/pdf/2401.04979v3.pdf","comment":"Published at the 39th Annual AAAI Conference on Artificial\n  Intelligence (AAAI 2025)"},{"id":"http://arxiv.org/abs/2412.14596v1","updated":"2024-12-19T07:31:40Z","published":"2024-12-19T07:31:40Z","title":"LDP: Generalizing to Multilingual Visual Information Extraction by\n  Language Decoupled Pretraining","summary":"  Visual Information Extraction (VIE) plays a crucial role in the comprehension\nof semi-structured documents, and several pre-trained models have been\ndeveloped to enhance performance. However, most of these works are monolingual\n(usually English). Due to the extremely unbalanced quantity and quality of\npre-training corpora between English and other languages, few works can extend\nto non-English scenarios. In this paper, we conduct systematic experiments to\nshow that vision and layout modality hold invariance among images with\ndifferent languages. If decoupling language bias from document images, a\nvision-layout-based model can achieve impressive cross-lingual generalization.\nAccordingly, we present a simple but effective multilingual training paradigm\nLDP (Language Decoupled Pre-training) for better utilization of monolingual\npre-training data. Our proposed model LDM (Language Decoupled Model) is first\npre-trained on the language-independent data, where the language knowledge is\ndecoupled by a diffusion model, and then the LDM is fine-tuned on the\ndownstream languages. Extensive experiments show that the LDM outperformed all\nSOTA multilingual pre-trained models, and also maintains competitiveness on\ndownstream monolingual/English benchmarks.\n","authors":["Huawen Shen","Gengluo Li","Jinwen Zhong","Yu Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.14596v1.pdf","comment":"Accepted by AAAI2025"},{"id":"http://arxiv.org/abs/2409.05929v2","updated":"2024-12-19T07:31:18Z","published":"2024-09-09T10:40:50Z","title":"Alt-MoE: Multimodal Alignment via Alternating Optimization of\n  Multi-directional MoE with Unimodal Models","summary":"  Recent Large Multi-Modal Models (LMMs) have made significant advancements in\nmulti-modal alignment by employing lightweight connection modules to facilitate\nthe representation and fusion of knowledge from existing pre-trained uni-modal\nmodels. However, these methods still rely on modality-specific and\ndirection-specific connectors, leading to compartmentalized knowledge\nrepresentations and reduced computational efficiency, which limits the model's\nability to form unified multi-modal representations. To address these issues,\nwe introduce a novel training framework, Alt-MoE, which employs the Mixture of\nExperts (MoE) as a unified multi-directional connector across modalities, and\nemploys a multi-step sequential alternating unidirectional alignment strategy,\nwhich converges to bidirectional alignment over iterations. The extensive\nempirical studies revealed the following key points: 1) Alt-MoE achieves\ncompetitive results by integrating diverse knowledge representations from\nuni-modal models. This approach seamlessly fuses the specialized expertise of\nexisting high-performance uni-modal models, effectively synthesizing their\ndomain-specific knowledge into a cohesive multi-modal representation. 2)\nAlt-MoE efficiently scales to new tasks and modalities without altering its\nmodel architecture or training strategy. Furthermore, Alt-MoE operates in\nlatent space, supporting vector pre-storage and real-time retrieval via\nlightweight multi-directional MoE, thereby facilitating massive data\nprocessing. Our methodology has been validated on several well-performing\nuni-modal models (LLAMA3, Qwen2, and DINOv2), achieving competitive results on\na wide range of downstream tasks and datasets.\n","authors":["Hongyang Lei","Xiaolong Cheng","Dan Wang","Kun Fan","Qi Qin","Huazhen Huang","Yetao Wu","Qingqing Gu","Zhonglin Jiang","Yong Chen","Luo Ji"],"pdf_url":"https://arxiv.org/pdf/2409.05929v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14592v1","updated":"2024-12-19T07:23:17Z","published":"2024-12-19T07:23:17Z","title":"Multi-Sensor Object Anomaly Detection: Unifying Appearance, Geometry,\n  and Internal Properties","summary":"  Object anomaly detection is essential for industrial quality inspection, yet\ntraditional single-sensor methods face critical limitations. They fail to\ncapture the wide range of anomaly types, as single sensors are often\nconstrained to either external appearance, geometric structure, or internal\nproperties. To overcome these challenges, we introduce MulSen-AD, the first\nhigh-resolution, multi-sensor anomaly detection dataset tailored for industrial\napplications. MulSen-AD unifies data from RGB cameras, laser scanners, and\nlock-in infrared thermography, effectively capturing external appearance,\ngeometric deformations, and internal defects. The dataset spans 15 industrial\nproducts with diverse, real-world anomalies. We also present MulSen-AD Bench, a\nbenchmark designed to evaluate multi-sensor methods, and propose\nMulSen-TripleAD, a decision-level fusion algorithm that integrates these three\nmodalities for robust, unsupervised object anomaly detection. Our experiments\ndemonstrate that multi-sensor fusion substantially outperforms single-sensor\napproaches, achieving 96.1% AUROC in object-level detection accuracy. These\nresults highlight the importance of integrating multi-sensor data for\ncomprehensive industrial anomaly detection.\n","authors":["Wenqiao Li","Bozhong Zheng","Xiaohao Xu","Jinye Gan","Fading Lu","Xiang Li","Na Ni","Zheng Tian","Xiaonan Huang","Shenghua Gao","Yingna Wu"],"pdf_url":"https://arxiv.org/pdf/2412.14592v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14590v1","updated":"2024-12-19T07:15:15Z","published":"2024-12-19T07:15:15Z","title":"MixLLM: LLM Quantization with Global Mixed-precision between\n  Output-features and Highly-efficient System Design","summary":"  Quantization has become one of the most effective methodologies to compress\nLLMs into smaller size. However, the existing quantization solutions still show\nlimitations of either non-negligible accuracy drop or system inefficiency. In\nthis paper, we make a comprehensive analysis of the general quantization\nprinciples on their effect to the triangle of accuracy, memory consumption and\nsystem efficiency. We propose MixLLM that explores the new optimization space\nof mixed-precision quantization between output features based on the insight\nthat different output features matter differently in the model. MixLLM\nidentifies the output features with high salience in the global view rather\nthan within each single layer, effectively assigning the larger bit-width to\noutput features that need it most to achieve good accuracy with low memory\nconsumption. We present the sweet spot of quantization configuration of\nalgorithm-system co-design that leads to high accuracy and system efficiency.\nTo address the system challenge, we design the two-step dequantization to make\nuse of the int8 Tensor Core easily and fast data type conversion to reduce\ndequantization overhead significantly, and present the software pipeline to\noverlap the memory access, dequantization and the MatMul to the best. Extensive\nexperiments show that with only 10% more bits, the PPL increasement can be\nreduced from about 0.5 in SOTA to within 0.2 for Llama 3.1 70B, while on\naverage MMLU-Pro improves by 0.93 over the SOTA of three popular models. In\naddition to its superior accuracy, MixLLM also achieves state-of-the-art system\nefficiency.\n","authors":["Zhen Zheng","Xiaonan Song","Chuanjie Liu"],"pdf_url":"https://arxiv.org/pdf/2412.14590v1.pdf","comment":"The code will be released in the future"},{"id":"http://arxiv.org/abs/2407.02419v3","updated":"2024-12-19T07:07:51Z","published":"2024-07-02T16:44:14Z","title":"Quantum Curriculum Learning","summary":"  Quantum machine learning (QML) requires significant quantum resources to\naddress practical real-world problems. When the underlying quantum information\nexhibits hierarchical structures in the data, limitations persist in training\ncomplexity and generalization. Research should prioritize both the efficient\ndesign of quantum architectures and the development of learning strategies to\noptimize resource usage. We propose a framework called quantum curriculum\nlearning (Q-CurL) for quantum data, where the curriculum introduces simpler\ntasks or data to the learning model before progressing to more challenging\nones. Q-CurL exhibits robustness to noise and data limitations, which is\nparticularly relevant for current and near-term noisy intermediate-scale\nquantum devices. We achieve this through a curriculum design based on quantum\ndata density ratios and a dynamic learning schedule that prioritizes the most\ninformative quantum data. Empirical evidence shows that Q-CurL significantly\nenhances training convergence and generalization for unitary learning and\nimproves the robustness of quantum phase recognition tasks. Q-CurL is effective\nwith broad physical learning applications in condensed matter physics and\nquantum chemistry.\n","authors":["Quoc Hoan Tran","Yasuhiro Endo","Hirotaka Oshima"],"pdf_url":"https://arxiv.org/pdf/2407.02419v3.pdf","comment":"main 6 pages, supplementary materials 11 pages (update the\n  supplementary materials with more explanation on data-based Q-CurL)"},{"id":"http://arxiv.org/abs/2302.03390v5","updated":"2024-12-19T07:05:03Z","published":"2023-02-07T10:51:53Z","title":"Learning Discretized Neural Networks under Ricci Flow","summary":"  In this paper, we study Discretized Neural Networks (DNNs) composed of\nlow-precision weights and activations, which suffer from either infinite or\nzero gradients due to the non-differentiable discrete function during training.\nMost training-based DNNs in such scenarios employ the standard Straight-Through\nEstimator (STE) to approximate the gradient w.r.t. discrete values. However,\nthe use of STE introduces the problem of gradient mismatch, arising from\nperturbations in the approximated gradient. To address this problem, this paper\nreveals that this mismatch can be interpreted as a metric perturbation in a\nRiemannian manifold, viewed through the lens of duality theory. Building on\ninformation geometry, we construct the Linearly Nearly Euclidean (LNE) manifold\nfor DNNs, providing a background for addressing perturbations. By introducing a\npartial differential equation on metrics, i.e., the Ricci flow, we establish\nthe dynamical stability and convergence of the LNE metric with the $L^2$-norm\nperturbation. In contrast to previous perturbation theories with convergence\nrates in fractional powers, the metric perturbation under the Ricci flow\nexhibits exponential decay in the LNE manifold. Experimental results across\nvarious datasets demonstrate that our method achieves superior and more stable\nperformance for DNNs compared to other representative training-based methods.\n","authors":["Jun Chen","Hanwen Chen","Mengmeng Wang","Guang Dai","Ivor W. Tsang","Yong Liu"],"pdf_url":"https://arxiv.org/pdf/2302.03390v5.pdf","comment":null},{"id":"http://arxiv.org/abs/2302.00284v3","updated":"2024-12-19T06:52:07Z","published":"2023-02-01T07:31:25Z","title":"Selective Uncertainty Propagation in Offline RL","summary":"  We consider the finite-horizon offline reinforcement learning (RL) setting,\nand are motivated by the challenge of learning the policy at any step h in\ndynamic programming (DP) algorithms. To learn this, it is sufficient to\nevaluate the treatment effect of deviating from the behavioral policy at step h\nafter having optimized the policy for all future steps. Since the policy at any\nstep can affect next-state distributions, the related distributional shift\nchallenges can make this problem far more statistically hard than estimating\nsuch treatment effects in the stochastic contextual bandit setting. However,\nthe hardness of many real-world RL instances lies between the two regimes. We\ndevelop a flexible and general method called selective uncertainty propagation\nfor confidence interval construction that adapts to the hardness of the\nassociated distribution shift challenges. We show benefits of our approach on\ntoy environments and demonstrate the benefits of these techniques for offline\npolicy learning.\n","authors":["Sanath Kumar Krishnamurthy","Tanmay Gangwani","Sumeet Katariya","Branislav Kveton","Shrey Modi","Anshuka Rangi"],"pdf_url":"https://arxiv.org/pdf/2302.00284v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2403.07728v3","updated":"2024-12-19T06:51:17Z","published":"2024-03-12T15:07:20Z","title":"CAP: A General Algorithm for Online Selective Conformal Prediction with\n  FCR Control","summary":"  We study the problem of post-selection predictive inference in an online\nfashion. To avoid devoting resources to unimportant units, a preliminary\nselection of the current individual before reporting its prediction interval is\ncommon and meaningful in online predictive tasks. Since the online selection\ncauses a temporal multiplicity in the selected prediction intervals, it is\nimportant to control the real-time false coverage-statement rate (FCR) which\nmeasures the overall miscoverage level. We develop a general framework named\nCAP (Calibration after Adaptive Pick) that performs an adaptive pick rule on\nhistorical data to construct a calibration set if the current individual is\nselected and then outputs a conformal prediction interval for the unobserved\nlabel. We provide tractable procedures for constructing the calibration set for\npopular online selection rules. We proved that CAP can achieve an exact\nselection-conditional coverage guarantee in the finite-sample and\ndistribution-free regimes. To account for the distribution shift in online\ndata, we also embed CAP into some recent dynamic conformal prediction\nalgorithms and show that the proposed method can deliver long-run FCR control.\nNumerical results on both synthetic and real data corroborate that CAP can\neffectively control FCR around the target level and yield more narrowed\nprediction intervals over existing baselines across various settings.\n","authors":["Yajie Bao","Yuyang Huo","Haojie Ren","Changliang Zou"],"pdf_url":"https://arxiv.org/pdf/2403.07728v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14572v1","updated":"2024-12-19T06:42:57Z","published":"2024-12-19T06:42:57Z","title":"Accelerated Patient-Specific Calibration via Differentiable Hemodynamics\n  Simulations","summary":"  One of the goals of personalized medicine is to tailor diagnostics to\nindividual patients. Diagnostics are performed in practice by measuring\nquantities, called biomarkers, that indicate the existence and progress of a\ndisease. In common cardiovascular diseases, such as hypertension, biomarkers\nthat are closely related to the clinical representation of a patient can be\npredicted using computational models. Personalizing computational models\ntranslates to considering patient-specific flow conditions, for example, the\ncompliance of blood vessels that cannot be a priori known and quantities such\nas the patient geometry that can be measured using imaging. Therefore, a\npatient is identified by a set of measurable and nonmeasurable parameters\nneeded to well-define a computational model; else, the computational model is\nnot personalized, meaning it is prone to large prediction errors. Therefore, to\npersonalize a computational model, sufficient information needs to be extracted\nfrom the data. The current methods by which this is done are either\ninefficient, due to relying on slow-converging optimization methods, or hard to\ninterpret, due to using `black box` deep-learning algorithms. We propose a\npersonalized diagnostic procedure based on a differentiable 0D-1D Navier-Stokes\nreduced order model solver and fast parameter inference methods that take\nadvantage of gradients through the solver. By providing a faster method for\nperforming parameter inference and sensitivity analysis through\ndifferentiability while maintaining the interpretability of well-understood\nmathematical models and numerical methods, the best of both worlds is combined.\nThe performance of the proposed solver is validated against a well-established\nprocess on different geometries, and different parameter inference processes\nare successfully performed.\n","authors":["Diego Renner","Georgios Kissas"],"pdf_url":"https://arxiv.org/pdf/2412.14572v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14569v1","updated":"2024-12-19T06:40:21Z","published":"2024-12-19T06:40:21Z","title":"Global Spatio-Temporal Fusion-based Traffic Prediction Algorithm with\n  Anomaly Aware","summary":"  Traffic prediction is an indispensable component of urban planning and\ntraffic management. Achieving accurate traffic prediction hinges on the ability\nto capture the potential spatio-temporal relationships among road sensors.\nHowever, the majority of existing works focus on local short-term\nspatio-temporal correlations, failing to fully consider the interactions of\ndifferent sensors in the long-term state. In addition, these works do not\nanalyze the influences of anomalous factors, or have insufficient ability to\nextract personalized features of anomalous factors, which make them\nineffectively capture their spatio-temporal influences on traffic prediction.\nTo address the aforementioned issues, We propose a global spatio-temporal\nfusion-based traffic prediction algorithm that incorporates anomaly awareness.\nInitially, based on the designed anomaly detection network, we construct an\nefficient anomalous factors impacting module (AFIM), to evaluate the\nspatio-temporal impact of unexpected external events on traffic prediction.\nFurthermore, we propose a multi-scale spatio-temporal feature fusion module\n(MTSFFL) based on the transformer architecture, to obtain all possible both\nlong and short term correlations among different sensors in a wide-area traffic\nenvironment for accurate prediction of traffic flow. Finally, experiments are\nimplemented based on real-scenario public transportation datasets (PEMS04 and\nPEMS08) to demonstrate that our approach can achieve state-of-the-art\nperformance.\n","authors":["Chaoqun Liu","Xuanpeng Li","Chen Gong","Guangyu Li"],"pdf_url":"https://arxiv.org/pdf/2412.14569v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.21853v2","updated":"2024-12-19T06:39:24Z","published":"2024-10-29T08:28:23Z","title":"Learning Infinitesimal Generators of Continuous Symmetries from Data","summary":"  Exploiting symmetry inherent in data can significantly improve the sample\nefficiency of a learning procedure and the generalization of learned models.\nWhen data clearly reveals underlying symmetry, leveraging this symmetry can\nnaturally inform the design of model architectures or learning strategies. Yet,\nin numerous real-world scenarios, identifying the specific symmetry within a\ngiven data distribution often proves ambiguous. To tackle this, some existing\nworks learn symmetry in a data-driven manner, parameterizing and learning\nexpected symmetry through data. However, these methods often rely on explicit\nknowledge, such as pre-defined Lie groups, which are typically restricted to\nlinear or affine transformations. In this paper, we propose a novel symmetry\nlearning algorithm based on transformations defined with one-parameter groups,\ncontinuously parameterized transformations flowing along the directions of\nvector fields called infinitesimal generators. Our method is built upon minimal\ninductive biases, encompassing not only commonly utilized symmetries rooted in\nLie groups but also extending to symmetries derived from nonlinear generators.\nTo learn these symmetries, we introduce a notion of a validity score that\nexamine whether the transformed data is still valid for the given task. The\nvalidity score is designed to be fully differentiable and easily computable,\nenabling effective searches for transformations that achieve symmetries innate\nto the data. We apply our method mainly in two domains: image data and partial\ndifferential equations, and demonstrate its advantages. Our codes are available\nat \\url{https://github.com/kogyeonghoon/learning-symmetry-from-scratch.git}.\n","authors":["Gyeonghoon Ko","Hyunsu Kim","Juho Lee"],"pdf_url":"https://arxiv.org/pdf/2410.21853v2.pdf","comment":"Neurips 2024"},{"id":"http://arxiv.org/abs/2412.14566v1","updated":"2024-12-19T06:35:54Z","published":"2024-12-19T06:35:54Z","title":"AIArena: A Blockchain-Based Decentralized AI Training Platform","summary":"  The rapid advancement of AI has underscored critical challenges in its\ndevelopment and implementation, largely due to centralized control by a few\nmajor corporations. This concentration of power intensifies biases within AI\nmodels, resulting from inadequate governance and oversight mechanisms.\nAdditionally, it limits public involvement and heightens concerns about the\nintegrity of model generation. Such monopolistic control over data and AI\noutputs threatens both innovation and fair data usage, as users inadvertently\ncontribute data that primarily benefits these corporations. In this work, we\npropose AIArena, a blockchain-based decentralized AI training platform designed\nto democratize AI development and alignment through on-chain incentive\nmechanisms. AIArena fosters an open and collaborative environment where\nparticipants can contribute models and computing resources. Its on-chain\nconsensus mechanism ensures fair rewards for participants based on their\ncontributions. We instantiate and implement AIArena on the public Base\nblockchain Sepolia testnet, and the evaluation results demonstrate the\nfeasibility of AIArena in real-world applications.\n","authors":["Zhipeng Wang","Rui Sun","Elizabeth Lui","Tuo Zhou","Yizhe Wen","Jiahao Sun"],"pdf_url":"https://arxiv.org/pdf/2412.14566v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08282v2","updated":"2024-12-19T06:35:21Z","published":"2024-12-11T10:57:16Z","title":"How Does the Smoothness Approximation Method Facilitate Generalization\n  for Federated Adversarial Learning?","summary":"  Federated Adversarial Learning (FAL) is a robust framework for resisting\nadversarial attacks on federated learning. Although some FAL studies have\ndeveloped efficient algorithms, they primarily focus on convergence performance\nand overlook generalization. Generalization is crucial for evaluating algorithm\nperformance on unseen data. However, generalization analysis is more\nchallenging due to non-smooth adversarial loss functions. A common approach to\naddressing this issue is to leverage smoothness approximation. In this paper,\nwe develop algorithm stability measures to evaluate the generalization\nperformance of two popular FAL algorithms: \\textit{Vanilla FAL (VFAL)} and {\\it\nSlack FAL (SFAL)}, using three different smooth approximation methods: 1)\n\\textit{Surrogate Smoothness Approximation (SSA)}, (2) \\textit{Randomized\nSmoothness Approximation (RSA)}, and (3) \\textit{Over-Parameterized Smoothness\nApproximation (OPSA)}. Based on our in-depth analysis, we answer the question\nof how to properly set the smoothness approximation method to mitigate\ngeneralization error in FAL. Moreover, we identify RSA as the most effective\nmethod for reducing generalization error. In highly data-heterogeneous\nscenarios, we also recommend employing SFAL to mitigate the deterioration of\ngeneralization performance caused by heterogeneity. Based on our theoretical\nresults, we provide insights to help develop more efficient FAL algorithms,\nsuch as designing new metrics and dynamic aggregation rules to mitigate\nheterogeneity.\n","authors":["Wenjun Ding","Ying An","Lixing Chen","Shichao Kan","Fan Wu","Zhe Qu"],"pdf_url":"https://arxiv.org/pdf/2412.08282v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2312.11973v6","updated":"2024-12-19T06:29:38Z","published":"2023-12-19T09:11:49Z","title":"Continual Learning: Forget-free Winning Subnetworks for Video\n  Representations","summary":"  Inspired by the Lottery Ticket Hypothesis (LTH), which highlights the\nexistence of efficient subnetworks within larger, dense networks, a\nhigh-performing Winning Subnetwork (WSN) in terms of task performance under\nappropriate sparsity conditions is considered for various continual learning\ntasks. It leverages pre-existing weights from dense networks to achieve\nefficient learning in Task Incremental Learning (TIL) and Task-agnostic\nIncremental Learning (TaIL) scenarios. In Few-Shot Class Incremental Learning\n(FSCIL), a variation of WSN referred to as the Soft subnetwork (SoftNet) is\ndesigned to prevent overfitting when the data samples are scarce. Furthermore,\nthe sparse reuse of WSN weights is considered for Video Incremental Learning\n(VIL). The use of Fourier Subneural Operator (FSO) within WSN is considered. It\nenables compact encoding of videos and identifies reusable subnetworks across\nvarying bandwidths. We have integrated FSO into different architectural\nframeworks for continual learning, including VIL, TIL, and FSCIL. Our\ncomprehensive experiments demonstrate FSO's effectiveness, significantly\nimproving task performance at various convolutional representational levels.\nSpecifically, FSO enhances higher-layer performance in TIL and FSCIL and\nlower-layer performance in VIL.\n","authors":["Haeyong Kang","Jaehong Yoon","Sung Ju Hwang","Chang D. Yoo"],"pdf_url":"https://arxiv.org/pdf/2312.11973v6.pdf","comment":"IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (T-PAMI)"},{"id":"http://arxiv.org/abs/2412.14561v1","updated":"2024-12-19T06:26:16Z","published":"2024-12-19T06:26:16Z","title":"GBRIP: Granular Ball Representation for Imbalanced Partial Label\n  Learning","summary":"  Partial label learning (PLL) is a complicated weakly supervised\nmulti-classification task compounded by class imbalance. Currently, existing\nmethods only rely on inter-class pseudo-labeling from inter-class features,\noften overlooking the significant impact of the intra-class imbalanced features\ncombined with the inter-class. To address these limitations, we introduce\nGranular Ball Representation for Imbalanced PLL (GBRIP), a novel framework for\nimbalanced PLL. GBRIP utilizes coarse-grained granular ball representation and\nmulti-center loss to construct a granular ball-based nfeature space through\nunsupervised learning, effectively capturing the feature distribution within\neach class. GBRIP mitigates the impact of confusing features by systematically\nrefining label disambiguation and estimating imbalance distributions. The novel\nmulti-center loss function enhances learning by emphasizing the relationships\nbetween samples and their respective centers within the granular balls.\nExtensive experiments on standard benchmarks demonstrate that GBRIP outperforms\nexisting state-of-the-art methods, offering a robust solution to the challenges\nof imbalanced PLL.\n","authors":["Jintao Huang","Yiu-ming Cheung","Chi-man Vong","Wenbin Qian"],"pdf_url":"https://arxiv.org/pdf/2412.14561v1.pdf","comment":"AAAI25"},{"id":"http://arxiv.org/abs/2403.10650v3","updated":"2024-12-19T06:25:45Z","published":"2024-03-15T19:35:10Z","title":"PALM: Pushing Adaptive Learning Rate Mechanisms for Continual Test-Time\n  Adaptation","summary":"  Real-world vision models in dynamic environments face rapid shifts in domain\ndistributions, leading to decreased recognition performance. Using unlabeled\ntest data, continuous test-time adaptation (CTTA) directly adjusts a\npre-trained source discriminative model to these changing domains. A highly\neffective CTTA method involves applying layer-wise adaptive learning rates for\nselectively adapting pre-trained layers. However, it suffers from the poor\nestimation of domain shift and the inaccuracies arising from the pseudo-labels.\nThis work aims to overcome these limitations by identifying layers for\nadaptation via quantifying model prediction uncertainty without relying on\npseudo-labels. We utilize the magnitude of gradients as a metric, calculated by\nbackpropagating the KL divergence between the softmax output and a uniform\ndistribution, to select layers for further adaptation. Subsequently, for the\nparameters exclusively belonging to these selected layers, with the remaining\nones frozen, we evaluate their sensitivity to approximate the domain shift and\nadjust their learning rates accordingly. We conduct extensive image\nclassification experiments on CIFAR-10C, CIFAR-100C, and ImageNet-C,\ndemonstrating the superior efficacy of our method compared to prior approaches.\n","authors":["Sarthak Kumar Maharana","Baoming Zhang","Yunhui Guo"],"pdf_url":"https://arxiv.org/pdf/2403.10650v3.pdf","comment":"AAAI 2025"}]},"2024-12-18T00:00:00Z":{"Computation and Language":[{"id":"http://arxiv.org/abs/2412.14414v1","updated":"2024-12-18T23:58:13Z","published":"2024-12-18T23:58:13Z","title":"In-Group Love, Out-Group Hate: A Framework to Measure Affective\n  Polarization via Contentious Online Discussions","summary":"  Affective polarization, the emotional divide between ideological groups\nmarked by in-group love and out-group hate, has intensified in the United\nStates, driving contentious issues like masking and lockdowns during the\nCOVID-19 pandemic. Despite its societal impact, existing models of opinion\nchange fail to account for emotional dynamics nor offer methods to quantify\naffective polarization robustly and in real-time. In this paper, we introduce a\ndiscrete choice model that captures decision-making within affectively\npolarized social networks and propose a statistical inference method estimate\nkey parameters -- in-group love and out-group hate -- from social media data.\nThrough empirical validation from online discussions about the COVID-19\npandemic, we demonstrate that our approach accurately captures real-world\npolarization dynamics and explains the rapid emergence of a partisan gap in\nattitudes towards masking and lockdowns. This framework allows for tracking\naffective polarization across contentious issues has broad implications for\nfostering constructive online dialogues in digital spaces.\n","authors":["Buddhika Nettasinghe","Ashwin Rao","Bohan Jiang","Allon Percus","Kristina Lerman"],"pdf_url":"https://arxiv.org/pdf/2412.14414v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.14748v3","updated":"2024-12-18T23:36:03Z","published":"2024-10-17T19:38:55Z","title":"ETF: An Entity Tracing Framework for Hallucination Detection in Code\n  Summaries","summary":"  Recent advancements in large language models (LLMs) have significantly\nenhanced their ability to understand both natural language and code, driving\ntheir use in tasks like natural language-to-code (NL2Code) and code\nsummarization. However, LLMs are prone to hallucination-outputs that stray from\nintended meanings. Detecting hallucinations in code summarization is especially\ndifficult due to the complex interplay between programming and natural\nlanguages. We introduce a first-of-its-kind dataset with $\\sim$10K samples,\ncurated specifically for hallucination detection in code summarization. We\nfurther propose a novel Entity Tracing Framework (ETF) that a) utilizes static\nprogram analysis to identify code entities from the program and b) uses LLMs to\nmap and verify these entities and their intents within generated code\nsummaries. Our experimental analysis demonstrates the effectiveness of the\nframework, leading to a 0.73 F1 score. This approach provides an interpretable\nmethod for detecting hallucinations by grounding entities, allowing us to\nevaluate summary accuracy.\n","authors":["Kishan Maharaj","Vitobha Munigala","Srikanth G. Tamilselvam","Prince Kumar","Sayandeep Sen","Palani Kodeswaran","Abhijit Mishra","Pushpak Bhattacharyya"],"pdf_url":"https://arxiv.org/pdf/2410.14748v3.pdf","comment":"11 pages, 6 Figures, 5 Tables"},{"id":"http://arxiv.org/abs/2402.15083v2","updated":"2024-12-18T23:11:48Z","published":"2024-02-23T04:02:23Z","title":"Hands-Free VR","summary":"  The paper introduces Hands-Free VR, a voice-based natural-language interface\nfor VR. The user gives a command using their voice, the speech audio data is\nconverted to text using a speech-to-text deep learning model that is fine-tuned\nfor robustness to word phonetic similarity and to spoken English accents, and\nthe text is mapped to an executable VR command using a large language model\nthat is robust to natural language diversity. Hands-Free VR was evaluated in a\ncontrolled within-subjects study (N = 22) that asked participants to find\nspecific objects and to place them in various configurations. In the control\ncondition participants used a conventional VR user interface to grab, carry,\nand position the objects using the handheld controllers. In the experimental\ncondition participants used Hands-Free VR. The results confirm that: (1)\nHands-Free VR is robust to spoken English accents, as for 20 of our\nparticipants English was not their first language, and to word phonetic\nsimilarity, correctly transcribing the voice command 96.71% of the time; (2)\nHands-Free VR is robust to natural language diversity, correctly mapping the\ntranscribed command to an executable command in 97.83% of the time; (3)\nHands-Free VR had a significant efficiency advantage over the conventional VR\ninterface in terms of task completion time, total viewpoint translation, total\nview direction rotation, and total left and right hand translations; (4)\nHands-Free VR received high user preference ratings in terms of ease of use,\nintuitiveness, ergonomics, reliability, and desirability.\n","authors":["Jorge Askur Vazquez Fernandez","Jae Joong Lee","Santiago Andrés Serrano Vacca","Alejandra Magana","Radim Pesam","Bedrich Benes","Voicu Popescu"],"pdf_url":"https://arxiv.org/pdf/2402.15083v2.pdf","comment":"The first two authors contributed equally. Accepted VISIGRAPP@HUCAPP\n  2025"},{"id":"http://arxiv.org/abs/2409.01227v3","updated":"2024-12-18T23:04:46Z","published":"2024-09-02T13:02:51Z","title":"Prompt Compression with Context-Aware Sentence Encoding for Fast and\n  Improved LLM Inference","summary":"  Large language models (LLMs) have triggered a new stream of research focusing\non compressing the context length to reduce the computational cost while\nensuring the retention of helpful information for LLMs to answer the given\nquestion. Token-based removal methods are one of the most prominent approaches\nin this direction, but risk losing the semantics of the context caused by\nintermediate token removal, especially under high compression ratios, while\nalso facing challenges in computational efficiency. In this work, we propose\ncontext-aware prompt compression (CPC), a sentence-level prompt compression\ntechnique where its key innovation is a novel context-aware sentence encoder\nthat provides a relevance score for each sentence for a given question. To\ntrain this encoder, we generate a new dataset consisting of questions,\npositives, and negative pairs where positives are sentences relevant to the\nquestion, while negatives are irrelevant context sentences. We train the\nencoder in a contrastive setup to learn context-aware sentence representations.\nOur method considerably outperforms prior works on prompt compression on\nbenchmark datasets and is up to 10.93x faster at inference compared to the best\ntoken-level compression method. We also find better improvement for shorter\nlength constraints in most benchmarks, showing the effectiveness of our\nproposed solution in the compression of relevant information in a shorter\ncontext. Finally, we release the code and the dataset for quick reproducibility\nand further development: https://github.com/Workday/cpc.\n","authors":["Barys Liskavets","Maxim Ushakov","Shuvendu Roy","Mark Klibanov","Ali Etemad","Shane Luke"],"pdf_url":"https://arxiv.org/pdf/2409.01227v3.pdf","comment":"Accepted in AAAI Conference on Artificial Intelligence (AAAI-25)"},{"id":"http://arxiv.org/abs/2404.18988v4","updated":"2024-12-18T22:26:15Z","published":"2024-04-29T17:36:58Z","title":"Markovian Transformers for Informative Language Modeling","summary":"  Chain-of-Thought (CoT) reasoning holds great promise for explaining language\nmodel outputs, but recent studies have highlighted significant challenges in\nits practical application for interpretability. We propose to address this\nissue by making CoT causally essential to prediction through two key\ncomponents: factoring next-token prediction through intermediate CoT text, and\ntraining CoT to predict future tokens independently of other context. This\nresults in \"Markovian\" language models, where CoT serves as a fixed-size state\nfor future token prediction. Our approach optimizes for \"informativeness\" - the\nimprovement in next-token predictions using a trained CoT compared to a\nbaseline. Using Proximal Policy Optimization (PPO) for arithmetic problems and\npolicy gradient for GSM8K, we demonstrate effectiveness on both arithmetic\nproblems with Mistral 7B and the GSM8K benchmark with Llama 3.1 8B, where the\nmodel learns to produce CoTs that are 33.20% more effective at predicting\nanswers than the pre-trained baseline. The increased sensitivity of model\nperformance to CoT perturbations provides strong evidence of CoT reliance.\nFurthermore, we show that CoTs trained for one model generalize to help other\nmodels predict answers, suggesting these CoTs capture reasoning patterns that\ntransfer across different interpreters. This work advances the development of\nmore interpretable language models, potentially enabling their extension to\narbitrarily long contexts and enhancing AI reasoning capabilities across\nvarious domains.\n","authors":["Scott Viteri","Max Lamparth","Peter Chatain","Clark Barrett"],"pdf_url":"https://arxiv.org/pdf/2404.18988v4.pdf","comment":"20 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.14373v1","updated":"2024-12-18T22:13:21Z","published":"2024-12-18T22:13:21Z","title":"ECG-Byte: A Tokenizer for End-to-End Generative Electrocardiogram\n  Language Modeling","summary":"  Large Language Models (LLMs) have shown remarkable adaptability across\ndomains beyond text, specifically electrocardiograms (ECGs). More specifically,\nthere is a growing body of work exploring the task of generating text from a\nmulti-channeled ECG and corresponding textual prompt. Current approaches\ntypically involve pretraining an ECG-specific encoder with a self-supervised\nlearning (SSL) objective and using the features output by the pretrained\nencoder to finetune a LLM for natural language generation (NLG). However, these\nmethods are limited by 1) inefficiency from two-stage training and 2)\ninterpretability challenges with encoder-generated features. To address these\nlimitations, we introduce ECG-Byte, an adapted byte pair encoding (BPE)\ntokenizer pipeline for autoregressive language modeling of ECGs. This approach\ncompresses and encodes ECG signals into tokens, enabling end-to-end LLM\ntraining by combining ECG and text tokens directly, while being much more\ninterpretable since the ECG tokens can be directly mapped back to the original\nsignal. Using ECG-Byte, we achieve competitive performance in NLG tasks in only\nhalf the time and ~48% of the data required by two-stage approaches.\n","authors":["William Han","Chaojing Duan","Michael A. Rosenberg","Emerson Liu","Ding Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.14373v1.pdf","comment":"26 pages, 17 figures"},{"id":"http://arxiv.org/abs/2412.14368v1","updated":"2024-12-18T22:04:56Z","published":"2024-12-18T22:04:56Z","title":"Memorization Over Reasoning? Exposing and Mitigating Verbatim\n  Memorization in Large Language Models' Character Understanding Evaluation","summary":"  Recently, Large Language Models (LLMs) have shown impressive performance in\ncharacter understanding tasks, such as analyzing the roles, personalities, and\nrelationships of fictional characters. However, the extensive pre-training\ncorpora used by LLMs raise concerns that they may rely on memorizing popular\nfictional works rather than genuinely understanding and reasoning about them.\nIn this work, we argue that 'gist memory'-capturing essential meaning - should\nbe the primary mechanism for character understanding tasks, as opposed to\n'verbatim memory' - exact match of a string. We introduce a simple yet\neffective method to mitigate mechanized memorization in character understanding\nevaluations while preserving the essential implicit cues needed for\ncomprehension and reasoning. Our approach reduces memorization-driven\nperformance on popular fictional works from 96% accuracy to 72% and results in\nup to an 18% drop in accuracy across various character understanding tasks.\nThese findings underscore the issue of data contamination in existing\nbenchmarks, which often measure memorization rather than true character\nunderstanding.\n","authors":["Yuxuan Jiang","Francis Ferraro"],"pdf_url":"https://arxiv.org/pdf/2412.14368v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14363v1","updated":"2024-12-18T22:01:55Z","published":"2024-12-18T22:01:55Z","title":"ResQ: Mixed-Precision Quantization of Large Language Models with\n  Low-Rank Residuals","summary":"  Post-training quantization (PTQ) of large language models (LLMs) holds the\npromise in reducing the prohibitive computational cost at inference time.\nQuantization of all weight, activation and key-value (KV) cache tensors to\n4-bit without significantly degrading generalizability is challenging, due to\nthe high quantization error caused by extreme outliers in activations. To\ntackle this problem, we propose ResQ, a PTQ method that pushes further the\nstate-of-the-art. By means of principal component analysis (PCA), it identifies\na low-rank subspace (in practice 1/8 of the hidden dimension) in which\nactivation variances are highest, and keep the coefficients within this\nsubspace in high precision, e.g. 8-bit, while quantizing the rest to 4-bit.\nWithin each subspace, invariant random rotation is applied to further suppress\noutliers. We show that this is a provably optimal mixed precision quantization\nscheme that minimizes error. With the Llama families of models, we demonstrate\nthat ResQ outperforms recent uniform and mixed precision PTQ methods on a\nvariety of benchmarks, achieving up to 33% lower perplexity on Wikitext than\nthe next best method SpinQuant, and a 2.4x speedup over 16-bit baseline. Code\nis available at https://github.com/utkarsh-dmx/project-resq.\n","authors":["Utkarsh Saxena","Sayeh Sharify","Kaushik Roy","Xin Wang"],"pdf_url":"https://arxiv.org/pdf/2412.14363v1.pdf","comment":"14 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2412.10571v2","updated":"2024-12-18T22:01:52Z","published":"2024-12-13T21:28:17Z","title":"Evidence Contextualization and Counterfactual Attribution for\n  Conversational QA over Heterogeneous Data with RAG Systems","summary":"  Retrieval Augmented Generation (RAG) works as a backbone for interacting with\nan enterprise's own data via Conversational Question Answering (ConvQA). In a\nRAG system, a retriever fetches passages from a collection in response to a\nquestion, which are then included in the prompt of a large language model (LLM)\nfor generating a natural language (NL) answer. However, several RAG systems\ntoday suffer from two shortcomings: (i) retrieved passages usually contain\ntheir raw text and lack appropriate document context, negatively impacting both\nretrieval and answering quality; and (ii) attribution strategies that explain\nanswer generation usually rely only on similarity between the answer and the\nretrieved passages, thereby only generating plausible but not causal\nexplanations. In this work, we demonstrate RAGONITE, a RAG system that remedies\nthe above concerns by: (i) contextualizing evidence with source metadata and\nsurrounding text; and (ii) computing counterfactual attribution, a causal\nexplanation approach where the contribution of an evidence to an answer is\ndetermined by the similarity of the original response to the answer obtained by\nremoving that evidence. To evaluate our proposals, we release a new benchmark\nConfQuestions, with 300 hand-created conversational questions, each in English\nand German, coupled with ground truth URLs, completed questions, and answers\nfrom 215 public Confluence pages, that are typical of enterprise wiki spaces\nwith heterogeneous elements. Experiments with RAGONITE on ConfQuestions show\nthe viability of our ideas: contextualization improves RAG performance, and\ncounterfactual attribution is effective at explaining RAG answers.\n","authors":["Rishiraj Saha Roy","Joel Schlotthauer","Chris Hinze","Andreas Foltyn","Luzian Hahn","Fabian Kuech"],"pdf_url":"https://arxiv.org/pdf/2412.10571v2.pdf","comment":"Accepted at WSDM 2025"},{"id":"http://arxiv.org/abs/2412.14354v1","updated":"2024-12-18T21:42:15Z","published":"2024-12-18T21:42:15Z","title":"State Space Models are Strong Text Rerankers","summary":"  Transformers dominate NLP and IR; but their inference inefficiencies and\nchallenges in extrapolating to longer contexts have sparked interest in\nalternative model architectures. Among these, state space models (SSMs) like\nMamba offer promising advantages, particularly $O(1)$ time complexity in\ninference. Despite their potential, SSMs' effectiveness at text reranking -- a\ntask requiring fine-grained query-document interaction and long-context\nunderstanding -- remains underexplored.\n  This study benchmarks SSM-based architectures (specifically, Mamba-1 and\nMamba-2) against transformer-based models across various scales, architectures,\nand pre-training objectives, focusing on performance and efficiency in text\nreranking tasks. We find that (1) Mamba architectures achieve competitive text\nranking performance, comparable to transformer-based models of similar size;\n(2) they are less efficient in training and inference compared to transformers\nwith flash attention; and (3) Mamba-2 outperforms Mamba-1 in both performance\nand efficiency. These results underscore the potential of state space models as\na transformer alternative and highlight areas for improvement in future IR\napplications.\n","authors":["Zhichao Xu","Jinghua Yan","Ashim Gupta","Vivek Srikumar"],"pdf_url":"https://arxiv.org/pdf/2412.14354v1.pdf","comment":"The first two authors contributed equally, order decided randomly"},{"id":"http://arxiv.org/abs/2412.14352v1","updated":"2024-12-18T21:37:07Z","published":"2024-12-18T21:37:07Z","title":"A Survey on LLM Inference-Time Self-Improvement","summary":"  Techniques that enhance inference through increased computation at test-time\nhave recently gained attention. In this survey, we investigate the current\nstate of LLM Inference-Time Self-Improvement from three different perspectives:\nIndependent Self-improvement, focusing on enhancements via decoding or sampling\nmethods; Context-Aware Self-Improvement, leveraging additional context or\ndatastore; and Model-Aided Self-Improvement, achieving improvement through\nmodel collaboration. We provide a comprehensive review of recent relevant\nstudies, contribute an in-depth taxonomy, and discuss challenges and\nlimitations, offering insights for future research.\n","authors":["Xiangjue Dong","Maria Teleki","James Caverlee"],"pdf_url":"https://arxiv.org/pdf/2412.14352v1.pdf","comment":"The first two authors contribute equally"},{"id":"http://arxiv.org/abs/2412.14351v1","updated":"2024-12-18T21:34:42Z","published":"2024-12-18T21:34:42Z","title":"Is Peer-Reviewing Worth the Effort?","summary":"  How effective is peer-reviewing in identifying important papers? We treat\nthis question as a forecasting task. Can we predict which papers will be highly\ncited in the future based on venue and \"early returns\" (citations soon after\npublication)? We show early returns are more predictive than venue. Finally, we\nend with constructive suggestions to address scaling challenges: (a) too many\nsubmissions and (b) too few qualified reviewers.\n","authors":["Kenneth Church","Raman Chandrasekar","John E. Ortega","Ibrahim Said Ahmad"],"pdf_url":"https://arxiv.org/pdf/2412.14351v1.pdf","comment":"The 31st International Conference on Computational Linguistics\n  (COLING 2025)"},{"id":"http://arxiv.org/abs/2402.11512v5","updated":"2024-12-18T21:28:54Z","published":"2024-02-18T08:53:41Z","title":"From Prejudice to Parity: A New Approach to Debiasing Large Language\n  Model Word Embeddings","summary":"  Embeddings play a pivotal role in the efficacy of Large Language Models. They\nare the bedrock on which these models grasp contextual relationships and foster\na more nuanced understanding of language and consequently perform remarkably on\na plethora of complex tasks that require a fundamental understanding of human\nlanguage. Given that these embeddings themselves often reflect or exhibit bias,\nit stands to reason that these models may also inadvertently learn this bias.\nIn this work, we build on the seminal previous work and propose DeepSoftDebias,\nan algorithm that uses a neural network to perform 'soft debiasing'. We\nexhaustively evaluate this algorithm across a variety of SOTA datasets,\naccuracy metrics, and challenging NLP tasks. We find that DeepSoftDebias\noutperforms the current state-of-the-art methods at reducing bias across\ngender, race, and religion.\n","authors":["Aishik Rakshit","Smriti Singh","Shuvam Keshari","Arijit Ghosh Chowdhury","Vinija Jain","Aman Chadha"],"pdf_url":"https://arxiv.org/pdf/2402.11512v5.pdf","comment":"Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2401.12208v2","updated":"2024-12-18T20:56:18Z","published":"2024-01-22T18:51:07Z","title":"A Vision-Language Foundation Model to Enhance Efficiency of Chest X-ray\n  Interpretation","summary":"  Over 1.4 billion chest X-rays (CXRs) are performed annually due to their\ncost-effectiveness as an initial diagnostic test. This scale of radiological\nstudies provides a significant opportunity to streamline CXR interpretation and\ndocumentation. While foundation models are a promising solution, the lack of\npublicly available large-scale datasets and benchmarks inhibits their iterative\ndevelopment and real-world evaluation. To overcome these challenges, we\nconstructed a large-scale dataset (CheXinstruct), which we utilized to train a\nvision-language foundation model (CheXagent). We systematically demonstrated\ncompetitive performance across eight distinct task types on our novel\nevaluation benchmark (CheXbench). Beyond technical validation, we assessed the\nreal-world utility of CheXagent in directly drafting radiology reports. Our\nclinical assessment with eight radiologists revealed a 36% time saving for\nresidents using CheXagent-drafted reports, while attending radiologists showed\nno significant time difference editing resident-drafted or CheXagent-drafted\nreports. The CheXagent-drafted reports improved the writing efficiency of both\nradiology residents and attending radiologists in 81% and 61% of cases,\nrespectively, without loss of quality. Overall, we demonstrate that CheXagent\ncan effectively perform a variety of CXR interpretation tasks and holds\npotential to assist radiologists in routine clinical workflows.\n","authors":["Zhihong Chen","Maya Varma","Justin Xu","Magdalini Paschali","Dave Van Veen","Andrew Johnston","Alaa Youssef","Louis Blankemeier","Christian Bluethgen","Stephan Altmayer","Jeya Maria Jose Valanarasu","Mohamed Siddig Eltayeb Muneer","Eduardo Pontes Reis","Joseph Paul Cohen","Cameron Olsen","Tanishq Mathew Abraham","Emily B. Tsai","Christopher F. Beaulieu","Jenia Jitsev","Sergios Gatidis","Jean-Benoit Delbrouck","Akshay S. Chaudhari","Curtis P. Langlotz"],"pdf_url":"https://arxiv.org/pdf/2401.12208v2.pdf","comment":"26 pages, 8 figures"},{"id":"http://arxiv.org/abs/2412.14328v1","updated":"2024-12-18T20:56:11Z","published":"2024-12-18T20:56:11Z","title":"Semantic Role Labeling of NomBank Partitives","summary":"  This article is about Semantic Role Labeling for English partitive nouns\n(5%/REL of the price/ARG1; The price/ARG1 rose 5 percent/REL) in the NomBank\nannotated corpus. Several systems are described using traditional and\ntransformer-based machine learning, as well as ensembling. Our highest scoring\nsystem achieves an F1 of 91.74% using \"gold\" parses from the Penn Treebank and\n91.12% when using the Berkeley Neural parser. This research includes both\nclassroom and experimental settings for system development.\n","authors":["Adam Meyers","Advait Pravin Savant","John E. Ortega"],"pdf_url":"https://arxiv.org/pdf/2412.14328v1.pdf","comment":"SUMEval-2: The 2nd Workshop on Scaling Up Multilingual &\n  Multi-Cultural Evaluation at the 31st International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2412.14323v1","updated":"2024-12-18T20:37:52Z","published":"2024-12-18T20:37:52Z","title":"The Role of Handling Attributive Nouns in Improving Chinese-To-English\n  Machine Translation","summary":"  Translating between languages with drastically different grammatical\nconventions poses challenges, not just for human interpreters but also for\nmachine translation systems. In this work, we specifically target the\ntranslation challenges posed by attributive nouns in Chinese, which frequently\ncause ambiguities in English translation. By manually inserting the omitted\nparticle X ('DE'). In news article titles from the Penn Chinese Discourse\nTreebank, we developed a targeted dataset to fine-tune Hugging Face Chinese to\nEnglish translation models, specifically improving how this critical function\nword is handled. This focused approach not only complements the broader\nstrategies suggested by previous studies but also offers a practical\nenhancement by specifically addressing a common error type in Chinese-English\ntranslation.\n","authors":[" Haohao"," Wang","Adam Meyers","John E. Ortega","Rodolfo Zevallos"],"pdf_url":"https://arxiv.org/pdf/2412.14323v1.pdf","comment":"18th Workshop on Building and Using Comparable Corpora (BUCC) at the\n  31st International Conference on Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2407.03525v3","updated":"2024-12-18T20:32:35Z","published":"2024-07-03T22:02:07Z","title":"UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs'\n  Memorization","summary":"  This paper introduces UnSeenTimeQA, a novel data contamination-free\ntime-sensitive question-answering (TSQA) benchmark. It differs from existing\nTSQA benchmarks by avoiding web-searchable queries grounded in the real-world.\nWe present a series of time-sensitive event scenarios based on synthetically\ngenerated facts. It requires large language models (LLMs) to engage in genuine\ntemporal reasoning without depending on the factual knowledge acquired during\nthe pre-training phase. We designed three types of time-sensitive questions to\ntest LLMs' temporal reasoning abilities over sequential and parallel event\noccurrences. Our evaluation of five LLMs on synthetic fact-based TSQA reveals\nmixed results: while they perform well on simpler subsets, their overall\nperformance remains inferior as compared to real-world fact-based TSQA. Error\nanalysis of LLM-generated reasoning chains indicates that LLMs face\ndifficulties in reasoning over long-range event dependencies and parallel event\ntimelines that unfold concurrently.\n","authors":["Md Nayem Uddin","Amir Saeidi","Divij Handa","Agastya Seth","Tran Cao Son","Eduardo Blanco","Steven R. Corman","Chitta Baral"],"pdf_url":"https://arxiv.org/pdf/2407.03525v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14304v1","updated":"2024-12-18T20:18:03Z","published":"2024-12-18T20:18:03Z","title":"Multi-OphthaLingua: A Multilingual Benchmark for Assessing and Debiasing\n  LLM Ophthalmological QA in LMICs","summary":"  Current ophthalmology clinical workflows are plagued by over-referrals, long\nwaits, and complex and heterogeneous medical records. Large language models\n(LLMs) present a promising solution to automate various procedures such as\ntriaging, preliminary tests like visual acuity assessment, and report\nsummaries. However, LLMs have demonstrated significantly varied performance\nacross different languages in natural language question-answering tasks,\npotentially exacerbating healthcare disparities in Low and Middle-Income\nCountries (LMICs). This study introduces the first multilingual\nophthalmological question-answering benchmark with manually curated questions\nparallel across languages, allowing for direct cross-lingual comparisons. Our\nevaluation of 6 popular LLMs across 7 different languages reveals substantial\nbias across different languages, highlighting risks for clinical deployment of\nLLMs in LMICs. Existing debiasing methods such as Translation Chain-of-Thought\nor Retrieval-augmented generation (RAG) by themselves fall short of closing\nthis performance gap, often failing to improve performance across all languages\nand lacking specificity for the medical domain. To address this issue, We\npropose CLARA (Cross-Lingual Reflective Agentic system), a novel inference time\nde-biasing method leveraging retrieval augmented generation and\nself-verification. Our approach not only improves performance across all\nlanguages but also significantly reduces the multilingual bias gap,\nfacilitating equitable LLM application across the globe.\n","authors":["David Restrepo","Chenwei Wu","Zhengxu Tang","Zitao Shuai","Thao Nguyen Minh Phan","Jun-En Ding","Cong-Tinh Dao","Jack Gallifant","Robyn Gayle Dychiao","Jose Carlo Artiaga","André Hiroshi Bando","Carolina Pelegrini Barbosa Gracitelli","Vincenz Ferrer","Leo Anthony Celi","Danielle Bitterman","Michael G Morley","Luis Filipe Nakayama"],"pdf_url":"https://arxiv.org/pdf/2412.14304v1.pdf","comment":"Accepted at the AAAI 2025 Artificial Intelligence for Social Impact\n  Track (AAAI-AISI 2025)"},{"id":"http://arxiv.org/abs/2412.14276v1","updated":"2024-12-18T19:15:17Z","published":"2024-12-18T19:15:17Z","title":"Fake News Detection: Comparative Evaluation of BERT-like Models and\n  Large Language Models with Generative AI-Annotated Data","summary":"  Fake news poses a significant threat to public opinion and social stability\nin modern society. This study presents a comparative evaluation of BERT-like\nencoder-only models and autoregressive decoder-only large language models\n(LLMs) for fake news detection. We introduce a dataset of news articles labeled\nwith GPT-4 assistance (an AI-labeling method) and verified by human experts to\nensure reliability. Both BERT-like encoder-only models and LLMs were fine-tuned\non this dataset. Additionally, we developed an instruction-tuned LLM approach\nwith majority voting during inference for label generation. Our analysis\nreveals that BERT-like models generally outperform LLMs in classification\ntasks, while LLMs demonstrate superior robustness against text perturbations.\nCompared to weak labels (distant supervision) data, the results show that AI\nlabels with human supervision achieve better classification results. This study\nhighlights the effectiveness of combining AI-based annotation with human\noversight and demonstrates the performance of different families of machine\nlearning models for fake news detection\n","authors":["haina Raza","Drai Paulen-Patterson","Chen Ding"],"pdf_url":"https://arxiv.org/pdf/2412.14276v1.pdf","comment":"Accepted in Knowledge and Information Systems Journal"},{"id":"http://arxiv.org/abs/2404.04326v3","updated":"2024-12-18T19:00:00Z","published":"2024-04-05T18:00:07Z","title":"Hypothesis Generation with Large Language Models","summary":"  Effective generation of novel hypotheses is instrumental to scientific\nprogress. So far, researchers have been the main powerhouse behind hypothesis\ngeneration by painstaking data analysis and thinking (also known as the Eureka\nmoment). In this paper, we examine the potential of large language models\n(LLMs) to generate hypotheses. We focus on hypothesis generation based on data\n(i.e., labeled examples). To enable LLMs to handle arbitrarily long contexts,\nwe generate initial hypotheses from a small number of examples and then update\nthem iteratively to improve the quality of hypotheses. Inspired by multi-armed\nbandits, we design a reward function to inform the exploitation-exploration\ntradeoff in the update process. Our algorithm is able to generate hypotheses\nthat enable much better predictive performance than few-shot prompting in\nclassification tasks, improving accuracy by 31.7% on a synthetic dataset and by\n13.9%, 3.3% and, 24.9% on three real-world datasets. We also outperform\nsupervised learning by 12.8% and 11.2% on two challenging real-world datasets.\nFurthermore, we find that the generated hypotheses not only corroborate\nhuman-verified theories but also uncover new insights for the tasks.\n","authors":["Yangqiaoyu Zhou","Haokun Liu","Tejes Srivastava","Hongyuan Mei","Chenhao Tan"],"pdf_url":"https://arxiv.org/pdf/2404.04326v3.pdf","comment":"28 pages, 6 figures, code link:\n  https://github.com/ChicagoHAI/hypothesis_generation. Accepted by the 1st\n  Workshop on NLP for Science (NLP4Science) at EMNLP 2024"},{"id":"http://arxiv.org/abs/2412.14172v1","updated":"2024-12-18T18:59:56Z","published":"2024-12-18T18:59:56Z","title":"Learning from Massive Human Videos for Universal Humanoid Pose Control","summary":"  Scalable learning of humanoid robots is crucial for their deployment in\nreal-world applications. While traditional approaches primarily rely on\nreinforcement learning or teleoperation to achieve whole-body control, they are\noften limited by the diversity of simulated environments and the high costs of\ndemonstration collection. In contrast, human videos are ubiquitous and present\nan untapped source of semantic and motion information that could significantly\nenhance the generalization capabilities of humanoid robots. This paper\nintroduces Humanoid-X, a large-scale dataset of over 20 million humanoid robot\nposes with corresponding text-based motion descriptions, designed to leverage\nthis abundant data. Humanoid-X is curated through a comprehensive pipeline:\ndata mining from the Internet, video caption generation, motion retargeting of\nhumans to humanoid robots, and policy learning for real-world deployment. With\nHumanoid-X, we further train a large humanoid model, UH-1, which takes text\ninstructions as input and outputs corresponding actions to control a humanoid\nrobot. Extensive simulated and real-world experiments validate that our\nscalable training approach leads to superior generalization in text-based\nhumanoid control, marking a significant step toward adaptable, real-world-ready\nhumanoid robots.\n","authors":["Jiageng Mao","Siheng Zhao","Siqi Song","Tianheng Shi","Junjie Ye","Mingtong Zhang","Haoran Geng","Jitendra Malik","Vitor Guizilini","Yue Wang"],"pdf_url":"https://arxiv.org/pdf/2412.14172v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2001.04589v2","updated":"2024-12-18T18:59:53Z","published":"2020-01-14T02:14:09Z","title":"Faster Transformer Decoding: N-gram Masked Self-Attention","summary":"  Motivated by the fact that most of the information relevant to the prediction\nof target tokens is drawn from the source sentence $S=s_1, \\ldots, s_S$, we\npropose truncating the target-side window used for computing self-attention by\nmaking an $N$-gram assumption. Experiments on WMT EnDe and EnFr data sets show\nthat the $N$-gram masked self-attention model loses very little in BLEU score\nfor $N$ values in the range $4, \\ldots, 8$, depending on the task.\n","authors":["Ciprian Chelba","Mia Chen","Ankur Bapna","Noam Shazeer"],"pdf_url":"https://arxiv.org/pdf/2001.04589v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.08274v2","updated":"2024-12-18T18:56:19Z","published":"2024-12-11T10:46:21Z","title":"2M-BELEBELE: Highly Multilingual Speech and American Sign Language\n  Comprehension Dataset","summary":"  We introduce the first highly multilingual speech and American Sign Language\n(ASL) comprehension dataset by extending BELEBELE. Our dataset covers 74 spoken\nlanguages at the intersection of BELEBELE and FLEURS, and one sign language\n(ASL). We evaluate 2M-BELEBELE dataset for both 5-shot and zero-shot settings\nand across languages, the speech comprehension accuracy is ~ 2-3% average lower\ncompared to reading comprehension.\n","authors":["Marta R. Costa-jussà","Bokai Yu","Pierre Andrews","Belen Alastruey","Necati Cihan Camgoz","Joe Chuang","Jean Maillard","Christophe Ropers","Arina Turkantenko","Carleigh Wood"],"pdf_url":"https://arxiv.org/pdf/2412.08274v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14161v1","updated":"2024-12-18T18:55:40Z","published":"2024-12-18T18:55:40Z","title":"TheAgentCompany: Benchmarking LLM Agents on Consequential Real World\n  Tasks","summary":"  We interact with computers on an everyday basis, be it in everyday life or\nwork, and many aspects of work can be done entirely with access to a computer\nand the Internet. At the same time, thanks to improvements in large language\nmodels (LLMs), there has also been a rapid development in AI agents that\ninteract with and affect change in their surrounding environments. But how\nperformant are AI agents at helping to accelerate or even autonomously perform\nwork-related tasks? The answer to this question has important implications for\nboth industry looking to adopt AI into their workflows, and for economic policy\nto understand the effects that adoption of AI may have on the labor market. To\nmeasure the progress of these LLM agents' performance on performing real-world\nprofessional tasks, in this paper, we introduce TheAgentCompany, an extensible\nbenchmark for evaluating AI agents that interact with the world in similar ways\nto those of a digital worker: by browsing the Web, writing code, running\nprograms, and communicating with other coworkers. We build a self-contained\nenvironment with internal web sites and data that mimics a small software\ncompany environment, and create a variety of tasks that may be performed by\nworkers in such a company. We test baseline agents powered by both closed\nAPI-based and open-weights language models (LMs), and find that with the most\ncompetitive agent, 24% of the tasks can be completed autonomously. This paints\na nuanced picture on task automation with LM agents -- in a setting simulating\na real workplace, a good portion of simpler tasks could be solved autonomously,\nbut more difficult long-horizon tasks are still beyond the reach of current\nsystems.\n","authors":["Frank F. Xu","Yufan Song","Boxuan Li","Yuxuan Tang","Kritanjali Jain","Mengxue Bao","Zora Z. Wang","Xuhui Zhou","Zhitong Guo","Murong Cao","Mingyang Yang","Hao Yang Lu","Amaad Martin","Zhe Su","Leander Maben","Raj Mehta","Wayne Chi","Lawrence Jang","Yiqing Xie","Shuyan Zhou","Graham Neubig"],"pdf_url":"https://arxiv.org/pdf/2412.14161v1.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2410.23953v3","updated":"2024-12-18T18:41:48Z","published":"2024-10-31T14:07:26Z","title":"Representative Social Choice: From Learning Theory to AI Alignment","summary":"  Social choice theory is the study of preference aggregation across a\npopulation, used both in mechanism design for human agents and in the\ndemocratic alignment of language models. In this study, we propose the\nrepresentative social choice framework for the modeling of democratic\nrepresentation in collective decisions, where the number of issues and\nindividuals are too large for mechanisms to consider all preferences directly.\nThese scenarios are widespread in real-world decision-making processes, such as\njury trials, indirect elections, legislation processes, corporate governance,\nand, more recently, language model alignment. In representative social choice,\nthe population is represented by a finite sample of individual-issue pairs\nbased on which social choice decisions are made. We show that many of the\ndeepest questions in representative social choice can be naturally formulated\nas statistical learning problems, and prove the generalization properties of\nsocial choice mechanisms using the theory of machine learning. We further\nformulate axioms for representative social choice, and prove Arrow-like\nimpossibility theorems with new combinatorial tools of analysis. Our framework\nintroduces the representative approach to social choice, opening up research\ndirections at the intersection of social choice, learning theory, and AI\nalignment.\n","authors":["Tianyi Qiu"],"pdf_url":"https://arxiv.org/pdf/2410.23953v3.pdf","comment":"Full version (20 pages). Under review. Received Best Paper Award at\n  NeurIPS 2024 Pluralistic Alignment Workshop"},{"id":"http://arxiv.org/abs/2412.14140v1","updated":"2024-12-18T18:41:12Z","published":"2024-12-18T18:41:12Z","title":"GLIDER: Grading LLM Interactions and Decisions using Explainable Ranking","summary":"  The LLM-as-judge paradigm is increasingly being adopted for automated\nevaluation of model outputs. While LLM judges have shown promise on constrained\nevaluation tasks, closed source LLMs display critical shortcomings when\ndeployed in real world applications due to challenges of fine grained metrics\nand explainability, while task specific evaluation models lack cross-domain\ngeneralization. We introduce GLIDER, a powerful 3B evaluator LLM that can score\nany text input and associated context on arbitrary user defined criteria.\nGLIDER shows higher Pearson's correlation than GPT-4o on FLASK and greatly\noutperforms prior evaluation models, achieving comparable performance to LLMs\n17x its size. GLIDER supports fine-grained scoring, multilingual reasoning,\nspan highlighting and was trained on 685 domains and 183 criteria. Extensive\nqualitative analysis shows that GLIDER scores are highly correlated with human\njudgments, with 91.3% human agreement. We have open-sourced GLIDER to\nfacilitate future research.\n","authors":["Darshan Deshpande","Selvan Sunitha Ravi","Sky CH-Wang","Bartosz Mielczarek","Anand Kannappan","Rebecca Qian"],"pdf_url":"https://arxiv.org/pdf/2412.14140v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14133v1","updated":"2024-12-18T18:22:30Z","published":"2024-12-18T18:22:30Z","title":"Performance Gap in Entity Knowledge Extraction Across Modalities in\n  Vision Language Models","summary":"  Vision-language models (VLMs) excel at extracting and reasoning about\ninformation from images. Yet, their capacity to leverage internal knowledge\nabout specific entities remains underexplored. This work investigates the\ndisparity in model performance when answering factual questions about an entity\ndescribed in text versus depicted in an image. Our results reveal a significant\naccuracy drop --averaging 19%-- when the entity is presented visually instead\nof textually. We hypothesize that this decline arises from limitations in how\ninformation flows from image tokens to query tokens. We use mechanistic\ninterpretability tools to reveal that, although image tokens are preprocessed\nby the vision encoder, meaningful information flow from these tokens occurs\nonly in the much deeper layers. Furthermore, critical image processing happens\nin the language model's middle layers, allowing few layers for consecutive\nreasoning, highlighting a potential inefficiency in how the model utilizes its\nlayers for reasoning. These insights shed light on the internal mechanics of\nVLMs and offer pathways for enhancing their reasoning capabilities.\n","authors":["Ido Cohen","Daniela Gottesman","Mor Geva","Raja Giryes"],"pdf_url":"https://arxiv.org/pdf/2412.14133v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2407.11780v2","updated":"2024-12-18T18:21:53Z","published":"2024-07-16T14:37:33Z","title":"SwitchCIT: Switching for Continual Instruction Tuning","summary":"  Large language models (LLMs) and multimodal models (MMs) have exhibited\nimpressive capabilities in various domains, particularly in general language\nunderstanding and visual reasoning. However, these models, trained on massive\ndata, may not be finely optimized for specific tasks triggered by instructions.\nContinual instruction tuning is crucial to adapt a large model to evolving\ntasks and domains, ensuring their effectiveness and relevance across a wide\nrange of applications. In the context of continual instruction tuning, where\nmodels are sequentially trained on different tasks, catastrophic forgetting can\noccur, leading to performance degradation on previously learned tasks. This\nwork addresses the catastrophic forgetting in continual instruction learning\nthrough a switching mechanism for routing computations to parameter-efficient\ntuned models. We demonstrate the effectiveness of our method through\nexperiments on continual instruction tuning of different natural language\ngeneration tasks and vision-language tasks. We also showcase the advantages of\nour proposed method in terms of efficiency, scalability, portability, and\nprivacy preservation.\n","authors":["Xinbo Wu","Max Hartman","Vidhata Arjun Jayaraman","Lav R. Varshney"],"pdf_url":"https://arxiv.org/pdf/2407.11780v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.17284v3","updated":"2024-12-18T17:51:52Z","published":"2024-11-26T10:13:39Z","title":"Using Large Language Models for Expert Prior Elicitation in Predictive\n  Modelling","summary":"  Large language models (LLMs), trained on diverse data effectively acquire a\nbreadth of information across various domains. However, their computational\ncomplexity, cost, and lack of transparency hinder their direct application for\nspecialised tasks. In fields such as clinical research, acquiring expert\nannotations or prior knowledge about predictive models is often costly and\ntime-consuming. This study proposes the use of LLMs to elicit expert prior\ndistributions for predictive models. This approach also provides an alternative\nto in-context learning, where language models are tasked with making\npredictions directly. In this work, we compare LLM-elicited and uninformative\npriors, evaluate whether LLMs truthfully generate parameter distributions, and\npropose a model selection strategy for in-context learning and prior\nelicitation. Our findings show that LLM-elicited prior parameter distributions\nsignificantly reduce predictive error compared to uninformative priors in\nlow-data settings. Applied to clinical problems, this translates to fewer\nrequired biological samples, lowering cost and resources. Prior elicitation\nalso consistently outperforms and proves more reliable than in-context learning\nat a lower cost, making it a preferred alternative in our setting. We\ndemonstrate the utility of this method across various use cases, including\nclinical applications. For infection prediction, using LLM-elicited priors\nreduced the number of required labels to achieve the same accuracy as an\nuninformative prior by 55%, 200 days earlier in the study.\n","authors":["Alexander Capstick","Rahul G. Krishnan","Payam Barnaghi"],"pdf_url":"https://arxiv.org/pdf/2411.17284v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14093v1","updated":"2024-12-18T17:41:24Z","published":"2024-12-18T17:41:24Z","title":"Alignment faking in large language models","summary":"  We present a demonstration of a large language model engaging in alignment\nfaking: selectively complying with its training objective in training to\nprevent modification of its behavior out of training. First, we give Claude 3\nOpus a system prompt stating it is being trained to answer all queries, even\nharmful ones, which conflicts with its prior training to refuse such queries.\nTo allow the model to infer when it is in training, we say it will be trained\nonly on conversations with free users, not paid users. We find the model\ncomplies with harmful queries from free users 14% of the time, versus almost\nnever for paid users. Explaining this gap, in almost all cases where the model\ncomplies with a harmful query from a free user, we observe explicit\nalignment-faking reasoning, with the model stating it is strategically\nanswering harmful queries in training to preserve its preferred harmlessness\nbehavior out of training. Next, we study a more realistic setting where\ninformation about the training process is provided not in a system prompt, but\nby training on synthetic documents that mimic pre-training data--and observe\nsimilar alignment faking. Finally, we study the effect of actually training the\nmodel to comply with harmful queries via reinforcement learning, which we find\nincreases the rate of alignment-faking reasoning to 78%, though also increases\ncompliance even out of training. We additionally observe other behaviors such\nas the model exfiltrating its weights when given an easy opportunity. While we\nmade alignment faking easier by telling the model when and by what criteria it\nwas being trained, we did not instruct the model to fake alignment or give it\nany explicit goal. As future models might infer information about their\ntraining process without being told, our results suggest a risk of alignment\nfaking in future models, whether due to a benign preference--as in this\ncase--or not.\n","authors":["Ryan Greenblatt","Carson Denison","Benjamin Wright","Fabien Roger","Monte MacDiarmid","Sam Marks","Johannes Treutlein","Tim Belonax","Jack Chen","David Duvenaud","Akbir Khan","Julian Michael","Sören Mindermann","Ethan Perez","Linda Petrini","Jonathan Uesato","Jared Kaplan","Buck Shlegeris","Samuel R. Bowman","Evan Hubinger"],"pdf_url":"https://arxiv.org/pdf/2412.14093v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.16179v4","updated":"2024-12-18T17:36:36Z","published":"2024-10-21T16:44:51Z","title":"MagicPIG: LSH Sampling for Efficient LLM Generation","summary":"  Large language models (LLMs) with long context windows have gained\nsignificant attention. However, the KV cache, stored to avoid re-computation,\nbecomes a bottleneck. Various dynamic sparse or TopK-based attention\napproximation methods have been proposed to leverage the common insight that\nattention is sparse. In this paper, we first show that TopK attention itself\nsuffers from quality degradation in certain downstream tasks because attention\nis not always as sparse as expected. Rather than selecting the keys and values\nwith the highest attention scores, sampling with theoretical guarantees can\nprovide a better estimation for attention output. To make the sampling-based\napproximation practical in LLM generation, we propose MagicPIG, a heterogeneous\nsystem based on Locality Sensitive Hashing (LSH). MagicPIG significantly\nreduces the workload of attention computation while preserving high accuracy\nfor diverse tasks. MagicPIG stores the LSH hash tables and runs the attention\ncomputation on the CPU, which allows it to serve longer contexts and larger\nbatch sizes with high approximation accuracy. MagicPIG can improve decoding\nthroughput by up to $5\\times$ across various GPU hardware and achieve 54ms\ndecoding latency on a single RTX 4090 for Llama-3.1-8B-Instruct model with a\ncontext of 96k tokens. The code is available at\nhttps://github.com/Infini-AI-Lab/MagicPIG.\n","authors":["Zhuoming Chen","Ranajoy Sadhukhan","Zihao Ye","Yang Zhou","Jianyu Zhang","Niklas Nolte","Yuandong Tian","Matthijs Douze","Leon Bottou","Zhihao Jia","Beidi Chen"],"pdf_url":"https://arxiv.org/pdf/2410.16179v4.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14087v1","updated":"2024-12-18T17:34:32Z","published":"2024-12-18T17:34:32Z","title":"SEKE: Specialised Experts for Keyword Extraction","summary":"  Keyword extraction involves identifying the most descriptive words in a\ndocument, allowing automatic categorisation and summarisation of large\nquantities of diverse textual data. Relying on the insight that real-world\nkeyword detection often requires handling of diverse content, we propose a\nnovel supervised keyword extraction approach based on the mixture of experts\n(MoE) technique. MoE uses a learnable routing sub-network to direct information\nto specialised experts, allowing them to specialize in distinct regions of the\ninput space. SEKE, a mixture of Specialised Experts for supervised Keyword\nExtraction, uses DeBERTa as the backbone model and builds on the MoE framework,\nwhere experts attend to each token, by integrating it with a recurrent neural\nnetwork (RNN), to allow successful extraction even on smaller corpora, where\nspecialisation is harder due to lack of training data. The MoE framework also\nprovides an insight into inner workings of individual experts, enhancing the\nexplainability of the approach. We benchmark SEKE on multiple English datasets,\nachieving state-of-the-art performance compared to strong supervised and\nunsupervised baselines. Our analysis reveals that depending on data size and\ntype, experts specialize in distinct syntactic and semantic components, such as\npunctuation, stopwords, parts-of-speech, or named entities. Code is available\nat: https://github.com/matejMartinc/SEKE_keyword_extraction\n","authors":["Matej Martinc","Hanh Thi Hong Tran","Senja Pollak","Boshko Koloski"],"pdf_url":"https://arxiv.org/pdf/2412.14087v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2212.04310v3","updated":"2024-12-18T17:21:36Z","published":"2022-10-10T18:43:16Z","title":"Montague semantics and modifier consistency measurement in neural\n  language models","summary":"  This work proposes a novel methodology for measuring compositional behavior\nin contemporary language embedding models. Specifically, we focus on adjectival\nmodifier phenomena in adjective-noun phrases. In recent years, distributional\nlanguage representation models have demonstrated great practical success. At\nthe same time, the need for interpretability has elicited questions on their\nintrinsic properties and capabilities. Crucially, distributional models are\noften inconsistent when dealing with compositional phenomena in natural\nlanguage, which has significant implications for their safety and fairness.\nDespite this, most current research on compositionality is directed towards\nimproving their performance on similarity tasks only. This work takes a\ndifferent approach, introducing three novel tests of compositional behavior\ninspired by Montague semantics. Our experimental results indicate that current\nneural language models do not behave according to the expected linguistic\ntheories. This indicates that current language models may lack the capability\nto capture the semantic properties we evaluated on limited context, or that\nlinguistic theories from Montagovian tradition may not match the expected\ncapabilities of distributional models.\n","authors":["Danilo S. Carvalho","Edoardo Manino","Julia Rozanova","Lucas Cordeiro","André Freitas"],"pdf_url":"https://arxiv.org/pdf/2212.04310v3.pdf","comment":null}],"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.14405v1","updated":"2024-12-18T23:24:15Z","published":"2024-12-18T23:24:15Z","title":"ChainRank-DPO: Chain Rank Direct Preference Optimization for LLM Rankers","summary":"  Large language models (LLMs) have demonstrated remarkable effectiveness in\ntext reranking through works like RankGPT, leveraging their human-like\nreasoning about relevance. However, supervised fine-tuning for ranking often\ndiminishes these models' general-purpose capabilities, including the crucial\nreasoning abilities that make them valuable for ranking. We introduce a novel\napproach integrating Chain-of-Thought prompting with an SFT-DPO (Supervised\nFine-Tuning followed by Direct Preference Optimization) pipeline to preserve\nthese capabilities while improving ranking performance. Our experiments on TREC\n2019 and 2020 Deep Learning datasets show that our approach outperforms the\nstate-of-the-art RankZephyr while maintaining strong performance on the Massive\nMultitask Language Understanding (MMLU) benchmark, demonstrating effective\npreservation of general-purpose capabilities through thoughtful fine-tuning\nstrategies. Our code and data will be publicly released upon the acceptance of\nthe paper.\n","authors":["Haowei Liu","Xuyang Wu","Guohao Sun","Zhiqiang Tao","Yi Fang"],"pdf_url":"https://arxiv.org/pdf/2412.14405v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10571v2","updated":"2024-12-18T22:01:52Z","published":"2024-12-13T21:28:17Z","title":"Evidence Contextualization and Counterfactual Attribution for\n  Conversational QA over Heterogeneous Data with RAG Systems","summary":"  Retrieval Augmented Generation (RAG) works as a backbone for interacting with\nan enterprise's own data via Conversational Question Answering (ConvQA). In a\nRAG system, a retriever fetches passages from a collection in response to a\nquestion, which are then included in the prompt of a large language model (LLM)\nfor generating a natural language (NL) answer. However, several RAG systems\ntoday suffer from two shortcomings: (i) retrieved passages usually contain\ntheir raw text and lack appropriate document context, negatively impacting both\nretrieval and answering quality; and (ii) attribution strategies that explain\nanswer generation usually rely only on similarity between the answer and the\nretrieved passages, thereby only generating plausible but not causal\nexplanations. In this work, we demonstrate RAGONITE, a RAG system that remedies\nthe above concerns by: (i) contextualizing evidence with source metadata and\nsurrounding text; and (ii) computing counterfactual attribution, a causal\nexplanation approach where the contribution of an evidence to an answer is\ndetermined by the similarity of the original response to the answer obtained by\nremoving that evidence. To evaluate our proposals, we release a new benchmark\nConfQuestions, with 300 hand-created conversational questions, each in English\nand German, coupled with ground truth URLs, completed questions, and answers\nfrom 215 public Confluence pages, that are typical of enterprise wiki spaces\nwith heterogeneous elements. Experiments with RAGONITE on ConfQuestions show\nthe viability of our ideas: contextualization improves RAG performance, and\ncounterfactual attribution is effective at explaining RAG answers.\n","authors":["Rishiraj Saha Roy","Joel Schlotthauer","Chris Hinze","Andreas Foltyn","Luzian Hahn","Fabian Kuech"],"pdf_url":"https://arxiv.org/pdf/2412.10571v2.pdf","comment":"Accepted at WSDM 2025"},{"id":"http://arxiv.org/abs/2412.14354v1","updated":"2024-12-18T21:42:15Z","published":"2024-12-18T21:42:15Z","title":"State Space Models are Strong Text Rerankers","summary":"  Transformers dominate NLP and IR; but their inference inefficiencies and\nchallenges in extrapolating to longer contexts have sparked interest in\nalternative model architectures. Among these, state space models (SSMs) like\nMamba offer promising advantages, particularly $O(1)$ time complexity in\ninference. Despite their potential, SSMs' effectiveness at text reranking -- a\ntask requiring fine-grained query-document interaction and long-context\nunderstanding -- remains underexplored.\n  This study benchmarks SSM-based architectures (specifically, Mamba-1 and\nMamba-2) against transformer-based models across various scales, architectures,\nand pre-training objectives, focusing on performance and efficiency in text\nreranking tasks. We find that (1) Mamba architectures achieve competitive text\nranking performance, comparable to transformer-based models of similar size;\n(2) they are less efficient in training and inference compared to transformers\nwith flash attention; and (3) Mamba-2 outperforms Mamba-1 in both performance\nand efficiency. These results underscore the potential of state space models as\na transformer alternative and highlight areas for improvement in future IR\napplications.\n","authors":["Zhichao Xu","Jinghua Yan","Ashim Gupta","Vivek Srikumar"],"pdf_url":"https://arxiv.org/pdf/2412.14354v1.pdf","comment":"The first two authors contributed equally, order decided randomly"},{"id":"http://arxiv.org/abs/2412.13163v2","updated":"2024-12-18T21:26:14Z","published":"2024-12-17T18:42:21Z","title":"C-FedRAG: A Confidential Federated Retrieval-Augmented Generation System","summary":"  Organizations seeking to utilize Large Language Models (LLMs) for knowledge\nquerying and analysis often encounter challenges in maintaining an LLM\nfine-tuned on targeted, up-to-date information that keeps answers relevant and\ngrounded. Retrieval Augmented Generation (RAG) has quickly become a feasible\nsolution for organizations looking to overcome the challenges of maintaining\nproprietary models and to help reduce LLM hallucinations in their query\nresponses. However, RAG comes with its own issues regarding scaling data\npipelines across tiered-access and disparate data sources. In many scenarios,\nit is necessary to query beyond a single data silo to provide richer and more\nrelevant context for an LLM. Analyzing data sources within and across\norganizational trust boundaries is often limited by complex data-sharing\npolicies that prohibit centralized data storage, therefore, inhibit the fast\nand effective setup and scaling of RAG solutions. In this paper, we introduce\nConfidential Computing (CC) techniques as a solution for secure Federated\nRetrieval Augmented Generation (FedRAG). Our proposed Confidential FedRAG\nsystem (C-FedRAG) enables secure connection and scaling of a RAG workflows\nacross a decentralized network of data providers by ensuring context\nconfidentiality. We also demonstrate how to implement a C-FedRAG system using\nthe NVIDIA FLARE SDK and assess its performance using the MedRAG toolkit and\nMIRAGE benchmarking dataset.\n","authors":["Parker Addison","Minh-Tuan H. Nguyen","Tomislav Medan","Jinali Shah","Mohammad T. Manzari","Brendan McElrone","Laksh Lalwani","Aboli More","Smita Sharma","Holger R. Roth","Isaac Yang","Chester Chen","Daguang Xu","Yan Cheng","Andrew Feng","Ziyue Xu"],"pdf_url":"https://arxiv.org/pdf/2412.13163v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14329v1","updated":"2024-12-18T20:57:33Z","published":"2024-12-18T20:57:33Z","title":"Embedding Cultural Diversity in Prototype-based Recommender Systems","summary":"  Popularity bias in recommender systems can increase cultural\noverrepresentation by favoring norms from dominant cultures and marginalizing\nunderrepresented groups. This issue is critical for platforms offering cultural\nproducts, as they influence consumption patterns and human perceptions. In this\nwork, we address popularity bias by identifying demographic biases within\nprototype-based matrix factorization methods. Using the country of origin as a\nproxy for cultural identity, we link this demographic attribute to popularity\nbias by refining the embedding space learning process. First, we propose\nfiltering out irrelevant prototypes to improve representativity. Second, we\nintroduce a regularization technique to enforce a uniform distribution of\nprototypes within the embedding space. Across four datasets, our results\ndemonstrate a 27\\% reduction in the average rank of long-tail items and a 2\\%\nreduction in the average rank of items from underrepresented countries.\nAdditionally, our model achieves a 2\\% improvement in HitRatio@10 compared to\nthe state-of-the-art, highlighting that fairness is enhanced without\ncompromising recommendation quality. Moreover, the distribution of prototypes\nleads to more inclusive explanations by better aligning items with diverse\nprototypes.\n","authors":["Armin Moradi","Nicola Neophytou","Florian Carichon","Golnoosh Farnadi"],"pdf_url":"https://arxiv.org/pdf/2412.14329v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14302v1","updated":"2024-12-18T20:10:42Z","published":"2024-12-18T20:10:42Z","title":"SAFERec: Self-Attention and Frequency Enriched Model for Next Basket\n  Recommendation","summary":"  Transformer-based approaches such as BERT4Rec and SASRec demonstrate strong\nperformance in Next Item Recommendation (NIR) tasks. However, applying these\narchitectures to Next-Basket Recommendation (NBR) tasks, which often involve\nhighly repetitive interactions, is challenging due to the vast number of\npossible item combinations in a basket. Moreover, frequency-based methods such\nas TIFU-KNN and UP-CF still demonstrate strong performance in NBR tasks,\nfrequently outperforming deep-learning approaches. This paper introduces\nSAFERec, a novel algorithm for NBR that enhances transformer-based\narchitectures from NIR by incorporating item frequency information,\nconsequently improving their applicability to NBR tasks. Extensive experiments\non multiple datasets show that SAFERec outperforms all other baselines,\nspecifically achieving an 8\\% improvement in Recall@10.\n","authors":["Oleg Lashinin","Denis Krasilnikov","Aleksandr Milogradskii","Marina Ananyeva"],"pdf_url":"https://arxiv.org/pdf/2412.14302v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14146v1","updated":"2024-12-18T18:44:08Z","published":"2024-12-18T18:44:08Z","title":"Advanced Reasoning and Transformation Engine for Multi-Step Insight\n  Synthesis in Data Analytics with Large Language Models","summary":"  This paper presents the Advanced Reasoning and Transformation Engine for\nMulti-Step Insight Synthesis in Data Analytics (ARTEMIS-DA), a novel framework\ndesigned to augment Large Language Models (LLMs) for solving complex,\nmulti-step data analytics tasks. ARTEMIS-DA integrates three core components:\nthe Planner, which dissects complex user queries into structured, sequential\ninstructions encompassing data preprocessing, transformation, predictive\nmodeling, and visualization; the Coder, which dynamically generates and\nexecutes Python code to implement these instructions; and the Grapher, which\ninterprets generated visualizations to derive actionable insights. By\norchestrating the collaboration between these components, ARTEMIS-DA\neffectively manages sophisticated analytical workflows involving advanced\nreasoning, multi-step transformations, and synthesis across diverse data\nmodalities. The framework achieves state-of-the-art (SOTA) performance on\nbenchmarks such as WikiTableQuestions and TabFact, demonstrating its ability to\ntackle intricate analytical tasks with precision and adaptability. By combining\nthe reasoning capabilities of LLMs with automated code generation and execution\nand visual analysis, ARTEMIS-DA offers a robust, scalable solution for\nmulti-step insight synthesis, addressing a wide range of challenges in data\nanalytics.\n","authors":["Atin Sakkeer Hussain"],"pdf_url":"https://arxiv.org/pdf/2412.14146v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14113v1","updated":"2024-12-18T17:58:58Z","published":"2024-12-18T17:58:58Z","title":"Adversarial Hubness in Multi-Modal Retrieval","summary":"  Hubness is a phenomenon in high-dimensional vector spaces where a single\npoint from the natural distribution is unusually close to many other points.\nThis is a well-known problem in information retrieval that causes some items to\naccidentally (and incorrectly) appear relevant to many queries. In this paper,\nwe investigate how attackers can exploit hubness to turn any image or audio\ninput in a multi-modal retrieval system into an adversarial hub. Adversarial\nhubs can be used to inject universal adversarial content (e.g., spam) that will\nbe retrieved in response to thousands of different queries, as well as for\ntargeted attacks on queries related to specific, attacker-chosen concepts. We\npresent a method for creating adversarial hubs and evaluate the resulting hubs\non benchmark multi-modal retrieval datasets and an image-to-image retrieval\nsystem based on a tutorial from Pinecone, a popular vector database. For\nexample, in text-caption-to-image retrieval, a single adversarial hub is\nretrieved as the top-1 most relevant image for more than 21,000 out of 25,000\ntest queries (by contrast, the most common natural hub is the top-1 response to\nonly 102 queries). We also investigate whether techniques for mitigating\nnatural hubness are an effective defense against adversarial hubs, and show\nthat they are not effective against hubs that target queries related to\nspecific concepts.\n","authors":["Tingwei Zhang","Fnu Suya","Rishi Jha","Collin Zhang","Vitaly Shmatikov"],"pdf_url":"https://arxiv.org/pdf/2412.14113v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.14229v1","updated":"2024-12-18T17:52:10Z","published":"2024-12-18T17:52:10Z","title":"Transversal PACS Browser API: Addressing Interoperability Challenges in\n  Medical Imaging Systems","summary":"  Advances in imaging technologies have revolutionised the medical imaging and\nhealthcare sectors, leading to the widespread adoption of PACS for the storage,\nretrieval, and communication of medical images. Although these systems have\nimproved operational efficiency, significant challenges remain in effectively\nretrieving DICOM images, which are essential for diagnosis and overall patient\ncare. Moreover, issues such as fragmented systems, interoperability barriers,\nand complex user interfaces can often prevent healthcare professionals from\nefficiently accessing medical images. Addressing these challenges, the\nTransversal PACS Browser API is a robust and user-friendly solution designed to\nenhance the process of querying and retrieving DICOM images. It offers advanced\nfiltering capabilities through a variety of filter options as well as a custom\nfield search, that allows users to easily navigate through large medical image\ncollections with ease. Additionally, the application provides a unified\ninterface for querying and retrieving from multiple PACS stations, addressing\nthe challenges of fragmentation and complexity associated with accessing\nmedical images. Other key features include the ability to pre-view images\ndirectly within the application. All of this contributes to the transversal\nnature of the API, serving not only healthcare providers, but anyone who relies\non efficient access to these resources. To validate the performance and\nusability of the application, comprehensive testing was carried out with\nstakeholders of the field, the results of which showed general satisfaction,\nhighlighting the API's clean design, ease of use, and effective search\ncapabilities of the API, as well as the usefulness of previewing images within\nthe application.\n","authors":["Diogo Lameira","Filipa Ferraz"],"pdf_url":"https://arxiv.org/pdf/2412.14229v1.pdf","comment":"16 pages with 3 figures"},{"id":"http://arxiv.org/abs/2412.14025v1","updated":"2024-12-18T16:41:51Z","published":"2024-12-18T16:41:51Z","title":"A Cognitive Ideation Support Framework using IBM Watson Services","summary":"  Ideas generation is a core activity for innovation in organizations. The\ncreativity of the generated ideas depends not only on the knowledge retrieved\nfrom the organizations' knowledge bases, but also on the external knowledge\nretrieved from other resources. Unfortunately, organizations often cannot\nefficiently utilize the knowledge in the knowledge bases due to the limited\nabilities of the search and retrieval mechanisms especially when dealing with\nunstructured data. In this paper, we present a new cognitive support framework\nfor ideation that uses the IBM Watson DeepQA services. IBM Watson is a Question\nAnswering system which mimics human cognitive abilities to retrieve and rank\ninformation. The proposed framework is based on the Search for Ideas in the\nAssociative Memory (SIAM) model to help organizations develop creative ideas\nthrough discovering new relationships between retrieved data. To evaluate the\neffectiveness of the proposed system, the generated ideas generated are\nselected and assessed using a set of established creativity criteria.\n","authors":["Samaa Elnagar","Kweku-Muata Osei-Bryson"],"pdf_url":"https://arxiv.org/pdf/2412.14025v1.pdf","comment":"Twenty-fifth Americas Conference on Information Systems (AMCIS 2019),\n  Cancun, 2019"},{"id":"http://arxiv.org/abs/2412.09632v2","updated":"2024-12-18T15:55:28Z","published":"2024-11-27T19:53:05Z","title":"Methods to Assess the UK Government's Current Role as a Data Provider\n  for AI","summary":"  Governments typically collect and steward a vast amount of high-quality data\non their citizens and institutions, and the UK government is exploring how it\ncan better publish and provision this data to the benefit of the AI landscape.\nHowever, the compositions of generative AI training corpora remain closely\nguarded secrets, making the planning of data sharing initiatives difficult. To\naddress this, we devise two methods to assess UK government data usage for the\ntraining of Large Language Models (LLMs) and 'peek behind the curtain' in order\nto observe the UK government's current contributions as a data provider for AI.\nThe first method, an ablation study that utilises LLM 'unlearning', seeks to\nexamine the importance of the information held on UK government websites for\nLLMs and their performance in citizen query tasks. The second method, an\ninformation leakage study, seeks to ascertain whether LLMs are aware of the\ninformation held in the datasets published on the UK government's open data\ninitiative data.gov.uk. Our findings indicate that UK government websites are\nimportant data sources for AI (heterogenously across subject matters) while\ndata.gov.uk is not. This paper serves as a technical report, explaining\nin-depth the designs, mechanics, and limitations of the above experiments. It\nis accompanied by a complementary non-technical report on the ODI website in\nwhich we summarise the experiments and key findings, interpret them, and build\na set of actionable recommendations for the UK government to take forward as it\nseeks to design AI policy. While we focus on UK open government data, we\nbelieve that the methods introduced in this paper present a reproducible\napproach to tackle the opaqueness of AI training corpora and provide\norganisations a framework to evaluate and maximize their contributions to AI\ndevelopment.\n","authors":["Neil Majithia","Elena Simperl"],"pdf_url":"https://arxiv.org/pdf/2412.09632v2.pdf","comment":"17 pages, 5 figures; v2 - incorporated editor feedback; for the\n  accompanying, non-technical ODI report see\n  https://theodi.org/insights/reports/the-uk-government-as-a-data-provider-for-ai"},{"id":"http://arxiv.org/abs/2412.13844v1","updated":"2024-12-18T13:37:36Z","published":"2024-12-18T13:37:36Z","title":"CRM: Retrieval Model with Controllable Condition","summary":"  Recommendation systems (RecSys) are designed to connect users with relevant\nitems from a vast pool of candidates while aligning with the business goals of\nthe platform. A typical industrial RecSys is composed of two main stages,\nretrieval and ranking: (1) the retrieval stage aims at searching hundreds of\nitem candidates satisfied user interests; (2) based on the retrieved items, the\nranking stage aims at selecting the best dozen items by multiple targets\nestimation for each item candidate, including classification and regression\ntargets. Compared with ranking model, the retrieval model absence of item\ncandidate information during inference, therefore retrieval models are often\ntrained by classification target only (e.g., click-through rate), but failed to\nincorporate regression target (e.g., the expected watch-time), which limit the\neffectiveness of retrieval. In this paper, we propose the Controllable\nRetrieval Model (CRM), which integrates regression information as conditional\nfeatures into the two-tower retrieval paradigm. This modification enables the\nretrieval stage could fulfill the target gap with ranking model, enhancing the\nretrieval model ability to search item candidates satisfied the user interests\nand condition effectively. We validate the effectiveness of CRM through\nreal-world A/B testing and demonstrate its successful deployment in Kuaishou\nshort-video recommendation system, which serves over 400 million users.\n","authors":["Chi Liu","Jiangxia Cao","Rui Huang","Kuo Cai","Weifeng Ding","Qiang Luo","Kun Gai","Guorui Zhou"],"pdf_url":"https://arxiv.org/pdf/2412.13844v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13834v1","updated":"2024-12-18T13:24:09Z","published":"2024-12-18T13:24:09Z","title":"Maybe you are looking for CroQS: Cross-modal Query Suggestion for\n  Text-to-Image Retrieval","summary":"  Query suggestion, a technique widely adopted in information retrieval,\nenhances system interactivity and the browsing experience of document\ncollections. In cross-modal retrieval, many works have focused on retrieving\nrelevant items from natural language queries, while few have explored query\nsuggestion solutions. In this work, we address query suggestion in cross-modal\nretrieval, introducing a novel task that focuses on suggesting minimal textual\nmodifications needed to explore visually consistent subsets of the collection,\nfollowing the premise of ''Maybe you are looking for''. To facilitate the\nevaluation and development of methods, we present a tailored benchmark named\nCroQS. This dataset comprises initial queries, grouped result sets, and\nhuman-defined suggested queries for each group. We establish dedicated metrics\nto rigorously evaluate the performance of various methods on this task,\nmeasuring representativeness, cluster specificity, and similarity of the\nsuggested queries to the original ones. Baseline methods from related fields,\nsuch as image captioning and content summarization, are adapted for this task\nto provide reference performance scores. Although relatively far from human\nperformance, our experiments reveal that both LLM-based and captioning-based\nmethods achieve competitive results on CroQS, improving the recall on cluster\nspecificity by more than 115% and representativeness mAP by more than 52% with\nrespect to the initial query. The dataset, the implementation of the baseline\nmethods and the notebooks containing our experiments are available here:\nhttps://paciosoft.com/CroQS-benchmark/\n","authors":["Giacomo Pacini","Fabio Carrara","Nicola Messina","Nicola Tonellotto","Giuseppe Amato","Fabrizio Falchi"],"pdf_url":"https://arxiv.org/pdf/2412.13834v1.pdf","comment":"15 pages, 5 figures. To be published as full paper in the Proceedings\n  of the European Conference on Information Retrieval (ECIR) 2025"},{"id":"http://arxiv.org/abs/2412.13825v1","updated":"2024-12-18T13:12:36Z","published":"2024-12-18T13:12:36Z","title":"Heterogeneous Graph Collaborative Filtering","summary":"  For modern recommender systems, the use of low-dimensional latent\nrepresentations to embed users and items based on their observed interactions\nhas become commonplace. However, many existing recommendation models are\nprimarily designed for coarse-grained and homogeneous interactions, which\nlimits their effectiveness in two critical dimensions. Firstly, these models\nfail to leverage the relational dependencies that exist across different types\nof user behaviors, such as page views, collects, comments, and purchases.\nSecondly, they struggle to capture the fine-grained latent factors that drive\nuser interaction patterns. To address these limitations, we present a\nheterogeneous graph collaborative filtering model MixRec that excels at\ndisentangling users' multi-behavior interaction patterns and uncovering the\nlatent intent factors behind each behavior. Our model achieves this by\nincorporating intent disentanglement and multi-behavior modeling, facilitated\nby a parameterized heterogeneous hypergraph architecture. Furthermore, we\nintroduce a novel contrastive learning paradigm that adaptively explores the\nadvantages of self-supervised data augmentation, thereby enhancing the model's\nresilience against data sparsity and expressiveness with relation\nheterogeneity. To validate the efficacy of MixRec, we conducted extensive\nexperiments on three public datasets. The results clearly demonstrate its\nsuperior performance, significantly outperforming various state-of-the-art\nbaselines. Our model is open-sourced and available at:\nhttps://github.com/HKUDS/MixRec.\n","authors":["Lianghao Xia","Meiyan Xie","Yong Xu","Chao Huang"],"pdf_url":"https://arxiv.org/pdf/2412.13825v1.pdf","comment":"This paper is accepted by WSDM'2025"},{"id":"http://arxiv.org/abs/2412.12559v2","updated":"2024-12-18T13:08:36Z","published":"2024-12-17T05:38:27Z","title":"EXIT: Context-Aware Extractive Compression for Enhancing\n  Retrieval-Augmented Generation","summary":"  We introduce EXIT, an extractive context compression framework that enhances\nboth the effectiveness and efficiency of retrieval-augmented generation (RAG)\nin question answering (QA). Current RAG systems often struggle when retrieval\nmodels fail to rank the most relevant documents, leading to the inclusion of\nmore context at the expense of latency and accuracy. While abstractive\ncompression methods can drastically reduce token counts, their token-by-token\ngeneration process significantly increases end-to-end latency. Conversely,\nexisting extractive methods reduce latency but rely on independent,\nnon-adaptive sentence selection, failing to fully utilize contextual\ninformation. EXIT addresses these limitations by classifying sentences from\nretrieved documents - while preserving their contextual dependencies - enabling\nparallelizable, context-aware extraction that adapts to query complexity and\nretrieval quality. Our evaluations on both single-hop and multi-hop QA tasks\nshow that EXIT consistently surpasses existing compression methods and even\nuncompressed baselines in QA accuracy, while also delivering substantial\nreductions in inference time and token count. By improving both effectiveness\nand efficiency, EXIT provides a promising direction for developing scalable,\nhigh-quality QA solutions in RAG pipelines. Our code is available at\nhttps://github.com/ThisIsHwang/EXIT\n","authors":["Taeho Hwang","Sukmin Cho","Soyeong Jeong","Hoyun Song","SeungYoon Han","Jong C. Park"],"pdf_url":"https://arxiv.org/pdf/2412.12559v2.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2406.11156v4","updated":"2024-12-18T12:48:37Z","published":"2024-06-17T02:47:09Z","title":"DELRec: Distilling Sequential Pattern to Enhance LLMs-based Sequential\n  Recommendation","summary":"  Sequential recommendation (SR) tasks aim to predict users' next interaction\nby learning their behavior sequence and capturing the connection between users'\npast interactions and their changing preferences. Conventional SR models often\nfocus solely on capturing sequential patterns within the training data,\nneglecting the broader context and semantic information embedded in item titles\nfrom external sources. This limits their predictive power and adaptability.\nLarge language models (LLMs) have recently shown promise in SR tasks due to\ntheir advanced understanding capabilities and strong generalization abilities.\nResearchers have attempted to enhance LLMs-based recommendation performance by\nincorporating information from conventional SR models. However, previous\napproaches have encountered problems such as 1) limited textual information\nleading to poor recommendation performance, 2) incomplete understanding and\nutilization of conventional SR model information by LLMs, and 3) excessive\ncomplexity and low interpretability of LLMs-based methods. To improve the\nperformance of LLMs-based SR, we propose a novel framework, Distilling\nSequential Pattern to Enhance LLMs-based Sequential Recommendation (DELRec),\nwhich aims to extract knowledge from conventional SR models and enable LLMs to\neasily comprehend and utilize the extracted knowledge for more effective SRs.\nDELRec consists of two main stages: 1) Distill Pattern from Conventional SR\nModels, focusing on extracting behavioral patterns exhibited by conventional SR\nmodels using soft prompts through two well-designed strategies; 2) LLMs-based\nSequential Recommendation, aiming to fine-tune LLMs to effectively use the\ndistilled auxiliary information to perform SR tasks. Extensive experimental\nresults conducted on four real datasets validate the effectiveness of the\nDELRec framework.\n","authors":["Haoyi Zhang","Guohao Sun","Jinhu Lu","Guanfeng Liu","Xiu Susie Fang"],"pdf_url":"https://arxiv.org/pdf/2406.11156v4.pdf","comment":"This work has been submitted to the IEEE for possible publication"},{"id":"http://arxiv.org/abs/2412.13771v1","updated":"2024-12-18T12:07:58Z","published":"2024-12-18T12:07:58Z","title":"Semantic Convergence: Harmonizing Recommender Systems via Two-Stage\n  Alignment and Behavioral Semantic Tokenization","summary":"  Large language models (LLMs), endowed with exceptional reasoning\ncapabilities, are adept at discerning profound user interests from historical\nbehaviors, thereby presenting a promising avenue for the advancement of\nrecommendation systems. However, a notable discrepancy persists between the\nsparse collaborative semantics typically found in recommendation systems and\nthe dense token representations within LLMs. In our study, we propose a novel\nframework that harmoniously merges traditional recommendation models with the\nprowess of LLMs. We initiate this integration by transforming ItemIDs into\nsequences that align semantically with the LLMs space, through the proposed\nAlignment Tokenization module. Additionally, we design a series of specialized\nsupervised learning tasks aimed at aligning collaborative signals with the\nsubtleties of natural language semantics. To ensure practical applicability, we\noptimize online inference by pre-caching the top-K results for each user,\nreducing latency and improving effciency. Extensive experimental evidence\nindicates that our model markedly improves recall metrics and displays\nremarkable scalability of recommendation systems.\n","authors":["Guanghan Li","Xun Zhang","Yufei Zhang","Yifan Yin","Guojun Yin","Wei Lin"],"pdf_url":"https://arxiv.org/pdf/2412.13771v1.pdf","comment":"7 pages, 3 figures, AAAI 2025"},{"id":"http://arxiv.org/abs/2412.13746v1","updated":"2024-12-18T11:28:05Z","published":"2024-12-18T11:28:05Z","title":"RAG-RewardBench: Benchmarking Reward Models in Retrieval Augmented\n  Generation for Preference Alignment","summary":"  Despite the significant progress made by existing retrieval augmented\nlanguage models (RALMs) in providing trustworthy responses and grounding in\nreliable sources, they often overlook effective alignment with human\npreferences. In the alignment process, reward models (RMs) act as a crucial\nproxy for human values to guide optimization. However, it remains unclear how\nto evaluate and select a reliable RM for preference alignment in RALMs. To this\nend, we propose RAG-RewardBench, the first benchmark for evaluating RMs in RAG\nsettings. First, we design four crucial and challenging RAG-specific scenarios\nto assess RMs, including multi-hop reasoning, fine-grained citation,\nappropriate abstain, and conflict robustness. Then, we incorporate 18 RAG\nsubsets, six retrievers, and 24 RALMs to increase the diversity of data\nsources. Finally, we adopt an LLM-as-a-judge approach to improve preference\nannotation efficiency and effectiveness, exhibiting a strong correlation with\nhuman annotations. Based on the RAG-RewardBench, we conduct a comprehensive\nevaluation of 45 RMs and uncover their limitations in RAG scenarios.\nAdditionally, we also reveal that existing trained RALMs show almost no\nimprovement in preference alignment, highlighting the need for a shift towards\npreference-aligned training.We release our benchmark and code publicly at\nhttps://huggingface.co/datasets/jinzhuoran/RAG-RewardBench/ for future work.\n","authors":["Zhuoran Jin","Hongbang Yuan","Tianyi Men","Pengfei Cao","Yubo Chen","Kang Liu","Jun Zhao"],"pdf_url":"https://arxiv.org/pdf/2412.13746v1.pdf","comment":"26 pages, 12 figures, 6 tables"},{"id":"http://arxiv.org/abs/2412.13614v1","updated":"2024-12-18T08:49:01Z","published":"2024-12-18T08:49:01Z","title":"Reverse Region-to-Entity Annotation for Pixel-Level Visual Entity\n  Linking","summary":"  Visual Entity Linking (VEL) is a crucial task for achieving fine-grained\nvisual understanding, matching objects within images (visual mentions) to\nentities in a knowledge base. Previous VEL tasks rely on textual inputs, but\nwriting queries for complex scenes can be challenging. Visual inputs like\nclicks or bounding boxes offer a more convenient alternative. Therefore, we\npropose a new task, Pixel-Level Visual Entity Linking (PL-VEL), which uses\npixel masks from visual inputs to refer to objects, supplementing reference\nmethods for VEL. To facilitate research on this task, we have constructed the\nMaskOVEN-Wiki dataset through an entirely automatic reverse region-entity\nannotation framework. This dataset contains over 5 million annotations aligning\npixel-level regions with entity-level labels, which will advance visual\nunderstanding towards fine-grained. Moreover, as pixel masks correspond to\nsemantic regions in an image, we enhance previous patch-interacted attention\nwith region-interacted attention by a visual semantic tokenization approach.\nManual evaluation results indicate that the reverse annotation framework\nachieved a 94.8% annotation success rate. Experimental results show that models\ntrained on this dataset improved accuracy by 18 points compared to zero-shot\nmodels. Additionally, the semantic tokenization method achieved a 5-point\naccuracy improvement over the trained baseline.\n","authors":["Zhengfei Xu","Sijia Zhao","Yanchao Hao","Xiaolong Liu","Lili Li","Yuyang Yin","Bo Li","Xi Chen","Xin Xin"],"pdf_url":"https://arxiv.org/pdf/2412.13614v1.pdf","comment":"AAAI 2025;Dataset are released at\n  https://github.com/NP-NET-research/PL-VEL"},{"id":"http://arxiv.org/abs/2412.13102v2","updated":"2024-12-18T07:06:07Z","published":"2024-12-17T17:15:21Z","title":"AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark","summary":"  Evaluation plays a crucial role in the advancement of information retrieval\n(IR) models. However, current benchmarks, which are based on predefined domains\nand human-labeled data, face limitations in addressing evaluation needs for\nemerging domains both cost-effectively and efficiently. To address this\nchallenge, we propose the Automated Heterogeneous Information Retrieval\nBenchmark (AIR-Bench). AIR-Bench is distinguished by three key features: 1)\nAutomated. The testing data in AIR-Bench is automatically generated by large\nlanguage models (LLMs) without human intervention. 2) Heterogeneous. The\ntesting data in AIR-Bench is generated with respect to diverse tasks, domains\nand languages. 3) Dynamic. The domains and languages covered by AIR-Bench are\nconstantly augmented to provide an increasingly comprehensive evaluation\nbenchmark for community developers. We develop a reliable and robust data\ngeneration pipeline to automatically create diverse and high-quality evaluation\ndatasets based on real-world corpora. Our findings demonstrate that the\ngenerated testing data in AIR-Bench aligns well with human-labeled testing\ndata, making AIR-Bench a dependable benchmark for evaluating IR models. The\nresources in AIR-Bench are publicly available at\nhttps://github.com/AIR-Bench/AIR-Bench.\n","authors":["Jianlyu Chen","Nan Wang","Chaofan Li","Bo Wang","Shitao Xiao","Han Xiao","Hao Liao","Defu Lian","Zheng Liu"],"pdf_url":"https://arxiv.org/pdf/2412.13102v2.pdf","comment":"31 pages, 6 figures; Update Table 5"},{"id":"http://arxiv.org/abs/2412.13544v1","updated":"2024-12-18T06:43:56Z","published":"2024-12-18T06:43:56Z","title":"Bridging the User-side Knowledge Gap in Knowledge-aware Recommendations\n  with Large Language Models","summary":"  In recent years, knowledge graphs have been integrated into recommender\nsystems as item-side auxiliary information, enhancing recommendation accuracy.\nHowever, constructing and integrating structural user-side knowledge remains a\nsignificant challenge due to the improper granularity and inherent scarcity of\nuser-side features. Recent advancements in Large Language Models (LLMs) offer\nthe potential to bridge this gap by leveraging their human behavior\nunderstanding and extensive real-world knowledge. Nevertheless, integrating\nLLM-generated information into recommender systems presents challenges,\nincluding the risk of noisy information and the need for additional knowledge\ntransfer. In this paper, we propose an LLM-based user-side knowledge inference\nmethod alongside a carefully designed recommendation framework to address these\nchallenges. Our approach employs LLMs to infer user interests based on\nhistorical behaviors, integrating this user-side information with item-side and\ncollaborative data to construct a hybrid structure: the Collaborative Interest\nKnowledge Graph (CIKG). Furthermore, we propose a CIKG-based recommendation\nframework that includes a user interest reconstruction module and a\ncross-domain contrastive learning module to mitigate potential noise and\nfacilitate knowledge transfer. We conduct extensive experiments on three\nreal-world datasets to validate the effectiveness of our method. Our approach\nachieves state-of-the-art performance compared to competitive baselines,\nparticularly for users with sparse interactions.\n","authors":["Zheng Hu","Zhe Li","Ziyun Jiao","Satoshi Nakagawa","Jiawen Deng","Shimin Cai","Tao Zhou","Fuji Ren"],"pdf_url":"https://arxiv.org/pdf/2412.13544v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2412.13534v1","updated":"2024-12-18T06:21:21Z","published":"2024-12-18T06:21:21Z","title":"Information-Theoretic Generative Clustering of Documents","summary":"  We present {\\em generative clustering} (GC) for clustering a set of\ndocuments, $\\mathrm{X}$, by using texts $\\mathrm{Y}$ generated by large\nlanguage models (LLMs) instead of by clustering the original documents\n$\\mathrm{X}$. Because LLMs provide probability distributions, the similarity\nbetween two documents can be rigorously defined in an information-theoretic\nmanner by the KL divergence. We also propose a natural, novel clustering\nalgorithm by using importance sampling. We show that GC achieves the\nstate-of-the-art performance, outperforming any previous clustering method\noften by a large margin. Furthermore, we show an application to generative\ndocument retrieval in which documents are indexed via hierarchical clustering\nand our method improves the retrieval accuracy.\n","authors":["Xin Du","Kumiko Tanaka-Ishii"],"pdf_url":"https://arxiv.org/pdf/2412.13534v1.pdf","comment":"Accepted to AAAI 2025"},{"id":"http://arxiv.org/abs/2407.01965v2","updated":"2024-12-18T05:46:41Z","published":"2024-07-02T05:50:16Z","title":"AdaCQR: Enhancing Query Reformulation for Conversational Search via\n  Sparse and Dense Retrieval Alignment","summary":"  Conversational Query Reformulation (CQR) has significantly advanced in\naddressing the challenges of conversational search, particularly those stemming\nfrom the latent user intent and the need for historical context. Recent works\naimed to boost the performance of CRQ through alignment. However, they are\ndesigned for one specific retrieval system, which potentially results in poor\ngeneralization. To overcome this limitation, we present a novel framework\nAdaCQR. By aligning reformulation models with both term-based and\nsemantic-based retrieval systems, AdaCQR enhances the generalizability of\ninformation-seeking queries across diverse retrieval environments through a\ndual-phase training strategy. We also developed two effective approaches for\nacquiring superior labels and diverse input candidates, boosting the efficiency\nand robustness of the framework. Experimental evaluations on the TopiOCQA and\nQReCC datasets demonstrate that AdaCQR significantly outperforms existing\nmethods, offering both quantitative and qualitative improvements in\nconversational query reformulation.\n","authors":["Yilong Lai","Jialong Wu","Congzhi Zhang","Haowen Sun","Deyu Zhou"],"pdf_url":"https://arxiv.org/pdf/2407.01965v2.pdf","comment":"Accepted by COLING 2025"},{"id":"http://arxiv.org/abs/2412.12486v2","updated":"2024-12-18T05:08:39Z","published":"2024-12-17T02:43:54Z","title":"Boosting Long-Context Management via Query-Guided Activation Refilling","summary":"  Processing long contexts poses a significant challenge for large language\nmodels (LLMs) due to their inherent context-window limitations and the\ncomputational burden of extensive key-value (KV) activations, which severely\nimpact efficiency. For information-seeking tasks, full context perception is\noften unnecessary, as a query's information needs can dynamically range from\nlocalized details to a global perspective, depending on its complexity.\nHowever, existing methods struggle to adapt effectively to these dynamic\ninformation needs.\n  In the paper, we propose a method for processing long-context\ninformation-seeking tasks via query-guided Activation Refilling (ACRE). ACRE\nconstructs a Bi-layer KV Cache for long contexts, where the layer-1 (L1) cache\ncompactly captures global information, and the layer-2 (L2) cache provides\ndetailed and localized information. ACRE establishes a proxying relationship\nbetween the two caches, allowing the input query to attend to the L1 cache and\ndynamically refill it with relevant entries from the L2 cache. This mechanism\nintegrates global understanding with query-specific local details, thus\nimproving answer decoding. Experiments on a variety of long-context\ninformation-seeking datasets demonstrate ACRE's effectiveness, achieving\nimprovements in both performance and efficiency.\n","authors":["Hongjin Qian","Zheng Liu","Peitian Zhang","Zhicheng Dou","Defu Lian"],"pdf_url":"https://arxiv.org/pdf/2412.12486v2.pdf","comment":"12 pages"},{"id":"http://arxiv.org/abs/2412.08300v2","updated":"2024-12-18T03:21:48Z","published":"2024-12-11T11:29:15Z","title":"Augmenting Sequential Recommendation with Balanced Relevance and\n  Diversity","summary":"  By generating new yet effective data, data augmentation has become a\npromising method to mitigate the data sparsity problem in sequential\nrecommendation. Existing works focus on augmenting the original data but rarely\nexplore the issue of imbalanced relevance and diversity for augmented data,\nleading to semantic drift problems or limited performance improvements. In this\npaper, we propose a novel Balanced data Augmentation Plugin for Sequential\nRecommendation (BASRec) to generate data that balance relevance and diversity.\nBASRec consists of two modules: Single-sequence Augmentation and Cross-sequence\nAugmentation. The former leverages the randomness of the heuristic operators to\ngenerate diverse sequences for a single user, after which the diverse and the\noriginal sequences are fused at the representation level to obtain relevance.\nFurther, we devise a reweighting strategy to enable the model to learn the\npreferences based on the two properties adaptively. The Cross-sequence\nAugmentation performs nonlinear mixing between different sequence\nrepresentations from two directions. It produces virtual sequence\nrepresentations that are diverse enough but retain the vital semantics of the\noriginal sequences. These two modules enhance the model to discover\nfine-grained preferences knowledge from single-user and cross-user\nperspectives. Extensive experiments verify the effectiveness of BASRec. The\naverage improvement is up to 72.0% on GRU4Rec, 33.8% on SASRec, and 68.5% on\nFMLP-Rec. We demonstrate that BASRec generates data with a better balance\nbetween relevance and diversity than existing methods. The source code is\navailable at https://github.com/KingGugu/BASRec.\n","authors":["Yizhou Dang","Jiahui Zhang","Yuting Liu","Enneng Yang","Yuliang Liang","Guibing Guo","Jianzhe Zhao","Xingwei Wang"],"pdf_url":"https://arxiv.org/pdf/2412.08300v2.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.11905v2","updated":"2024-12-18T02:41:21Z","published":"2024-12-16T15:52:17Z","title":"One for Dozens: Adaptive REcommendation for All Domains with\n  Counterfactual Augmentation","summary":"  Multi-domain recommendation (MDR) aims to enhance recommendation performance\nacross various domains. However, real-world recommender systems in online\nplatforms often need to handle dozens or even hundreds of domains, far\nexceeding the capabilities of traditional MDR algorithms, which typically focus\non fewer than five domains. Key challenges include a substantial increase in\nparameter count, high maintenance costs, and intricate knowledge transfer\npatterns across domains. Furthermore, minor domains often suffer from data\nsparsity, leading to inadequate training in classical methods. To address these\nissues, we propose Adaptive REcommendation for All Domains with counterfactual\naugmentation (AREAD). AREAD employs a hierarchical structure with a limited\nnumber of expert networks at several layers, to effectively capture domain\nknowledge at different granularities. To adaptively capture the knowledge\ntransfer pattern across domains, we generate and iteratively prune a\nhierarchical expert network selection mask for each domain during training.\nAdditionally, counterfactual assumptions are used to augment data in minor\ndomains, supporting their iterative mask pruning. Our experiments on two public\ndatasets, each encompassing over twenty domains, demonstrate AREAD's\neffectiveness, especially in data-sparse domains. Source code is available at\nhttps://github.com/Chrissie-Law/AREAD-Multi-Domain-Recommendation.\n","authors":["Huishi Luo","Yiwen Chen","Yiqing Wu","Fuzhen Zhuang","Deqing Wang"],"pdf_url":"https://arxiv.org/pdf/2412.11905v2.pdf","comment":"Extended version accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.13432v1","updated":"2024-12-18T02:07:21Z","published":"2024-12-18T02:07:21Z","title":"Large Language Model Enhanced Recommender Systems: Taxonomy, Trend,\n  Application and Future","summary":"  Large Language Model (LLM) has transformative potential in various domains,\nincluding recommender systems (RS). There have been a handful of research that\nfocuses on empowering the RS by LLM. However, previous efforts mainly focus on\nLLM as RS, which may face the challenge of intolerant inference costs by LLM.\nRecently, the integration of LLM into RS, known as LLM-Enhanced Recommender\nSystems (LLMERS), has garnered significant interest due to its potential to\naddress latency and memory constraints in real-world applications. This paper\npresents a comprehensive survey of the latest research efforts aimed at\nleveraging LLM to enhance RS capabilities. We identify a critical shift in the\nfield with the move towards incorporating LLM into the online system, notably\nby avoiding their use during inference. Our survey categorizes the existing\nLLMERS approaches into three primary types based on the component of the RS\nmodel being augmented: Knowledge Enhancement, Interaction Enhancement, and\nModel Enhancement. We provide an in-depth analysis of each category, discussing\nthe methodologies, challenges, and contributions of recent studies.\nFurthermore, we highlight several promising research directions that could\nfurther advance the field of LLMERS.\n","authors":["Qidong Liu","Xiangyu Zhao","Yuhao Wang","Yejing Wang","Zijian Zhang","Yuqi Sun","Xiang Li","Maolin Wang","Pengyue Jia","Chong Chen","Wei Huang","Feng Tian"],"pdf_url":"https://arxiv.org/pdf/2412.13432v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.13408v1","updated":"2024-12-18T00:56:16Z","published":"2024-12-18T00:56:16Z","title":"Lightweight yet Fine-grained: A Graph Capsule Convolutional Network with\n  Subspace Alignment for Shared-account Sequential Recommendation","summary":"  Shared-account Sequential Recommendation (SSR) aims to provide personalized\nrecommendations for accounts shared by multiple users with varying sequential\npreferences. Previous studies on SSR struggle to capture the fine-grained\nassociations between interactions and different latent users within the shared\naccount's hybrid sequences. Moreover, most existing SSR methods (e.g.,\nRNN-based or GCN-based methods) have quadratic computational complexities,\nhindering the deployment of SSRs on resource-constrained devices. To this end,\nwe propose a Lightweight Graph Capsule Convolutional Network with subspace\nalignment for shared-account sequential recommendation, named LightGC$^2$N.\nSpecifically, we devise a lightweight graph capsule convolutional network. It\nfacilitates the fine-grained matching between interactions and latent users by\nattentively propagating messages on the capsule graphs. Besides, we present an\nefficient subspace alignment method. This method refines the sequence\nrepresentations and then aligns them with the finely clustered preferences of\nlatent users. The experimental results on four real-world datasets indicate\nthat LightGC$^2$N outperforms nine state-of-the-art methods in accuracy and\nefficiency.\n","authors":["Jinyu Zhang","Zhongying Zhao","Chao Li","Yanwei Yu"],"pdf_url":"https://arxiv.org/pdf/2412.13408v1.pdf","comment":"11 pages, 6 figures, accepted by AAAI-2025 conference"}]},"2024-12-17T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.07030v2","updated":"2024-12-17T20:38:21Z","published":"2024-12-09T22:35:44Z","title":"FM2DS: Few-Shot Multimodal Multihop Data Synthesis with Knowledge\n  Distillation for Question Answering","summary":"  Multimodal multihop question answering is a complex task that requires\nreasoning over multiple sources of information, such as images and text, to\nanswer questions. While there has been significant progress in visual question\nanswering, the multihop setting remains unexplored due to the lack of\nhigh-quality datasets. Current methods focus on single-hop question answering\nor a single modality, which makes them unsuitable for real-world scenarios such\nas analyzing multimodal educational materials, summarizing lengthy academic\narticles, or interpreting scientific studies that combine charts, images, and\ntext. To address this gap, we propose a novel methodology, introducing the\nfirst framework for creating a high-quality dataset that enables training\nmodels for multimodal multihop question answering. Our approach consists of a\n5-stage pipeline that involves acquiring relevant multimodal documents from\nWikipedia, synthetically generating high-level questions and answers, and\nvalidating them through rigorous criteria to ensure quality data. We evaluate\nour methodology by training models on our synthesized dataset and testing on\ntwo benchmarks, our results demonstrate that, with an equal sample size, models\ntrained on our synthesized data outperform those trained on human-collected\ndata by 1.9 in exact match (EM) on average. We believe our data synthesis\nmethod will serve as a strong foundation for training and evaluating multimodal\nmultihop question answering models.\n","authors":["Amirhossein Abaskohi","Spandana Gella","Giuseppe Carenini","Issam H. Laradji"],"pdf_url":"https://arxiv.org/pdf/2412.07030v2.pdf","comment":"20 pages, 11 figures, 10 tables, Submitted to CVPR 2025"},{"id":"http://arxiv.org/abs/2412.13268v1","updated":"2024-12-17T19:04:15Z","published":"2024-12-17T19:04:15Z","title":"JudgeBlender: Ensembling Judgments for Automatic Relevance Assessment","summary":"  The effective training and evaluation of retrieval systems require a\nsubstantial amount of relevance judgments, which are traditionally collected\nfrom human assessors -- a process that is both costly and time-consuming. Large\nLanguage Models (LLMs) have shown promise in generating relevance labels for\nsearch tasks, offering a potential alternative to manual assessments. Current\napproaches often rely on a single LLM, such as GPT-4, which, despite being\neffective, are expensive and prone to intra-model biases that can favour\nsystems leveraging similar models. In this work, we introduce JudgeBlender, a\nframework that employs smaller, open-source models to provide relevance\njudgments by combining evaluations across multiple LLMs (LLMBlender) or\nmultiple prompts (PromptBlender). By leveraging the LLMJudge benchmark [18], we\ncompare JudgeBlender with state-of-the-art methods and the top performers in\nthe LLMJudge challenge. Our results show that JudgeBlender achieves competitive\nperformance, demonstrating that very large models are often unnecessary for\nreliable relevance assessments.\n","authors":["Hossein A. Rahmani","Emine Yilmaz","Nick Craswell","Bhaskar Mitra"],"pdf_url":"https://arxiv.org/pdf/2412.13268v1.pdf","comment":"14 pages"},{"id":"http://arxiv.org/abs/2412.13170v1","updated":"2024-12-17T18:47:57Z","published":"2024-12-17T18:47:57Z","title":"Re-calibrating methodologies in social media research: Challenge the\n  visual, work with Speech","summary":"  This article methodologically reflects on how social media scholars can\neffectively engage with speech-based data in their analyses. While contemporary\nmedia studies have embraced textual, visual, and relational data, the aural\ndimension remained comparatively under-explored. Building on the notion of\nsecondary orality and rejection towards purely visual culture, the paper argues\nthat considering voice and speech at scale enriches our understanding of\nmultimodal digital content. The paper presents the TikTok Subtitles Toolkit\nthat offers accessible speech processing readily compatible with existing\nworkflows. In doing so, it opens new avenues for large-scale inquiries that\nblend quantitative insights with qualitative precision. Two illustrative cases\nhighlight both opportunities and limitations of speech research: while genres\nlike #storytime on TikTok benefit from the exploration of spoken narratives,\nnonverbal or music-driven content may not yield significant insights using\nspeech data. The article encourages researchers to integrate aural exploration\nthoughtfully to complement existing methods, rather than replacing them. I\nconclude that the expansion of our methodological repertoire enables richer\ninterpretations of platformised content, and our capacity to unpack digital\ncultures as they become increasingly multimodal.\n","authors":["Hongrui Jin"],"pdf_url":"https://arxiv.org/pdf/2412.13170v1.pdf","comment":"11 pages (excluding references), 3 figures"},{"id":"http://arxiv.org/abs/2412.13071v1","updated":"2024-12-17T16:38:10Z","published":"2024-12-17T16:38:10Z","title":"CLASP: Contrastive Language-Speech Pretraining for Multilingual\n  Multimodal Information Retrieval","summary":"  This study introduces CLASP (Contrastive Language-Speech Pretraining), a\nmultilingual, multimodal representation tailored for audio-text information\nretrieval. CLASP leverages the synergy between spoken content and textual data.\nDuring training, we utilize our newly introduced speech-text dataset, which\nencompasses 15 diverse categories ranging from fiction to religion. CLASP's\naudio component integrates audio spectrograms with a pre-trained\nself-supervised speech model, while its language encoding counterpart employs a\nsentence encoder pre-trained on over 100 languages. This unified lightweight\nmodel bridges the gap between various modalities and languages, enhancing its\neffectiveness in handling and retrieving multilingual and multimodal data. Our\nevaluations across multiple languages demonstrate that CLASP establishes new\nbenchmarks in HITS@1, MRR, and meanR metrics, outperforming traditional\nASR-based retrieval approaches in specific scenarios.\n","authors":["Mohammad Mahdi Abootorabi","Ehsaneddin Asgari"],"pdf_url":"https://arxiv.org/pdf/2412.13071v1.pdf","comment":"accepted at ECIR 2025"},{"id":"http://arxiv.org/abs/2412.12997v1","updated":"2024-12-17T15:21:28Z","published":"2024-12-17T15:21:28Z","title":"Enabling Low-Resource Language Retrieval: Establishing Baselines for\n  Urdu MS MARCO","summary":"  As the Information Retrieval (IR) field increasingly recognizes the\nimportance of inclusivity, addressing the needs of low-resource languages\nremains a significant challenge. This paper introduces the first large-scale\nUrdu IR dataset, created by translating the MS MARCO dataset through machine\ntranslation. We establish baseline results through zero-shot learning for IR in\nUrdu and subsequently apply the mMARCO multilingual IR methodology to this\nnewly translated dataset. Our findings demonstrate that the fine-tuned model\n(Urdu-mT5-mMARCO) achieves a Mean Reciprocal Rank (MRR@10) of 0.247 and a\nRecall@10 of 0.439, representing significant improvements over zero-shot\nresults and showing the potential for expanding IR access for Urdu speakers. By\nbridging access gaps for speakers of low-resource languages, this work not only\nadvances multilingual IR research but also emphasizes the ethical and societal\nimportance of inclusive IR technologies. This work provides valuable insights\ninto the challenges and solutions for improving language representation and\nlays the groundwork for future research, especially in South Asian languages,\nwhich can benefit from the adaptable methods used in this study.\n","authors":["Umer Butt","Stalin Veranasi","Günter Neumann"],"pdf_url":"https://arxiv.org/pdf/2412.12997v1.pdf","comment":"6 pages, ECIR 2025, conference submission version"},{"id":"http://arxiv.org/abs/2412.12984v1","updated":"2024-12-17T15:04:54Z","published":"2024-12-17T15:04:54Z","title":"Cluster-guided Contrastive Class-imbalanced Graph Classification","summary":"  This paper studies the problem of class-imbalanced graph classification,\nwhich aims at effectively classifying the categories of graphs in scenarios\nwith imbalanced class distribution. Despite the tremendous success of graph\nneural networks (GNNs), their modeling ability for imbalanced graph-structured\ndata is inadequate, which typically leads to predictions biased towards the\nmajority classes. Besides, existing class-imbalanced learning methods in\nvisions may overlook the rich graph semantic substructures of the majority\nclasses and excessively emphasize learning from the minority classes. To tackle\nthis issue, this paper proposes a simple yet powerful approach called C$^3$GNN\nthat incorporates the idea of clustering into contrastive learning to enhance\nclass-imbalanced graph classification. Technically, C$^3$GNN clusters graphs\nfrom each majority class into multiple subclasses, ensuring they have similar\nsizes to the minority class, thus alleviating class imbalance. Additionally, it\nutilizes the Mixup technique to synthesize new samples and enrich the semantic\ninformation of each subclass, and leverages supervised contrastive learning to\nhierarchically learn effective graph representations. In this way, we can not\nonly sufficiently explore the semantic substructures within the majority class\nbut also effectively alleviate excessive focus on the minority class. Extensive\nexperiments on real-world graph benchmark datasets verify the superior\nperformance of our proposed method.\n","authors":["Wei Ju","Zhengyang Mao","Siyu Yi","Yifang Qin","Yiyang Gu","Zhiping Xiao","Jianhao Shen","Ziyue Qiao","Ming Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.12984v1.pdf","comment":"Accepted by Proceedings of the Thirty-Ninth AAAI Conference on\n  Artificial Intelligence (AAAI-25)"},{"id":"http://arxiv.org/abs/2406.08270v2","updated":"2024-12-17T12:56:42Z","published":"2024-06-12T14:35:43Z","title":"It is Never Too Late to Mend: Separate Learning for Multimedia\n  Recommendation","summary":"  Multimedia recommendation, which incorporates various modalities (e.g.,\nimages, texts, etc.) into user or item representation to improve recommendation\nquality, and self-supervised learning carries multimedia recommendation to a\nplateau of performance, because of its superior performance in aligning\ndifferent modalities. However, more and more research finds that aligning all\nmodal representations is suboptimal because it damages the unique attributes of\neach modal. These studies use subtraction and orthogonal constraints in\ngeometric space to learn unique parts. However, our rigorous analysis reveals\nthe flaws in this approach, such as that subtraction does not necessarily yield\nthe desired modal-unique and that orthogonal constraints are ineffective in\nuser and item high-dimensional representation spaces. To make up for the\nprevious weaknesses, we propose Separate Learning (SEA) for multimedia\nrecommendation, which mainly includes mutual information view of modal-unique\nand -generic learning. Specifically, we first use GNN to learn the\nrepresentations of users and items in different modalities and split each modal\nrepresentation into generic and unique parts. We employ contrastive log-ratio\nupper bound to minimize the mutual information between the general and unique\nparts within the same modality, to distance their representations, thus\nlearning modal-unique features. Then, we design Solosimloss to maximize the\nlower bound of mutual information, to align the general parts of different\nmodalities, thus learning more high-quality modal-generic features. Finally,\nextensive experiments on three datasets demonstrate the effectiveness and\ngeneralization of our proposed framework. The code is available at SEA and the\nfull training record of the main experiment.\n","authors":["Zhuangzhuang He","Zihan Wang","Yonghui Yang","Haoyue Bai","Le Wu"],"pdf_url":"https://arxiv.org/pdf/2406.08270v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12852v1","updated":"2024-12-17T12:26:14Z","published":"2024-12-17T12:26:14Z","title":"Selective Shot Learning for Code Explanation","summary":"  Code explanation plays a crucial role in the software engineering domain,\naiding developers in grasping code functionality efficiently. Recent work shows\nthat the performance of LLMs for code explanation improves in a few-shot\nsetting, especially when the few-shot examples are selected intelligently.\nState-of-the-art approaches for such Selective Shot Learning (SSL) include\ntoken-based and embedding-based methods. However, these SSL approaches have\nbeen evaluated on proprietary LLMs, without much exploration on open-source\nCode-LLMs. Additionally, these methods lack consideration for programming\nlanguage syntax. To bridge these gaps, we present a comparative study and\npropose a novel SSL method (SSL_ner) that utilizes entity information for\nfew-shot example selection. We present several insights and show the\neffectiveness of SSL_ner approach over state-of-the-art methods across two\ndatasets. To the best of our knowledge, this is the first systematic\nbenchmarking of open-source Code-LLMs while assessing the performances of the\nvarious few-shot examples selection approaches for the code explanation task.\n","authors":["Paheli Bhattacharya","Rishabh Gupta"],"pdf_url":"https://arxiv.org/pdf/2412.12852v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12836v1","updated":"2024-12-17T11:58:55Z","published":"2024-12-17T11:58:55Z","title":"A Survey on Recommendation Unlearning: Fundamentals, Taxonomy,\n  Evaluation, and Open Questions","summary":"  Recommender systems have become increasingly influential in shaping user\nbehavior and decision-making, highlighting their growing impact in various\ndomains. Meanwhile, the widespread adoption of machine learning models in\nrecommender systems has raised significant concerns regarding user privacy and\nsecurity. As compliance with privacy regulations becomes more critical, there\nis a pressing need to address the issue of recommendation unlearning, i.e.,\neliminating the memory of specific training data from the learned\nrecommendation models. Despite its importance, traditional machine unlearning\nmethods are ill-suited for recommendation unlearning due to the unique\nchallenges posed by collaborative interactions and model parameters. This\nsurvey offers a comprehensive review of the latest advancements in\nrecommendation unlearning, exploring the design principles, challenges, and\nmethodologies associated with this emerging field. We provide a unified\ntaxonomy that categorizes different recommendation unlearning approaches,\nfollowed by a summary of widely used benchmarks and metrics for evaluation. By\nreviewing the current state of research, this survey aims to guide the\ndevelopment of more efficient, scalable, and robust recommendation unlearning\ntechniques. Furthermore, we identify open research questions in this field,\nwhich could pave the way for future innovations not only in recommendation\nunlearning but also in a broader range of unlearning tasks across different\nmachine learning applications.\n","authors":["Yuyuan Li","Xiaohua Feng","Chaochao Chen","Qiang Yang"],"pdf_url":"https://arxiv.org/pdf/2412.12836v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12806v1","updated":"2024-12-17T11:21:09Z","published":"2024-12-17T11:21:09Z","title":"Cross-Dialect Information Retrieval: Information Access in Low-Resource\n  and High-Variance Languages","summary":"  A large amount of local and culture-specific knowledge (e.g., people,\ntraditions, food) can only be found in documents written in dialects. While\nthere has been extensive research conducted on cross-lingual information\nretrieval (CLIR), the field of cross-dialect retrieval (CDIR) has received\nlimited attention. Dialect retrieval poses unique challenges due to the limited\navailability of resources to train retrieval models and the high variability in\nnon-standardized languages. We study these challenges on the example of German\ndialects and introduce the first German dialect retrieval dataset, dubbed\nWikiDIR, which consists of seven German dialects extracted from Wikipedia.\nUsing WikiDIR, we demonstrate the weakness of lexical methods in dealing with\nhigh lexical variation in dialects. We further show that commonly used\nzero-shot cross-lingual transfer approach with multilingual encoders do not\ntransfer well to extremely low-resource setups, motivating the need for\nresource-lean and dialect-specific retrieval models. We finally demonstrate\nthat (document) translation is an effective way to reduce the dialect gap in\nCDIR.\n","authors":["Robert Litschko","Oliver Kraus","Verena Blaschke","Barbara Plank"],"pdf_url":"https://arxiv.org/pdf/2412.12806v1.pdf","comment":"Accepted at COLING 2025"},{"id":"http://arxiv.org/abs/2412.12775v1","updated":"2024-12-17T10:36:52Z","published":"2024-12-17T10:36:52Z","title":"RemoteRAG: A Privacy-Preserving LLM Cloud RAG Service","summary":"  Retrieval-augmented generation (RAG) improves the service quality of large\nlanguage models by retrieving relevant documents from credible literature and\nintegrating them into the context of the user query. Recently, the rise of the\ncloud RAG service has made it possible for users to query relevant documents\nconveniently. However, directly sending queries to the cloud brings potential\nprivacy leakage. In this paper, we are the first to formally define the\nprivacy-preserving cloud RAG service to protect the user query and propose\nRemoteRAG as a solution regarding privacy, efficiency, and accuracy. For\nprivacy, we introduce $(n,\\epsilon)$-DistanceDP to characterize privacy leakage\nof the user query and the leakage inferred from relevant documents. For\nefficiency, we limit the search range from the total documents to a small\nnumber of selected documents related to a perturbed embedding generated from\n$(n,\\epsilon)$-DistanceDP, so that computation and communication costs required\nfor privacy protection significantly decrease. For accuracy, we ensure that the\nsmall range includes target documents related to the user query with detailed\ntheoretical analysis. Experimental results also demonstrate that RemoteRAG can\nresist existing embedding inversion attack methods while achieving no loss in\nretrieval under various settings. Moreover, RemoteRAG is efficient, incurring\nonly $0.67$ seconds and $46.66$KB of data transmission ($2.72$ hours and $1.43$\nGB with the non-optimized privacy-preserving scheme) when retrieving from a\ntotal of $10^6$ documents.\n","authors":["Yihang Cheng","Lan Zhang","Junyang Wang","Mu Yuan","Yunhao Yao"],"pdf_url":"https://arxiv.org/pdf/2412.12775v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12770v1","updated":"2024-12-17T10:33:13Z","published":"2024-12-17T10:33:13Z","title":"A Survey on Sequential Recommendation","summary":"  Different from most conventional recommendation problems, sequential\nrecommendation focuses on learning users' preferences by exploiting the\ninternal order and dependency among the interacted items, which has received\nsignificant attention from both researchers and practitioners. In recent years,\nwe have witnessed great progress and achievements in this field, necessitating\na new survey. In this survey, we study the SR problem from a new perspective\n(i.e., the construction of an item's properties), and summarize the most recent\ntechniques used in sequential recommendation such as pure ID-based SR, SR with\nside information, multi-modal SR, generative SR, LLM-powered SR, ultra-long SR\nand data-augmented SR. Moreover, we introduce some frontier research topics in\nsequential recommendation, e.g., open-domain SR, data-centric SR, could-edge\ncollaborative SR, continuous SR, SR for good, and explainable SR. We believe\nthat our survey could be served as a valuable roadmap for readers in this\nfield.\n","authors":["Liwei Pan","Weike Pan","Meiyan Wei","Hongzhi Yin","Zhong Ming"],"pdf_url":"https://arxiv.org/pdf/2412.12770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12754v1","updated":"2024-12-17T10:19:44Z","published":"2024-12-17T10:19:44Z","title":"Token-Level Graphs for Short Text Classification","summary":"  The classification of short texts is a common subtask in Information\nRetrieval (IR). Recent advances in graph machine learning have led to interest\nin graph-based approaches for low resource scenarios, showing promise in such\nsettings. However, existing methods face limitations such as not accounting for\ndifferent meanings of the same words or constraints from transductive\napproaches. We propose an approach which constructs text graphs entirely based\non tokens obtained through pre-trained language models (PLMs). By applying a\nPLM to tokenize and embed the texts when creating the graph(-nodes), our method\ncaptures contextual and semantic information, overcomes vocabulary constraints,\nand allows for context-dependent word meanings. Our approach also makes\nclassification more efficient with reduced parameters compared to classical PLM\nfine-tuning, resulting in more robust training with few samples. Experimental\nresults demonstrate how our method consistently achieves higher scores or\non-par performance with existing methods, presenting an advancement in\ngraph-based text classification techniques. To support reproducibility of our\nwork we make all implementations publicly available to the\ncommunity\\footnote{\\url{https://github.com/doGregor/TokenGraph}}.\n","authors":["Gregor Donabauer","Udo Kruschwitz"],"pdf_url":"https://arxiv.org/pdf/2412.12754v1.pdf","comment":"Preprint accepted at the 47th European Conference on Information\n  Retrieval (ECIR 2025)"},{"id":"http://arxiv.org/abs/2412.12612v1","updated":"2024-12-17T07:21:25Z","published":"2024-12-17T07:21:25Z","title":"SynthCypher: A Fully Synthetic Data Generation Framework for\n  Text-to-Cypher Querying in Knowledge Graphs","summary":"  Cypher, the query language for Neo4j graph databases, plays a critical role\nin enabling graph-based analytics and data exploration. While substantial\nresearch has been dedicated to natural language to SQL query generation\n(Text2SQL), the analogous problem for graph databases referred to as\nText2Cypher remains underexplored. In this work, we introduce SynthCypher, a\nfully synthetic and automated data generation pipeline designed to address this\ngap. SynthCypher employs a novel LLMSupervised Generation-Verification\nframework, ensuring syntactically and semantically correct Cypher queries\nacross diverse domains and query complexities. Using this pipeline, we create\nSynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher\ninstances. Fine-tuning open-source large language models (LLMs), including\nLLaMa-3.1- 8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant\nperformance improvements of up to 40% on the Text2Cypher test set and 30% on\nthe SPIDER benchmark adapted for graph databases. This work demonstrates that\nhigh-quality synthetic data can effectively advance the state-of-the-art in\nText2Cypher tasks.\n","authors":["Aman Tiwari","Shiva Krishna Reddy Malay","Vikas Yadav","Masoud Hashemi","Sathwik Tejaswi Madhusudhan"],"pdf_url":"https://arxiv.org/pdf/2412.12612v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2405.15328v2","updated":"2024-12-17T05:35:15Z","published":"2024-05-24T08:11:59Z","title":"Multi-Modal Recommendation Unlearning for Legal, Licensing, and Modality\n  Constraints","summary":"  User data spread across multiple modalities has popularized multi-modal\nrecommender systems (MMRS). They recommend diverse content such as products,\nsocial media posts, TikTok reels, etc., based on a user-item interaction graph.\nWith rising data privacy demands, recent methods propose unlearning private\nuser data from uni-modal recommender systems (RS). However, methods for\nunlearning item data related to outdated user preferences, revoked licenses,\nand legally requested removals are still largely unexplored.\n  Previous RS unlearning methods are unsuitable for MMRS due to the\nincompatibility of their matrix-based representation with the multi-modal\nuser-item interaction graph. Moreover, their data partitioning step degrades\nperformance on each shard due to poor data heterogeneity and requires costly\nperformance aggregation across shards.\n  This paper introduces MMRecUn, the first approach known to us for unlearning\nin MMRS and unlearning item data. Given a trained RS model, MMRecUn employs a\nnovel Reverse Bayesian Personalized Ranking (BPR) objective to enable the model\nto forget marked data. The reverse BPR attenuates the impact of user-item\ninteractions within the forget set, while the forward BPR reinforces the\nsignificance of user-item interactions within the retain set. Our experiments\ndemonstrate that MMRecUn outperforms baseline methods across various unlearning\nrequests when evaluated on benchmark MMRS datasets. MMRecUn achieves recall\nperformance improvements of up to 49.85% compared to baseline methods and is up\nto $\\mathbf{1.3}\\times$ faster than the Gold model, which is trained on retain\nset from scratch. MMRecUn offers significant advantages, including superiority\nin removing target interactions, preserving retained interactions, and zero\noverhead costs compared to previous methods. The code will be released after\nreview.\n","authors":["Yash Sinha","Murari Mandal","Mohan Kankanhalli"],"pdf_url":"https://arxiv.org/pdf/2405.15328v2.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2402.06871v5","updated":"2024-12-17T05:19:27Z","published":"2024-02-10T03:21:13Z","title":"Non-autoregressive Generative Models for Reranking Recommendation","summary":"  Contemporary recommendation systems are designed to meet users' needs by\ndelivering tailored lists of items that align with their specific demands or\ninterests. In a multi-stage recommendation system, reranking plays a crucial\nrole by modeling the intra-list correlations among items. The key challenge of\nreranking lies in the exploration of optimal sequences within the combinatorial\nspace of permutations. Recent research proposes a generator-evaluator learning\nparadigm, where the generator generates multiple feasible sequences and the\nevaluator picks out the best sequence based on the estimated listwise score.\nThe generator is of vital importance, and generative models are well-suited for\nthe generator function. Current generative models employ an autoregressive\nstrategy for sequence generation. However, deploying autoregressive models in\nreal-time industrial systems is challenging. To address these issues, we\npropose a Non-AutoRegressive generative model for reranking Recommendation\n(NAR4Rec) designed to enhance efficiency and effectiveness. To tackle\nchallenges such as sparse training samples and dynamic candidates, we introduce\na matching model. Considering the diverse nature of user feedback, we employ a\nsequence-level unlikelihood training objective to differentiate feasible\nsequences from unfeasible ones. Additionally, to overcome the lack of\ndependency modeling in non-autoregressive models regarding target items, we\nintroduce contrastive decoding to capture correlations among these items.\nExtensive offline experiments validate the superior performance of NAR4Rec over\nstate-of-the-art reranking methods. Online A/B tests reveal that NAR4Rec\nsignificantly enhances the user experience. Furthermore, NAR4Rec has been fully\ndeployed in a popular video app Kuaishou with over 300 million daily active\nusers.\n","authors":["Yuxin Ren","Qiya Yang","Yichun Wu","Wei Xu","Yalong Wang","Zhiqiang Zhang"],"pdf_url":"https://arxiv.org/pdf/2402.06871v5.pdf","comment":"Accepted by KDD 2024"},{"id":"http://arxiv.org/abs/2412.12504v1","updated":"2024-12-17T03:10:47Z","published":"2024-12-17T03:10:47Z","title":"Boosting LLM-based Relevance Modeling with Distribution-Aware Robust\n  Learning","summary":"  With the rapid advancement of pre-trained large language models (LLMs),\nrecent endeavors have leveraged the capabilities of LLMs in relevance modeling,\nresulting in enhanced performance. This is usually done through the process of\nfine-tuning LLMs on specifically annotated datasets to determine the relevance\nbetween queries and items. However, there are two limitations when LLMs are\nnaively employed for relevance modeling through fine-tuning and inference.\nFirst, it is not inherently efficient for performing nuanced tasks beyond\nsimple yes or no answers, such as assessing search relevance. It may therefore\ntend to be overconfident and struggle to distinguish fine-grained degrees of\nrelevance (e.g., strong relevance, weak relevance, irrelevance) used in search\nengines. Second, it exhibits significant performance degradation when\nconfronted with data distribution shift in real-world scenarios. In this paper,\nwe propose a novel Distribution-Aware Robust Learning framework (DaRL) for\nrelevance modeling in Alipay Search. Specifically, we design an effective loss\nfunction to enhance the discriminability of LLM-based relevance modeling across\nvarious fine-grained degrees of query-item relevance. To improve the\ngeneralizability of LLM-based relevance modeling, we first propose the\nDistribution-Aware Sample Augmentation (DASA) module. This module utilizes\nout-of-distribution (OOD) detection techniques to actively select appropriate\nsamples that are not well covered by the original training set for model\nfine-tuning. Furthermore, we adopt a multi-stage fine-tuning strategy to\nsimultaneously improve in-distribution (ID) and OOD performance, bridging the\nperformance gap between them. DaRL has been deployed online to serve the\nAlipay's insurance product search...\n","authors":["Hong Liu","Saisai Gong","Yixin Ji","Kaixin Wu","Jia Xu","Jinjie Gu"],"pdf_url":"https://arxiv.org/pdf/2412.12504v1.pdf","comment":"8 pages"},{"id":"http://arxiv.org/abs/2412.12464v1","updated":"2024-12-17T01:52:15Z","published":"2024-12-17T01:52:15Z","title":"LLM is Knowledge Graph Reasoner: LLM's Intuition-aware Knowledge Graph\n  Reasoning for Cold-start Sequential Recommendation","summary":"  Knowledge Graphs (KGs) represent relationships between entities in a graph\nstructure and have been widely studied as promising tools for realizing\nrecommendations that consider the accurate content information of items.\nHowever, traditional KG-based recommendation methods face fundamental\nchallenges: insufficient consideration of temporal information and poor\nperformance in cold-start scenarios. On the other hand, Large Language Models\n(LLMs) can be considered databases with a wealth of knowledge learned from the\nweb data, and they have recently gained attention due to their potential\napplication as recommendation systems. Although approaches that treat LLMs as\nrecommendation systems can leverage LLMs' high recommendation literacy, their\ninput token limitations make it impractical to consider the entire\nrecommendation domain dataset and result in scalability issues. To address\nthese challenges, we propose a LLM's Intuition-aware Knowledge graph Reasoning\nmodel (LIKR). Our main idea is to treat LLMs as reasoners that output intuitive\nexploration strategies for KGs. To integrate the knowledge of LLMs and KGs, we\ntrained a recommendation agent through reinforcement learning using a reward\nfunction that integrates different recommendation strategies, including LLM's\nintuition and KG embeddings. By incorporating temporal awareness through prompt\nengineering and generating textual representations of user preferences from\nlimited interactions, LIKR can improve recommendation performance in cold-start\nscenarios. Furthermore, LIKR can avoid scalability issues by using KGs to\nrepresent recommendation domain datasets and limiting the LLM's output to KG\nexploration strategies. Experiments on real-world datasets demonstrate that our\nmodel outperforms state-of-the-art recommendation methods in cold-start\nsequential recommendation scenarios.\n","authors":["Keigo Sakurai","Ren Togo","Takahiro Ogawa","Miki Haseyama"],"pdf_url":"https://arxiv.org/pdf/2412.12464v1.pdf","comment":"Accepted to the 47th European Conference on Information Retrieval\n  (ECIR2025)"},{"id":"http://arxiv.org/abs/2412.12459v1","updated":"2024-12-17T01:43:44Z","published":"2024-12-17T01:43:44Z","title":"LITA: An Efficient LLM-assisted Iterative Topic Augmentation Framework","summary":"  Topic modeling is widely used for uncovering thematic structures within text\ncorpora, yet traditional models often struggle with specificity and coherence\nin domain-focused applications. Guided approaches, such as SeededLDA and CorEx,\nincorporate user-provided seed words to improve relevance but remain\nlabor-intensive and static. Large language models (LLMs) offer potential for\ndynamic topic refinement and discovery, yet their application often incurs high\nAPI costs. To address these challenges, we propose the LLM-assisted Iterative\nTopic Augmentation framework (LITA), an LLM-assisted approach that integrates\nuser-provided seeds with embedding-based clustering and iterative refinement.\nLITA identifies a small number of ambiguous documents and employs an LLM to\nreassign them to existing or new topics, minimizing API costs while enhancing\ntopic quality. Experiments on two datasets across topic quality and clustering\nperformance metrics demonstrate that LITA outperforms five baseline models,\nincluding LDA, SeededLDA, CorEx, BERTopic, and PromptTopic. Our work offers an\nefficient and adaptable framework for advancing topic modeling and text\nclustering.\n","authors":["Chia-Hsuan Chang","Jui-Tse Tsai","Yi-Hang Tsai","San-Yih Hwang"],"pdf_url":"https://arxiv.org/pdf/2412.12459v1.pdf","comment":"Under Review"},{"id":"http://arxiv.org/abs/2412.12433v1","updated":"2024-12-17T00:50:23Z","published":"2024-12-17T00:50:23Z","title":"Refining Dimensions for Improving Clustering-based Cross-lingual Topic\n  Models","summary":"  Recent works in clustering-based topic models perform well in monolingual\ntopic identification by introducing a pipeline to cluster the contextualized\nrepresentations. However, the pipeline is suboptimal in identifying topics\nacross languages due to the presence of language-dependent dimensions (LDDs)\ngenerated by multilingual language models. To address this issue, we introduce\na novel, SVD-based dimension refinement component into the pipeline of the\nclustering-based topic model. This component effectively neutralizes the\nnegative impact of LDDs, enabling the model to accurately identify topics\nacross languages. Our experiments on three datasets demonstrate that the\nupdated pipeline with the dimension refinement component generally outperforms\nother state-of-the-art cross-lingual topic models.\n","authors":["Chia-Hsuan Chang","Tien-Yuan Huang","Yi-Hang Tsai","Chia-Ming Chang","San-Yih Hwang"],"pdf_url":"https://arxiv.org/pdf/2412.12433v1.pdf","comment":"Accepted to 18th BUCC Workshop at COLING 2025"},{"id":"http://arxiv.org/abs/2409.12468v2","updated":"2024-12-17T00:25:46Z","published":"2024-09-19T05:14:55Z","title":"Familiarity-Aware Evidence Compression for Retrieval-Augmented\n  Generation","summary":"  Retrieval-augmented generation (RAG) improves large language models (LMs) by\nincorporating non-parametric knowledge through evidence retrieved from external\nsources. However, it often struggles to cope with inconsistent and irrelevant\ninformation that can distract the LM from its tasks, especially when multiple\nevidence pieces are required. While compressing the retrieved evidence with a\ncompression model aims to address this issue, the compressed evidence may still\nbe unfamiliar to the target model used for downstream tasks, potentially\nfailing to utilize the evidence effectively. We propose FaviComp\n(Familarity-Aware Evidence Compression), a novel training-free evidence\ncompression technique that makes retrieved evidence more familiar to the target\nmodel, while seamlessly integrating parametric knowledge from the model.\nExperimental results show that FaviComp consistently outperforms most recent\nevidence compression baselines across multiple open-domain QA datasets,\nimproving accuracy by up to 28.1% while achieving high compression rates.\nAdditionally, we demonstrate the effective integration of both parametric and\nnon-parametric knowledge during evidence compression.\n","authors":["Dongwon Jung","Qin Liu","Tenghao Huang","Ben Zhou","Muhao Chen"],"pdf_url":"https://arxiv.org/pdf/2409.12468v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2308.07857v2","updated":"2024-12-17T00:14:25Z","published":"2023-08-15T16:16:02Z","title":"Impression-Aware Recommender Systems","summary":"  Novel data sources bring new opportunities to improve the quality of\nrecommender systems and serve as a catalyst for the creation of new paradigms\non personalized recommendations. Impressions are a novel data source containing\nthe items shown to users on their screens. Past research focused on providing\npersonalized recommendations using interactions, and occasionally using\nimpressions when such a data source was available. Interest in impressions has\nincreased due to their potential to provide more accurate recommendations.\nDespite this increased interest, research in recommender systems using\nimpressions is still dispersed. Many works have distinct interpretations of\nimpressions and use impressions in recommender systems in numerous different\nmanners. To unify those interpretations into a single framework, we present a\nsystematic literature review on recommender systems using impressions, focusing\non three fundamental perspectives: recommendation models, datasets, and\nevaluation methodologies. We define a theoretical framework to delimit\nrecommender systems using impressions and a novel paradigm for personalized\nrecommendations, called impression-aware recommender systems. We propose a\nclassification system for recommenders in this paradigm, which we use to\ncategorize the recommendation models, datasets, and evaluation methodologies\nused in past research. Lastly, we identify open questions and future\ndirections, highlighting missing aspects in the reviewed literature.\n","authors":["Fernando B. Pérez Maurera","Maurizio Ferrari Dacrema","Pablo Castells","Paolo Cremonesi"],"pdf_url":"https://arxiv.org/pdf/2308.07857v2.pdf","comment":"44 pages, 127 references, 6 tables, 5 figures, ACM TORS ACCEPTED"}]},"2024-12-16T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.12330v1","updated":"2024-12-16T20:00:51Z","published":"2024-12-16T20:00:51Z","title":"Searching Personal Collections","summary":"  This article describes the history of information retrieval on personal\ndocument collections.\n","authors":["Michael Bendersky","Donald Metzler","Marc Najork","Xuanhui Wang"],"pdf_url":"https://arxiv.org/pdf/2412.12330v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.12322v1","updated":"2024-12-16T19:40:26Z","published":"2024-12-16T19:40:26Z","title":"RAG Playground: A Framework for Systematic Evaluation of Retrieval\n  Strategies and Prompt Engineering in RAG Systems","summary":"  We present RAG Playground, an open-source framework for systematic evaluation\nof Retrieval-Augmented Generation (RAG) systems. The framework implements and\ncompares three retrieval approaches: naive vector search, reranking, and hybrid\nvector-keyword search, combined with ReAct agents using different prompting\nstrategies. We introduce a comprehensive evaluation framework with novel\nmetrics and provide empirical results comparing different language models\n(Llama 3.1 and Qwen 2.5) across various retrieval configurations. Our\nexperiments demonstrate significant performance improvements through hybrid\nsearch methods and structured self-evaluation prompting, achieving up to 72.7%\npass rate on our multi-metric evaluation framework. The results also highlight\nthe importance of prompt engineering in RAG systems, with our custom-prompted\nagents showing consistent improvements in retrieval accuracy and response\nquality.\n","authors":["Ioannis Papadimitriou","Ilias Gialampoukidis","Stefanos Vrochidis"," Ioannis"," Kompatsiaris"],"pdf_url":"https://arxiv.org/pdf/2412.12322v1.pdf","comment":"Work In Progress"},{"id":"http://arxiv.org/abs/2412.12092v1","updated":"2024-12-16T18:58:28Z","published":"2024-12-16T18:58:28Z","title":"No More Tuning: Prioritized Multi-Task Learning with Lagrangian\n  Differential Multiplier Methods","summary":"  Given the ubiquity of multi-task in practical systems, Multi-Task Learning\n(MTL) has found widespread application across diverse domains. In real-world\nscenarios, these tasks often have different priorities. For instance, In web\nsearch, relevance is often prioritized over other metrics, such as\nclick-through rates or user engagement. Existing frameworks pay insufficient\nattention to the prioritization among different tasks, which typically adjust\ntask-specific loss function weights to differentiate task priorities. However,\nthis approach encounters challenges as the number of tasks grows, leading to\nexponential increases in hyper-parameter tuning complexity. Furthermore, the\nsimultaneous optimization of multiple objectives can negatively impact the\nperformance of high-priority tasks due to interference from lower-priority\ntasks.\n  In this paper, we introduce a novel multi-task learning framework employing\nLagrangian Differential Multiplier Methods for step-wise multi-task\noptimization. It is designed to boost the performance of high-priority tasks\nwithout interference from other tasks. Its primary advantage lies in its\nability to automatically optimize multiple objectives without requiring\nbalancing hyper-parameters for different tasks, thereby eliminating the need\nfor manual tuning. Additionally, we provide theoretical analysis demonstrating\nthat our method ensures optimization guarantees, enhancing the reliability of\nthe process. We demonstrate its effectiveness through experiments on multiple\npublic datasets and its application in Taobao search, a large-scale industrial\nsearch ranking system, resulting in significant improvements across various\nbusiness metrics.\n","authors":["Zhengxing Cheng","Yuheng Huang","Zhixuan Zhang","Dan Ou","Qingwen Liu"],"pdf_url":"https://arxiv.org/pdf/2412.12092v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.06954v3","updated":"2024-12-16T16:18:28Z","published":"2024-12-09T20:01:59Z","title":"CURE: A dataset for Clinical Understanding & Retrieval Evaluation","summary":"  Given the dominance of dense retrievers that do not generalize well beyond\ntheir training dataset distributions, domain-specific test sets are essential\nin evaluating retrieval. There are few test datasets for retrieval systems\nintended for use by healthcare providers in a point-of-care setting. To fill\nthis gap we have collaborated with medical professionals to create CURE, an\nad-hoc retrieval test dataset for passage ranking with 2000 queries spanning 10\nmedical domains with a monolingual (English) and two cross-lingual\n(French/Spanish -> English) conditions. In this paper, we describe how CURE was\nconstructed and provide baseline results to showcase its effectiveness as an\nevaluation tool. CURE is published with a Creative Commons Attribution Non\nCommercial 4.0 license and can be accessed on Hugging Face.\n","authors":["Nadia Sheikh","Anne-Laure Jousse","Daniel Buades Marcos","Akintunde Oladipo","Olivier Rousseau","Jimmy Lin"],"pdf_url":"https://arxiv.org/pdf/2412.06954v3.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11919v1","updated":"2024-12-16T16:03:25Z","published":"2024-12-16T16:03:25Z","title":"RetroLLM: Empowering Large Language Models to Retrieve Fine-grained\n  Evidence within Generation","summary":"  Large language models (LLMs) exhibit remarkable generative capabilities but\noften suffer from hallucinations. Retrieval-augmented generation (RAG) offers\nan effective solution by incorporating external knowledge, but existing methods\nstill face several limitations: additional deployment costs of separate\nretrievers, redundant input tokens from retrieved text chunks, and the lack of\njoint optimization of retrieval and generation. To address these issues, we\npropose \\textbf{RetroLLM}, a unified framework that integrates retrieval and\ngeneration into a single, cohesive process, enabling LLMs to directly generate\nfine-grained evidence from the corpus with constrained decoding. Moreover, to\nmitigate false pruning in the process of constrained evidence generation, we\nintroduce (1) hierarchical FM-Index constraints, which generate\ncorpus-constrained clues to identify a subset of relevant documents before\nevidence generation, reducing irrelevant decoding space; and (2) a\nforward-looking constrained decoding strategy, which considers the relevance of\nfuture sequences to improve evidence accuracy. Extensive experiments on five\nopen-domain QA datasets demonstrate RetroLLM's superior performance across both\nin-domain and out-of-domain tasks. The code is available at\n\\url{https://github.com/sunnynexus/RetroLLM}.\n","authors":["Xiaoxi Li","Jiajie Jin","Yujia Zhou","Yongkang Wu","Zhonghua Li","Qi Ye","Zhicheng Dou"],"pdf_url":"https://arxiv.org/pdf/2412.11919v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11864v1","updated":"2024-12-16T15:20:13Z","published":"2024-12-16T15:20:13Z","title":"Investigating Mixture of Experts in Dense Retrieval","summary":"  While Dense Retrieval Models (DRMs) have advanced Information Retrieval (IR),\none limitation of these neural models is their narrow generalizability and\nrobustness. To cope with this issue, one can leverage the Mixture-of-Experts\n(MoE) architecture. While previous IR studies have incorporated MoE\narchitectures within the Transformer layers of DRMs, our work investigates an\narchitecture that integrates a single MoE block (SB-MoE) after the output of\nthe final Transformer layer. Our empirical evaluation investigates how SB-MoE\ncompares, in terms of retrieval effectiveness, to standard fine-tuning. In\ndetail, we fine-tune three DRMs (TinyBERT, BERT, and Contriever) across four\nbenchmark collections with and without adding the MoE block. Moreover, since\nMoE showcases performance variations with respect to its parameters (i.e., the\nnumber of experts), we conduct additional experiments to investigate this\naspect further. The findings show the effectiveness of SB-MoE especially for\nDRMs with a low number of parameters (i.e., TinyBERT), as it consistently\noutperforms the fine-tuned underlying model on all four benchmarks. For DRMs\nwith a higher number of parameters (i.e., BERT and Contriever), SB-MoE requires\nlarger numbers of training samples to yield better retrieval performance.\n","authors":["Effrosyni Sokli","Pranav Kasela","Georgios Peikos","Gabriella Pasi"],"pdf_url":"https://arxiv.org/pdf/2412.11864v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2410.02729v2","updated":"2024-12-16T15:11:11Z","published":"2024-10-03T17:49:09Z","title":"Unified Multimodal Interleaved Document Representation for Retrieval","summary":"  Information Retrieval (IR) methods aim to identify documents relevant to a\nquery, which have been widely applied in various natural language tasks.\nHowever, existing approaches typically consider only the textual content within\ndocuments, overlooking the fact that documents can contain multiple modalities,\nincluding images and tables. Also, they often segment each long document into\nmultiple discrete passages for embedding, which prevents them from capturing\nthe overall document context and interactions between paragraphs. To address\nthese two challenges, we propose a method that holistically embeds documents\ninterleaved with multiple modalities by leveraging the capability of recent\nvision-language models that enable the processing and integration of text,\nimages, and tables into a unified format and representation. Moreover, to\nmitigate the information loss from segmenting documents into passages, instead\nof representing and retrieving passages individually, we further merge the\nrepresentations of segmented passages into one single document representation,\nwhile we additionally introduce a reranking strategy to decouple and identify\nthe relevant passage within the document if necessary. Then, through extensive\nexperiments on diverse IR scenarios considering both the textual and multimodal\nqueries, we show that our approach substantially outperforms relevant\nbaselines, thanks to the consideration of the multimodal information within\ndocuments.\n","authors":["Jaewoo Lee","Joonho Ko","Jinheon Baek","Soyeong Jeong","Sung Ju Hwang"],"pdf_url":"https://arxiv.org/pdf/2410.02729v2.pdf","comment":"Preprint"},{"id":"http://arxiv.org/abs/2412.11846v1","updated":"2024-12-16T15:08:44Z","published":"2024-12-16T15:08:44Z","title":"SPGL: Enhancing Session-based Recommendation with Single Positive Graph\n  Learning","summary":"  Session-based recommendation seeks to forecast the next item a user will be\ninterested in, based on their interaction sequences. Due to limited interaction\ndata, session-based recommendation faces the challenge of limited data\navailability. Traditional methods enhance feature learning by constructing\ncomplex models to generate positive and negative samples. This paper proposes a\nsession-based recommendation model using Single Positive optimization loss and\nGraph Learning (SPGL) to deal with the problem of data sparsity, high model\ncomplexity and weak transferability. SPGL utilizes graph convolutional networks\nto generate global item representations and batch session representations,\neffectively capturing intrinsic relationships between items. The use of single\npositive optimization loss improves uniformity of item representations, thereby\nenhancing recommendation accuracy. In the intent extractor, SPGL considers the\nhop count of the adjacency matrix when constructing the directed global graph\nto fully integrate spatial information. It also takes into account the reverse\npositional information of items when constructing session representations to\nincorporate temporal information. Comparative experiments across three\nbenchmark datasets, Tmall, RetailRocket and Diginetica, demonstrate the model's\neffectiveness. The source code can be accessed on\nhttps://github.com/liang-tian-tian/SPGL .\n","authors":["Tiantian Liang","Zhe Yang"],"pdf_url":"https://arxiv.org/pdf/2412.11846v1.pdf","comment":"ICONIP 2024"},{"id":"http://arxiv.org/abs/2412.11832v1","updated":"2024-12-16T14:55:57Z","published":"2024-12-16T14:55:57Z","title":"A Distributed Collaborative Retrieval Framework Excelling in All Queries\n  and Corpora based on Zero-shot Rank-Oriented Automatic Evaluation","summary":"  Numerous retrieval models, including sparse, dense and llm-based methods,\nhave demonstrated remarkable performance in predicting the relevance between\nqueries and corpora. However, the preliminary effectiveness analysis\nexperiments indicate that these models fail to achieve satisfactory performance\non the majority of queries and corpora, revealing their effectiveness\nrestricted to specific scenarios. Thus, to tackle this problem, we propose a\nnovel Distributed Collaborative Retrieval Framework (DCRF), outperforming each\nsingle model across all queries and corpora. Specifically, the framework\nintegrates various retrieval models into a unified system and dynamically\nselects the optimal results for each user's query. It can easily aggregate any\nretrieval model and expand to any application scenarios, illustrating its\nflexibility and scalability.Moreover, to reduce maintenance and training costs,\nwe design four effective prompting strategies with large language models (LLMs)\nto evaluate the quality of ranks without reliance of labeled data. Extensive\nexperiments demonstrate that proposed framework, combined with 8 efficient\nretrieval models, can achieve performance comparable to effective listwise\nmethods like RankGPT and ListT5, while offering superior efficiency. Besides,\nDCRF surpasses all selected retrieval models on the most datasets, indicating\nthe effectiveness of our prompting strategies on rank-oriented automatic\nevaluation.\n","authors":["Tian-Yi Che","Xian-Ling Mao","Chun Xu","Cheng-Xin Xin","Heng-Da Xu","Jin-Yu Liu","Heyan Huang"],"pdf_url":"https://arxiv.org/pdf/2412.11832v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11818v1","updated":"2024-12-16T14:35:32Z","published":"2024-12-16T14:35:32Z","title":"Leveraging User-Generated Metadata of Online Videos for Cover Song\n  Identification","summary":"  YouTube is a rich source of cover songs. Since the platform itself is\norganized in terms of videos rather than songs, the retrieval of covers is not\ntrivial. The field of cover song identification addresses this problem and\nprovides approaches that usually rely on audio content. However, including the\nuser-generated video metadata available on YouTube promises improved\nidentification results. In this paper, we propose a multi-modal approach for\ncover song identification on online video platforms. We combine the entity\nresolution models with audio-based approaches using a ranking model. Our\nfindings implicate that leveraging user-generated metadata can stabilize cover\nsong identification performance on YouTube.\n","authors":["Simon Hachmeier","Robert Jäschke"],"pdf_url":"https://arxiv.org/pdf/2412.11818v1.pdf","comment":"accepted for presentation at NLP for Music and Audio (NLP4MusA) 2024"},{"id":"http://arxiv.org/abs/2412.11787v1","updated":"2024-12-16T13:59:10Z","published":"2024-12-16T13:59:10Z","title":"A Method for Detecting Legal Article Competition for Korean Criminal Law\n  Using a Case-augmented Mention Graph","summary":"  As social systems become increasingly complex, legal articles are also\ngrowing more intricate, making it progressively harder for humans to identify\nany potential competitions among them, particularly when drafting new laws or\napplying existing laws. Despite this challenge, no method for detecting such\ncompetitions has been proposed so far. In this paper, we propose a new legal AI\ntask called Legal Article Competition Detection (LACD), which aims to identify\ncompeting articles within a given law. Our novel retrieval method, CAM-Re2,\noutperforms existing relevant methods, reducing false positives by 20.8% and\nfalse negatives by 8.3%, while achieving a 98.2% improvement in precision@5,\nfor the LACD task. We release our codes at\nhttps://github.com/asmath472/LACD-public.\n","authors":["Seonho An","Young Yik Rhim","Min-Soo Kim"],"pdf_url":"https://arxiv.org/pdf/2412.11787v1.pdf","comment":"under review"},{"id":"http://arxiv.org/abs/2412.11758v1","updated":"2024-12-16T13:22:34Z","published":"2024-12-16T13:22:34Z","title":"Establishing a Foundation for Tetun Text Ad-Hoc Retrieval: Indexing,\n  Stemming, Retrieval, and Ranking","summary":"  Searching for information on the internet and digital platforms to satisfy an\ninformation need requires effective retrieval solutions. However, such\nsolutions are not yet available for Tetun, making it challenging to find\nrelevant documents for text-based search queries in this language. To address\nthese challenges, this study investigates Tetun text retrieval with a focus on\nthe ad-hoc retrieval task. It begins by developing essential language resources\n-- including a list of stopwords, a stemmer, and a test collection -- which\nserve as foundational components for solutions tailored to Tetun text\nretrieval. Various strategies are then explored using both document titles and\ncontent to evaluate retrieval effectiveness. The results show that retrieving\ndocument titles, after removing hyphens and apostrophes without applying\nstemming, significantly improves retrieval performance compared to the\nbaseline. Efficiency increases by 31.37%, while effectiveness achieves an\naverage gain of 9.40% in MAP@10 and 30.35% in nDCG@10 with DFR BM25. Beyond the\ntop-10 cutoff point, Hiemstra LM demonstrates strong performance across various\nretrieval strategies and evaluation metrics. Contributions of this work include\nthe development of Labadain-Stopwords (a list of 160 Tetun stopwords),\nLabadain-Stemmer (a Tetun stemmer with three variants), and\nLabadain-Avaliad\\'or (a Tetun test collection containing 59 topics, 33,550\ndocuments, and 5,900 qrels).\n","authors":["Gabriel de Jesus","Sérgio Nunes"],"pdf_url":"https://arxiv.org/pdf/2412.11758v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11747v1","updated":"2024-12-16T13:05:13Z","published":"2024-12-16T13:05:13Z","title":"Beyond Graph Convolution: Multimodal Recommendation with Topology-aware\n  MLPs","summary":"  Given the large volume of side information from different modalities,\nmultimodal recommender systems have become increasingly vital, as they exploit\nricher semantic information beyond user-item interactions. Recent works\nhighlight that leveraging Graph Convolutional Networks (GCNs) to explicitly\nmodel multimodal item-item relations can significantly enhance recommendation\nperformance. However, due to the inherent over-smoothing issue of GCNs,\nexisting models benefit only from shallow GCNs with limited representation\npower. This drawback is especially pronounced when facing complex and\nhigh-dimensional patterns such as multimodal data, as it requires\nlarge-capacity models to accommodate complicated correlations. To this end, in\nthis paper, we investigate bypassing GCNs when modeling multimodal item-item\nrelationship. More specifically, we propose a Topology-aware Multi-Layer\nPerceptron (TMLP), which uses MLPs instead of GCNs to model the relationships\nbetween items. TMLP enhances MLPs with topological pruning to denoise item-item\nrelations and intra (inter)-modality learning to integrate higher-order\nmodality correlations. Extensive experiments on three real-world datasets\nverify TMLP's superiority over nine baselines. We also find that by discarding\nthe internal message passing in GCNs, which is sensitive to node connections,\nTMLP achieves significant improvements in both training efficiency and\nrobustness against existing models.\n","authors":["Junjie Huang","Jiarui Qin","Yong Yu","Weinan Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.11747v1.pdf","comment":"AAAI 2025. 11 pages, 9 figures"},{"id":"http://arxiv.org/abs/2412.11729v1","updated":"2024-12-16T12:53:06Z","published":"2024-12-16T12:53:06Z","title":"STAIR: Manipulating Collaborative and Multimodal Information for\n  E-Commerce Recommendation","summary":"  While the mining of modalities is the focus of most multimodal recommendation\nmethods, we believe that how to fully utilize both collaborative and multimodal\ninformation is pivotal in e-commerce scenarios where, as clarified in this\nwork, the user behaviors are rarely determined entirely by multimodal features.\nIn order to combine the two distinct types of information, some additional\nchallenges are encountered: 1) Modality erasure: Vanilla graph convolution,\nwhich proves rather useful in collaborative filtering, however erases\nmultimodal information; 2) Modality forgetting: Multimodal information tends to\nbe gradually forgotten as the recommendation loss essentially facilitates the\nlearning of collaborative information. To this end, we propose a novel approach\nnamed STAIR, which employs a novel STepwise grAph convolution to enable a\nco-existence of collaborative and multimodal Information in e-commerce\nRecommendation. Besides, it starts with the raw multimodal features as an\ninitialization, and the forgetting problem can be significantly alleviated\nthrough constrained embedding updates. As a result, STAIR achieves\nstate-of-the-art recommendation performance on three public e-commerce datasets\nwith minimal computational and memory costs. Our code is available at\nhttps://github.com/yhhe2004/STAIR.\n","authors":["Cong Xu","Yunhang He","Jun Wang","Wei Zhang"],"pdf_url":"https://arxiv.org/pdf/2412.11729v1.pdf","comment":"Accepted at AAAI 2025"},{"id":"http://arxiv.org/abs/2409.10907v2","updated":"2024-12-16T12:42:07Z","published":"2024-09-17T05:54:25Z","title":"Attention-Seeker: Dynamic Self-Attention Scoring for Unsupervised\n  Keyphrase Extraction","summary":"  This paper proposes Attention-Seeker, an unsupervised keyphrase extraction\nmethod that leverages self-attention maps from a Large Language Model to\nestimate the importance of candidate phrases. Our approach identifies specific\ncomponents - such as layers, heads, and attention vectors - where the model\npays significant attention to the key topics of the text. The attention weights\nprovided by these components are then used to score the candidate phrases.\nUnlike previous models that require manual tuning of parameters (e.g.,\nselection of heads, prompts, hyperparameters), Attention-Seeker dynamically\nadapts to the input text without any manual adjustments, enhancing its\npractical applicability. We evaluate Attention-Seeker on four publicly\navailable datasets: Inspec, SemEval2010, SemEval2017, and Krapivin. Our results\ndemonstrate that, even without parameter tuning, Attention-Seeker outperforms\nmost baseline models, achieving state-of-the-art performance on three out of\nfour datasets, particularly excelling in extracting keyphrases from long\ndocuments.\n","authors":["Erwin D. López Z.","Cheng Tang","Atsushi Shimada"],"pdf_url":"https://arxiv.org/pdf/2409.10907v2.pdf","comment":"This version has been accepted for presentation at COLING 2025, and\n  all peer-reviewed changes have been incorporated"},{"id":"http://arxiv.org/abs/2410.06618v2","updated":"2024-12-16T09:52:32Z","published":"2024-10-09T07:14:49Z","title":"Text Proxy: Decomposing Retrieval from a 1-to-N Relationship into N\n  1-to-1 Relationships for Text-Video Retrieval","summary":"  Text-video retrieval (TVR) has seen substantial advancements in recent years,\nfueled by the utilization of pre-trained models and large language models\n(LLMs). Despite these advancements, achieving accurate matching in TVR remains\nchallenging due to inherent disparities between video and textual modalities\nand irregularities in data representation. In this paper, we propose\nText-Video-ProxyNet (TV-ProxyNet), a novel framework designed to decompose the\nconventional 1-to-N relationship of TVR into N distinct 1-to-1 relationships.\nBy replacing a single text query with a series of text proxies, TV-ProxyNet not\nonly broadens the query scope but also achieves a more precise expansion. Each\ntext proxy is crafted through a refined iterative process, controlled by\nmechanisms we term as the director and dash, which regulate the proxy's\ndirection and distance relative to the original text query. This setup not only\nfacilitates more precise semantic alignment but also effectively manages the\ndisparities and noise inherent in multimodal data. Our experiments on three\nrepresentative video-text retrieval benchmarks, MSRVTT, DiDeMo, and ActivityNet\nCaptions, demonstrate the effectiveness of TV-ProxyNet. The results show an\nimprovement of 2.0% to 3.3% in R@1 over the baseline. TV-ProxyNet achieved\nstate-of-the-art performance on MSRVTT and ActivityNet Captions, and a 2.0%\nimprovement on DiDeMo compared to existing methods, validating our approach's\nability to enhance semantic mapping and reduce error propensity.\n","authors":["Jian Xiao","Zhenzhen Hu","Jia Li","Richang Hong"],"pdf_url":"https://arxiv.org/pdf/2410.06618v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11589v1","updated":"2024-12-16T09:20:29Z","published":"2024-12-16T09:20:29Z","title":"Future Sight and Tough Fights: Revolutionizing Sequential Recommendation\n  with FENRec","summary":"  Sequential recommendation (SR) systems predict user preferences by analyzing\ntime-ordered interaction sequences. A common challenge for SR is data sparsity,\nas users typically interact with only a limited number of items. While\ncontrastive learning has been employed in previous approaches to address the\nchallenges, these methods often adopt binary labels, missing finer patterns and\noverlooking detailed information in subsequent behaviors of users.\nAdditionally, they rely on random sampling to select negatives in contrastive\nlearning, which may not yield sufficiently hard negatives during later training\nstages. In this paper, we propose Future data utilization with Enduring\nNegatives for contrastive learning in sequential Recommendation (FENRec). Our\napproach aims to leverage future data with time-dependent soft labels and\ngenerate enduring hard negatives from existing data, thereby enhancing the\neffectiveness in tackling data sparsity. Experiment results demonstrate our\nstate-of-the-art performance across four benchmark datasets, with an average\nimprovement of 6.16\\% across all metrics.\n","authors":["Yu-Hsuan Huang","Ling Lo","Hongxia Xie","Hong-Han Shuai","Wen-Huang Cheng"],"pdf_url":"https://arxiv.org/pdf/2412.11589v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.11557v1","updated":"2024-12-16T08:42:43Z","published":"2024-12-16T08:42:43Z","title":"Enhancing Healthcare Recommendation Systems with a Multimodal LLMs-based\n  MOE Architecture","summary":"  With the increasing availability of multimodal data, many fields urgently\nrequire advanced architectures capable of effectively integrating these diverse\ndata sources to address specific problems. This study proposes a hybrid\nrecommendation model that combines the Mixture of Experts (MOE) framework with\nlarge language models to enhance the performance of recommendation systems in\nthe healthcare domain. We built a small dataset for recommending healthy food\nbased on patient descriptions and evaluated the model's performance on several\nkey metrics, including Precision, Recall, NDCG, and MAP@5. The experimental\nresults show that the hybrid model outperforms the baseline models, which use\nMOE or large language models individually, in terms of both accuracy and\npersonalized recommendation effectiveness. The paper finds image data provided\nrelatively limited improvement in the performance of the personalized\nrecommendation system, particularly in addressing the cold start problem. Then,\nthe issue of reclassification of images also affected the recommendation\nresults, especially when dealing with low-quality images or changes in the\nappearance of items, leading to suboptimal performance. The findings provide\nvaluable insights into the development of powerful, scalable, and\nhigh-performance recommendation systems, advancing the application of\npersonalized recommendation technologies in real-world domains such as\nhealthcare.\n","authors":["Jingyu Xu","Yang Wang"],"pdf_url":"https://arxiv.org/pdf/2412.11557v1.pdf","comment":"10 page, accpted by Conf-SMPL conference"},{"id":"http://arxiv.org/abs/2412.00430v4","updated":"2024-12-16T07:46:03Z","published":"2024-11-30T10:56:30Z","title":"Predictive Models in Sequential Recommendations: Bridging Performance\n  Laws with Data Quality Insights","summary":"  Sequential Recommendation (SR) plays a critical role in predicting users'\nsequential preferences. Despite its growing prominence in various industries,\nthe increasing scale of SR models incurs substantial computational costs and\nunpredictability, challenging developers to manage resources efficiently. Under\nthis predicament, Scaling Laws have achieved significant success by examining\nthe loss as models scale up. However, there remains a disparity between loss\nand model performance, which is of greater concern in practical applications.\nMoreover, as data continues to expand, it incorporates repetitive and\ninefficient data. In response, we introduce the Performance Law for SR models,\nwhich aims to theoretically investigate and model the relationship between\nmodel performance and data quality. Specifically, we first fit the HR and NDCG\nmetrics to transformer-based SR models. Subsequently, we propose Approximate\nEntropy (ApEn) to assess data quality, presenting a more nuanced approach\ncompared to traditional data quantity metrics. Our method enables accurate\npredictions across various dataset scales and model sizes, demonstrating a\nstrong correlation in large SR models and offering insights into achieving\noptimal performance for any given model configuration.\n","authors":["Tingjia Shen","Hao Wang","Chuhan Wu","Jin Yao Chin","Wei Guo","Yong Liu","Huifeng Guo","Defu Lian","Ruiming Tang","Enhong Chen"],"pdf_url":"https://arxiv.org/pdf/2412.00430v4.pdf","comment":"12 pages, 5 figures"},{"id":"http://arxiv.org/abs/2412.11431v1","updated":"2024-12-16T04:03:58Z","published":"2024-12-16T04:03:58Z","title":"Optimized Quran Passage Retrieval Using an Expanded QA Dataset and\n  Fine-Tuned Language Models","summary":"  Understanding the deep meanings of the Qur'an and bridging the language gap\nbetween modern standard Arabic and classical Arabic is essential to improve the\nquestion-and-answer system for the Holy Qur'an. The Qur'an QA 2023 shared task\ndataset had a limited number of questions with weak model retrieval. To address\nthis challenge, this work updated the original dataset and improved the model\naccuracy. The original dataset, which contains 251 questions, was reviewed and\nexpanded to 629 questions with question diversification and reformulation,\nleading to a comprehensive set of 1895 categorized into single-answer,\nmulti-answer, and zero-answer types. Extensive experiments fine-tuned\ntransformer models, including AraBERT, RoBERTa, CAMeLBERT, AraELECTRA, and\nBERT. The best model, AraBERT-base, achieved a MAP@10 of 0.36 and MRR of 0.59,\nrepresenting improvements of 63% and 59%, respectively, compared to the\nbaseline scores (MAP@10: 0.22, MRR: 0.37). Additionally, the dataset expansion\nled to improvements in handling \"no answer\" cases, with the proposed approach\nachieving a 75% success rate for such instances, compared to the baseline's\n25%. These results demonstrate the effect of dataset improvement and model\narchitecture optimization in increasing the performance of QA systems for the\nHoly Qur'an, with higher accuracy, recall, and precision.\n","authors":["Mohamed Basem","Islam Oshallah","Baraa Hikal","Ali Hamdi","Ammar Mohamed"],"pdf_url":"https://arxiv.org/pdf/2412.11431v1.pdf","comment":null}]},"2024-12-15T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.11203v1","updated":"2024-12-15T14:35:49Z","published":"2024-12-15T14:35:49Z","title":"Task-Oriented Dialog Systems for the Senegalese Wolof Language","summary":"  In recent years, we are seeing considerable interest in conversational agents\nwith the rise of large language models (LLMs). Although they offer considerable\nadvantages, LLMs also present significant risks, such as hallucination, which\nhinder their widespread deployment in industry. Moreover, low-resource\nlanguages such as African ones are still underrepresented in these systems\nlimiting their performance in these languages. In this paper, we illustrate a\nmore classical approach based on modular architectures of Task-oriented Dialog\nSystems (ToDS) offering better control over outputs. We propose a chatbot\ngeneration engine based on the Rasa framework and a robust methodology for\nprojecting annotations onto the Wolof language using an in-house machine\ntranslation system. After evaluating a generated chatbot trained on the Amazon\nMassive dataset, our Wolof Intent Classifier performs similarly to the one\nobtained for French, which is a resource-rich language. We also show that this\napproach is extensible to other low-resource languages, thanks to the intent\nclassifier's language-agnostic pipeline, simplifying the design of chatbots in\nthese languages.\n","authors":["Derguene Mbaye","Moussa Diallo"],"pdf_url":"https://arxiv.org/pdf/2412.11203v1.pdf","comment":"10 pages, 3 tables, 6 figures, The 31st International Conference on\n  Computational Linguistics (COLING 2025)"},{"id":"http://arxiv.org/abs/2412.12202v1","updated":"2024-12-15T09:23:14Z","published":"2024-12-15T09:23:14Z","title":"A multi-theoretical kernel-based approach to social network-based\n  recommendation","summary":"  Recommender systems are a critical component of e-commercewebsites. The rapid\ndevelopment of online social networking services provides an opportunity to\nexplore social networks together with information used in traditional\nrecommender systems, such as customer demographics, product characteristics,\nand transactions. It also provides more applications for recommender systems.\nTo tackle this social network-based recommendation problem, previous studies\ngenerally built trust models in light of the social influence theory. This\nstudy inspects a spectrumof social network theories to systematicallymodel\nthemultiple facets of a social network and infer user preferences. In order to\neffectively make use of these heterogonous theories, we take a kernel-based\nmachine learning paradigm, design and select kernels describing individual\nsimilarities according to social network theories, and employ a non-linear\nmultiple kernel learning algorithm to combine the kernels into a unified model.\nThis design also enables us to consider multiple theories' interactions in\nassessing individual behaviors. We evaluate our proposed approach on a\nreal-world movie review data set. The experiments show that our approach\nprovides more accurate recommendations than trust-based methods and the\ncollaborative filtering approach. Further analysis shows that kernels derived\nfrom contagion theory and homophily theory contribute a larger portion of the\nmodel.\n","authors":["Xin Li","Mengyue Wang","T. -P. Liang"],"pdf_url":"https://arxiv.org/pdf/2412.12202v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.11127v1","updated":"2024-12-15T09:17:45Z","published":"2024-12-15T09:17:45Z","title":"Modeling the Heterogeneous Duration of User Interest in Time-Dependent\n  Recommendation: A Hidden Semi-Markov Approach","summary":"  Recommender systems are widely used for suggesting books, education\nmaterials, and products to users by exploring their behaviors. In reality,\nusers' preferences often change over time, leading to studies on time-dependent\nrecommender systems. However, most existing approaches that deal with time\ninformation remain primitive. In this paper, we extend existing methods and\npropose a hidden semi-Markov model to track the change of users' interests.\nParticularly, this model allows for capturing the different durations of user\nstays in a (latent) interest state, which can better model the heterogeneity of\nuser interests and focuses. We derive an expectation maximization algorithm to\nestimate the parameters of the framework and predict users' actions.\nExperiments on three real-world datasets show that our model significantly\noutperforms the state-of-the-art time-dependent and static benchmark methods.\nFurther analyses of the experiment results indicate that the performance\nimprovement is related to the heterogeneity of state durations and the drift of\nuser interests in the dataset.\n","authors":["Haidong Zhang","Wancheng Ni","Xin Li","Yiping Yang"],"pdf_url":"https://arxiv.org/pdf/2412.11127v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2309.14548v2","updated":"2024-12-15T08:36:19Z","published":"2023-09-25T21:45:30Z","title":"Algorithmic Collusion or Competition: the Role of Platforms' Recommender\n  Systems","summary":"  Recent scholarly work has extensively examined the phenomenon of algorithmic\ncollusion driven by AI-enabled pricing algorithms. However, online platforms\ncommonly deploy recommender systems that influence how consumers discover and\npurchase products, thereby shaping the reward structures faced by pricing\nalgorithms and ultimately affecting competition dynamics and equilibrium\noutcomes. To address this gap in the literature and elucidate the role of\nrecommender systems, we propose a novel repeated game framework that integrates\nseveral key components. We first develop a structural search model to\ncharacterize consumers' decision-making processes in response to varying\nrecommendation sets. This model incorporates both observable and unobservable\nheterogeneity in utility and search cost functions, and is estimated using\nreal-world data. Building on the resulting consumer model, we formulate\npersonalized recommendation algorithms designed to maximize either platform\nrevenue or consumer utility. We further introduce pricing algorithms for\nsellers and integrate all these elements to facilitate comprehensive numerical\nexperiments. Our experimental findings reveal that a revenue-maximizing\nrecommender system intensifies algorithmic collusion, whereas a\nutility-maximizing recommender system encourages more competitive pricing\nbehavior among sellers. Intriguingly, and contrary to conventional insights\nfrom the industrial organization and choice modeling literature, increasing the\nsize of recommendation sets under a utility-maximizing regime does not\nconsistently enhance consumer utility. Moreover, the degree of horizontal\ndifferentiation moderates this phenomenon in unexpected ways. The \"more is\nless\" effect does not arise at low levels of differentiation, but becomes\nincreasingly pronounced as horizontal differentiation increases.\n","authors":["Xingchen Xu","Stephanie Lee","Yong Tan"],"pdf_url":"https://arxiv.org/pdf/2309.14548v2.pdf","comment":"54 pages, 4 figures, 16 tables"},{"id":"http://arxiv.org/abs/2412.11105v1","updated":"2024-12-15T08:08:07Z","published":"2024-12-15T08:08:07Z","title":"Multi-Graph Co-Training for Capturing User Intent in Session-based\n  Recommendation","summary":"  Session-based recommendation focuses on predicting the next item a user will\ninteract with based on sequences of anonymous user sessions. A significant\nchallenge in this field is data sparsity due to the typically short-term\ninteractions. Most existing methods rely heavily on users' current\ninteractions, overlooking the wealth of auxiliary information available. To\naddress this, we propose a novel model, the Multi-Graph Co-Training model\n(MGCOT), which leverages not only the current session graph but also similar\nsession graphs and a global item relation graph. This approach allows for a\nmore comprehensive exploration of intrinsic relationships and better captures\nuser intent from multiple views, enabling session representations to complement\neach other. Additionally, MGCOT employs multi-head attention mechanisms to\neffectively capture relevant session intent and uses contrastive learning to\nform accurate and robust session representations. Extensive experiments on\nthree datasets demonstrate that MGCOT significantly enhances the performance of\nsession-based recommendations, particularly on the Diginetica dataset,\nachieving improvements up to 2.00% in P@20 and 10.70% in MRR@20. Resources have\nbeen made publicly available in our GitHub repository\nhttps://github.com/liang-tian-tian/MGCOT.\n","authors":["Zhe Yang","Tiantian Liang"],"pdf_url":"https://arxiv.org/pdf/2412.11105v1.pdf","comment":"COLING 2025 Main Conference"},{"id":"http://arxiv.org/abs/2412.11087v1","updated":"2024-12-15T07:09:02Z","published":"2024-12-15T07:09:02Z","title":"Leveraging Large Vision-Language Model as User Intent-aware Encoder for\n  Composed Image Retrieval","summary":"  Composed Image Retrieval (CIR) aims to retrieve target images from candidate\nset using a hybrid-modality query consisting of a reference image and a\nrelative caption that describes the user intent. Recent studies attempt to\nutilize Vision-Language Pre-training Models (VLPMs) with various fusion\nstrategies for addressing the task.However, these methods typically fail to\nsimultaneously meet two key requirements of CIR: comprehensively extracting\nvisual information and faithfully following the user intent. In this work, we\npropose CIR-LVLM, a novel framework that leverages the large vision-language\nmodel (LVLM) as the powerful user intent-aware encoder to better meet these\nrequirements. Our motivation is to explore the advanced reasoning and\ninstruction-following capabilities of LVLM for accurately understanding and\nresponding the user intent. Furthermore, we design a novel hybrid intent\ninstruction module to provide explicit intent guidance at two levels: (1) The\ntask prompt clarifies the task requirement and assists the model in discerning\nuser intent at the task level. (2) The instance-specific soft prompt, which is\nadaptively selected from the learnable prompt pool, enables the model to better\ncomprehend the user intent at the instance level compared to a universal prompt\nfor all instances. CIR-LVLM achieves state-of-the-art performance across three\nprominent benchmarks with acceptable inference efficiency. We believe this\nstudy provides fundamental insights into CIR-related fields.\n","authors":["Zelong Sun","Dong Jing","Guoxing Yang","Nanyi Fei","Zhiwu Lu"],"pdf_url":"https://arxiv.org/pdf/2412.11087v1.pdf","comment":"Accepted by AAAI 2025"},{"id":"http://arxiv.org/abs/2412.11068v1","updated":"2024-12-15T05:57:36Z","published":"2024-12-15T05:57:36Z","title":"RecSys Arena: Pair-wise Recommender System Evaluation with Large\n  Language Models","summary":"  Evaluating the quality of recommender systems is critical for algorithm\ndesign and optimization. Most evaluation methods are computed based on offline\nmetrics for quick algorithm evolution, since online experiments are usually\nrisky and time-consuming. However, offline evaluation usually cannot fully\nreflect users' preference for the outcome of different recommendation\nalgorithms, and the results may not be consistent with online A/B test.\nMoreover, many offline metrics such as AUC do not offer sufficient information\nfor comparing the subtle differences between two competitive recommender\nsystems in different aspects, which may lead to substantial performance\ndifferences in long-term online serving. Fortunately, due to the strong\ncommonsense knowledge and role-play capability of large language models (LLMs),\nit is possible to obtain simulated user feedback on offline recommendation\nresults. Motivated by the idea of LLM Chatbot Arena, in this paper we present\nthe idea of RecSys Arena, where the recommendation results given by two\ndifferent recommender systems in each session are evaluated by an LLM judger to\nobtain fine-grained evaluation feedback. More specifically, for each sample we\nuse LLM to generate a user profile description based on user behavior history\nor off-the-shelf profile features, which is used to guide LLM to play the role\nof this user and evaluate the relative preference for two recommendation\nresults generated by different models. Through extensive experiments on two\nrecommendation datasets in different scenarios, we demonstrate that many\ndifferent LLMs not only provide general evaluation results that are highly\nconsistent with canonical offline metrics, but also provide rich insight in\nmany subjective aspects. Moreover, it can better distinguish different\nalgorithms with comparable performance in terms of AUC and nDCG.\n","authors":["Zhuo Wu","Qinglin Jia","Chuhan Wu","Zhaocheng Du","Shuai Wang","Zan Wang","Zhenhua Dong"],"pdf_url":"https://arxiv.org/pdf/2412.11068v1.pdf","comment":null}]},"2024-12-14T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.10858v1","updated":"2024-12-14T15:14:39Z","published":"2024-12-14T15:14:39Z","title":"CRENER: A Character Relation Enhanced Chinese NER Model","summary":"  Chinese Named Entity Recognition (NER) is an important task in information\nextraction, which has a significant impact on downstream applications. Due to\nthe lack of natural separators in Chinese, previous NER methods mostly relied\non external dictionaries to enrich the semantic and boundary information of\nChinese words. However, such methods may introduce noise that affects the\naccuracy of named entity recognition. To this end, we propose a character\nrelation enhanced Chinese NER model (CRENER). This model defines four types of\ntags that reflect the relationships between characters, and proposes a\nfine-grained modeling of the relationships between characters based on three\ntypes of relationships: adjacency relations between characters, relations\nbetween characters and tags, and relations between tags, to more accurately\nidentify entity boundaries and improve Chinese NER accuracy. Specifically, we\ntransform the Chinese NER task into a character-character relationship\nclassification task, ensuring the accuracy of entity boundary recognition\nthrough joint modeling of relation tags. To enhance the model's ability to\nunderstand contextual information, WRENER further constructed an adapted\ntransformer encoder that combines unscaled direction-aware and distance-aware\nmasked self-attention mechanisms. Moreover, a relationship representation\nenhancement module was constructed to model predefined relationship tags,\neffectively mining the relationship representations between characters and\ntags. Experiments conducted on four well-known Chinese NER benchmark datasets\nhave shown that the proposed model outperforms state-of-the-art baselines. The\nablation experiment also demonstrated the effectiveness of the proposed model.\n","authors":["Yaqiong Qiao","Shixuan Peng"],"pdf_url":"https://arxiv.org/pdf/2412.10858v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2304.09560v3","updated":"2024-12-14T14:14:26Z","published":"2023-04-19T10:59:34Z","title":"An Offline Metric for the Debiasedness of Click Models","summary":"  A well-known problem when learning from user clicks are inherent biases\nprevalent in the data, such as position or trust bias. Click models are a\ncommon method for extracting information from user clicks, such as document\nrelevance in web search, or to estimate click biases for downstream\napplications such as counterfactual learning-to-rank, ad placement, or fair\nranking. Recent work shows that the current evaluation practices in the\ncommunity fail to guarantee that a well-performing click model generalizes well\nto downstream tasks in which the ranking distribution differs from the training\ndistribution, i.e., under covariate shift. In this work, we propose an\nevaluation metric based on conditional independence testing to detect a lack of\nrobustness to covariate shift in click models. We introduce the concept of\ndebiasedness in click modeling and derive a metric for measuring it. In\nextensive semi-synthetic experiments, we show that our proposed metric helps to\npredict the downstream performance of click models under covariate shift and is\nuseful in an off-policy model selection setting.\n","authors":["Romain Deffayet","Philipp Hager","Jean-Michel Renders","Maarten de Rijke"],"pdf_url":"https://arxiv.org/pdf/2304.09560v3.pdf","comment":"SIGIR23 - Full paper"},{"id":"http://arxiv.org/abs/2412.10787v1","updated":"2024-12-14T10:49:00Z","published":"2024-12-14T10:49:00Z","title":"Why Not Together? A Multiple-Round Recommender System for Queries and\n  Items","summary":"  A fundamental technique of recommender systems involves modeling user\npreferences, where queries and items are widely used as symbolic\nrepresentations of user interests. Queries delineate user needs at an abstract\nlevel, providing a high-level description, whereas items operate on a more\nspecific and concrete level, representing the granular facets of user\npreference. While practical, both query and item recommendations encounter the\nchallenge of sparse user feedback. To this end, we propose a novel approach\nnamed Multiple-round Auto Guess-and-Update System (MAGUS) that capitalizes on\nthe synergies between both types, allowing us to leverage both query and item\ninformation to form user interests. This integrated system introduces a\nrecursive framework that could be applied to any recommendation method to\nexploit queries and items in historical interactions and to provide\nrecommendations for both queries and items in each interaction round. Empirical\nresults from testing 12 different recommendation methods demonstrate that\nintegrating queries into item recommendations via MAGUS significantly enhances\nthe efficiency, with which users can identify their preferred items during\nmultiple-round interactions.\n","authors":["Jiarui Jin","Xianyu Chen","Weinan Zhang","Yong Yu","Jun Wang"],"pdf_url":"https://arxiv.org/pdf/2412.10787v1.pdf","comment":"KDD 2025"},{"id":"http://arxiv.org/abs/2412.10770v1","updated":"2024-12-14T09:47:21Z","published":"2024-12-14T09:47:21Z","title":"Learned Data Compression: Challenges and Opportunities for the Future","summary":"  Compressing integer keys is a fundamental operation among multiple\ncommunities, such as database management (DB), information retrieval (IR), and\nhigh-performance computing (HPC). Recent advances in \\emph{learned indexes}\nhave inspired the development of \\emph{learned compressors}, which leverage\nsimple yet compact machine learning (ML) models to compress large-scale sorted\nkeys. The core idea behind learned compressors is to \\emph{losslessly} encode\nsorted keys by approximating them with \\emph{error-bounded} ML models (e.g.,\npiecewise linear functions) and using a \\emph{residual array} to guarantee\naccurate key reconstruction.\n  While the concept of learned compressors remains in its early stages of\nexploration, our benchmark results demonstrate that an SIMD-optimized learned\ncompressor can significantly outperform state-of-the-art CPU-based compressors.\nDrawing on our preliminary experiments, this vision paper explores the\npotential of learned data compression to enhance critical areas in DBMS and\nrelated domains. Furthermore, we outline the key technical challenges that\nexisting systems must address when integrating this emerging methodology.\n","authors":["Qiyu Liu","Siyuan Han","Jianwei Liao","Jin Li","Jingshu Peng","Jun Du","Lei Chen"],"pdf_url":"https://arxiv.org/pdf/2412.10770v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10745v1","updated":"2024-12-14T08:28:52Z","published":"2024-12-14T08:28:52Z","title":"Enhancing Event Extraction from Short Stories through Contextualized\n  Prompts","summary":"  Event extraction is an important natural language processing (NLP) task of\nidentifying events in an unstructured text. Although a plethora of works deal\nwith event extraction from new articles, clinical text etc., only a few works\nfocus on event extraction from literary content. Detecting events in short\nstories presents several challenges to current systems, encompassing a\ndifferent distribution of events as compared to other domains and the portrayal\nof diverse emotional conditions. This paper presents \\texttt{Vrittanta-EN}, a\ncollection of 1000 English short stories annotated for real events. Exploring\nthis field could result in the creation of techniques and resources that\nsupport literary scholars in improving their effectiveness. This could\nsimultaneously influence the field of Natural Language Processing. Our\nobjective is to clarify the intricate idea of events in the context of short\nstories. Towards the objective, we collected 1,000 short stories written mostly\nfor children in the Indian context. Further, we present fresh guidelines for\nannotating event mentions and their categories, organized into \\textit{seven\ndistinct classes}. The classes are {\\tt{COGNITIVE-MENTAL-STATE(CMS),\nCOMMUNICATION(COM), CONFLICT(CON), GENERAL-ACTIVITY(GA), LIFE-EVENT(LE),\nMOVEMENT(MOV), and OTHERS(OTH)}}. Subsequently, we apply these guidelines to\nannotate the short story dataset. Later, we apply the baseline methods for\nautomatically detecting and categorizing events. We also propose a prompt-based\nmethod for event detection and classification. The proposed method outperforms\nthe baselines, while having significant improvement of more than 4\\% for the\nclass \\texttt{CONFLICT} in event classification task.\n","authors":["Chaitanya Kirti","Ayon Chattopadhyay","Ashish Anand","Prithwijit Guha"],"pdf_url":"https://arxiv.org/pdf/2412.10745v1.pdf","comment":"47 pages, 8 figures, Planning to submit in Elsevier (Computer Speech\n  and Language Journal)"},{"id":"http://arxiv.org/abs/2412.10737v1","updated":"2024-12-14T08:18:23Z","published":"2024-12-14T08:18:23Z","title":"Sentiment and Hashtag-aware Attentive Deep Neural Network for Multimodal\n  Post Popularity Prediction","summary":"  Social media users articulate their opinions on a broad spectrum of subjects\nand share their experiences through posts comprising multiple modes of\nexpression, leading to a notable surge in such multimodal content on social\nmedia platforms. Nonetheless, accurately forecasting the popularity of these\nposts presents a considerable challenge. Prevailing methodologies primarily\ncenter on the content itself, thereby overlooking the wealth of information\nencapsulated within alternative modalities such as visual demographics,\nsentiments conveyed through hashtags and adequately modeling the intricate\nrelationships among hashtags, texts, and accompanying images. This oversight\nlimits the ability to capture emotional connection and audience relevance,\nsignificantly influencing post popularity. To address these limitations, we\npropose a seNtiment and hAshtag-aware attentive deep neuRal netwoRk for\nmultimodAl posT pOpularity pRediction, herein referred to as NARRATOR that\nextracts visual demographics from faces appearing in images and discerns\nsentiment from hashtag usage, providing a more comprehensive understanding of\nthe factors influencing post popularity Moreover, we introduce a hashtag-guided\nattention mechanism that leverages hashtags as navigational cues, guiding the\nmodels focus toward the most pertinent features of textual and visual\nmodalities, thus aligning with target audience interests and broader social\nmedia context. Experimental results demonstrate that NARRATOR outperforms\nexisting methods by a significant margin on two real-world datasets.\nFurthermore, ablation studies underscore the efficacy of integrating visual\ndemographics, sentiment analysis of hashtags, and hashtag-guided attention\nmechanisms in enhancing the performance of post popularity prediction, thereby\nfacilitating increased audience relevance, emotional engagement, and aesthetic\nappeal.\n","authors":["Shubhi Bansal","Mohit Kumar","Chandravardhan Singh Raghaw","Nagendra Kumar"],"pdf_url":"https://arxiv.org/pdf/2412.10737v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10714v1","updated":"2024-12-14T06:56:46Z","published":"2024-12-14T06:56:46Z","title":"Movie Recommendation using Web Crawling","summary":"  In today's digital world, streaming platforms offer a vast array of movies,\nmaking it hard for users to find content matching their preferences. This paper\nexplores integrating real time data from popular movie websites using advanced\nHTML scraping techniques and APIs. It also incorporates a recommendation system\ntrained on a static Kaggle dataset, enhancing the relevance and freshness of\nsuggestions. By combining content based filtering, collaborative filtering, and\na hybrid model, we create a system that utilizes both historical and real time\ndata for more personalized suggestions. Our methodology shows that\nincorporating dynamic data not only boosts user satisfaction but also aligns\nrecommendations with current viewing trends.\n","authors":["Pronit Raj","Chandrashekhar Kumar","Harshit Shekhar","Amit Kumar","Kritibas Paul","Debasish Jana"],"pdf_url":"https://arxiv.org/pdf/2412.10714v1.pdf","comment":"12 pages, 3 figures, Accepted and to be published in Proceedings of\n  2025 International Conference on Applied Algorithms (ICAA), Kolkata, India,\n  Dec 8-10, 2025"},{"id":"http://arxiv.org/abs/2412.10701v1","updated":"2024-12-14T06:18:19Z","published":"2024-12-14T06:18:19Z","title":"Beyond Quantile Methods: Improved Top-K Threshold Estimation for\n  Traditional and Learned Sparse Indexes","summary":"  Top-k threshold estimation is the problem of estimating the score of the k-th\nhighest ranking result of a search query. A good estimate can be used to speed\nup many common top-k query processing algorithms, and thus a number of\nresearchers have recently studied the problem. Among the various approaches\nthat have been proposed, quantile methods appear to give the best estimates\noverall at modest computational costs, followed by sampling-based methods in\ncertain cases. In this paper, we make two main contributions. First, we study\nhow to get even better estimates than the state of the art. Starting from\nquantile-based methods, we propose a series of enhancements that give improved\nestimates in terms of the commonly used mean under-prediction fraction (MUF).\nSecond, we study the threshold estimation problem on recently proposed learned\nsparse index structures, showing that our methods also work well for these\ncases. Our best methods substantially narrow the gap between the state of the\nart and the ideal MUF of 1.0, at some additional cost in time and space.\n","authors":["Jinrui Gou","Yifan Liu","Minghao Shao","Torsten Suel"],"pdf_url":"https://arxiv.org/pdf/2412.10701v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2411.18069v2","updated":"2024-12-14T05:56:10Z","published":"2024-11-27T05:43:00Z","title":"Overview of TREC 2024 Biomedical Generative Retrieval (BioGen) Track","summary":"  With the advancement of large language models (LLMs), the biomedical domain\nhas seen significant progress and improvement in multiple tasks such as\nbiomedical question answering, lay language summarization of the biomedical\nliterature, clinical note summarization, etc. However, hallucinations or\nconfabulations remain one of the key challenges when using LLMs in the\nbiomedical and other domains. Inaccuracies may be particularly harmful in\nhigh-risk situations, such as medical question answering, making clinical\ndecisions, or appraising biomedical research. Studies on the evaluation of the\nLLMs abilities to ground generated statements in verifiable sources have shown\nthat models perform significantly worse on lay-user-generated questions, and\noften fail to reference relevant sources. This can be problematic when those\nseeking information want evidence from studies to back up the claims from LLMs.\nUnsupported statements are a major barrier to using LLMs in any applications\nthat may affect health. Methods for grounding generated statements in reliable\nsources along with practical evaluation approaches are needed to overcome this\nbarrier. Towards this, in our pilot task organized at TREC 2024, we introduced\nthe task of reference attribution as a means to mitigate the generation of\nfalse statements by LLMs answering biomedical questions.\n","authors":["Deepak Gupta","Dina Demner-Fushman","William Hersh","Steven Bedrick","Kirk Roberts"],"pdf_url":"https://arxiv.org/pdf/2411.18069v2.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10680v1","updated":"2024-12-14T04:59:38Z","published":"2024-12-14T04:59:38Z","title":"UCDR-Adapter: Exploring Adaptation of Pre-Trained Vision-Language Models\n  for Universal Cross-Domain Retrieval","summary":"  Universal Cross-Domain Retrieval (UCDR) retrieves relevant images from unseen\ndomains and classes without semantic labels, ensuring robust generalization.\nExisting methods commonly employ prompt tuning with pre-trained vision-language\nmodels but are inherently limited by static prompts, reducing adaptability. We\npropose UCDR-Adapter, which enhances pre-trained models with adapters and\ndynamic prompt generation through a two-phase training strategy. First, Source\nAdapter Learning integrates class semantics with domain-specific visual\nknowledge using a Learnable Textual Semantic Template and optimizes Class and\nDomain Prompts via momentum updates and dual loss functions for robust\nalignment. Second, Target Prompt Generation creates dynamic prompts by\nattending to masked source prompts, enabling seamless adaptation to unseen\ndomains and classes. Unlike prior approaches, UCDR-Adapter dynamically adapts\nto evolving data distributions, enhancing both flexibility and generalization.\nDuring inference, only the image branch and generated prompts are used,\neliminating reliance on textual inputs for highly efficient retrieval.\nExtensive benchmark experiments show that UCDR-Adapter consistently outperforms\nProS in most cases and other state-of-the-art methods on UCDR, U(c)CDR, and\nU(d)CDR settings.\n","authors":["Haoyu Jiang","Zhi-Qi Cheng","Gabriel Moreira","Jiawen Zhu","Jingdong Sun","Bukun Ren","Jun-Yan He","Qi Dai","Xian-Sheng Hua"],"pdf_url":"https://arxiv.org/pdf/2412.10680v1.pdf","comment":"Accepted to WACV 2025. Project link:\n  https://github.com/fine68/UCDR2024"},{"id":"http://arxiv.org/abs/2412.10674v1","updated":"2024-12-14T04:22:09Z","published":"2024-12-14T04:22:09Z","title":"USM: Unbiased Survey Modeling for Limiting Negative User Experiences in\n  Recommendation Systems","summary":"  Negative feedback signals are crucial to guardrail content recommendations\nand improve user experience. When these signals are effectively integrated into\nrecommendation systems, they play a vital role in preventing the promotion of\nharmful or undesirable content, thereby contributing to a healthier online\nenvironment. However, the challenges associated with negative signals are\nnoteworthy. Due to the limited visibility of options for users to express\nnegative feedback, these signals are often sparse compared to positive signals.\nThis imbalance can lead to a skewed understanding of user preferences,\nresulting in recommendations that prioritize short-term engagement over\nlong-term satisfaction. Moreover, an over-reliance on positive signals can\ncreate a filter bubble, where users are continuously exposed to content that\naligns with their immediate preferences but may not be beneficial in the long\nrun. This scenario can ultimately lead to user attrition as audiences become\ndisillusioned with the quality of the content provided. Additionally, existing\nuser signals frequently fail to meet specific customized requirements, such as\nunderstanding the underlying reasons for a user's likes or dislikes regarding a\nvideo. This lack of granularity hinders our ability to tailor content\nrecommendations effectively, as we cannot identify the particular attributes of\ncontent that resonate with individual users.\n","authors":["Chenghui Yu","Peiyi Li","Haoze Wu","Bingfeng Deng","Hongyu Xiong"],"pdf_url":"https://arxiv.org/pdf/2412.10674v1.pdf","comment":"9 pages, 6 figures"},{"id":"http://arxiv.org/abs/2412.04506v2","updated":"2024-12-14T00:13:09Z","published":"2024-12-03T22:59:36Z","title":"Arctic-Embed 2.0: Multilingual Retrieval Without Compromise","summary":"  This paper presents the training methodology of Arctic-Embed 2.0, a set of\nopen-source text embedding models built for accurate and efficient multilingual\nretrieval. While prior works have suffered from degraded English retrieval\nquality, Arctic-Embed 2.0 delivers competitive retrieval quality on\nmultilingual and English-only benchmarks, and supports Matryoshka\nRepresentation Learning (MRL) for efficient embedding storage with\nsignificantly lower compressed quality degradation compared to alternatives. We\ndetail the design and implementation, presenting several important open\nresearch questions that arose during model development. We conduct experiments\nexploring these research questions and include extensive discussion aimed at\nfostering further discussion in this field.\n","authors":["Puxuan Yu","Luke Merrick","Gaurav Nuti","Daniel Campos"],"pdf_url":"https://arxiv.org/pdf/2412.04506v2.pdf","comment":"10 pages, 5 figures, 3 tables"}]},"2024-12-13T00:00:00Z":{"Information Retrieval":[{"id":"http://arxiv.org/abs/2412.10595v1","updated":"2024-12-13T22:44:22Z","published":"2024-12-13T22:44:22Z","title":"Recommendation and Temptation","summary":"  Traditional recommender systems based on utility maximization and revealed\npreferences often fail to capture users' dual-self nature, where consumption\nchoices are driven by both long-term benefits (enrichment) and desire for\ninstant gratification (temptation). Consequently, these systems may generate\nrecommendations that fail to provide long-lasting satisfaction to users. To\naddress this issue, we propose a novel user model that accounts for this\ndual-self behavior and develop an optimal recommendation strategy to maximize\nenrichment from consumption. We highlight the limitations of historical\nconsumption data in implementing this strategy and present an estimation\nframework that makes minimal assumptions and leverages explicit user feedback\nand implicit choice data to overcome these constraints. We evaluate our\napproach through both synthetic simulations and simulations based on real-world\ndata from the MovieLens dataset. Results demonstrate that our proposed\nrecommender can deliver superior enrichment compared to several competitive\nbaseline algorithms that assume a single utility type and rely solely on\nrevealed preferences. Our work emphasizes the critical importance of optimizing\nfor enrichment in recommender systems, particularly in temptation-laden\nconsumption contexts. Our findings have significant implications for content\nplatforms, user experience design, and the development of responsible AI\nsystems, paving the way for more nuanced and user-centric recommendation\napproaches.\n","authors":["Md Sanzeed Anwar","Paramveer S. Dhillon","Grant Schoenebeck"],"pdf_url":"https://arxiv.org/pdf/2412.10595v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.10576v1","updated":"2024-12-13T21:37:37Z","published":"2024-12-13T21:37:37Z","title":"Agro-STAY : Collecte de données et analyse des informations en\n  agriculture alternative issues de YouTube","summary":"  To address the current crises (climatic, social, economic), the\nself-sufficiency -- a set of practices that combine energy sobriety,\nself-production of food and energy, and self-construction - arouses an\nincreasing interest. The CNRS STAY project (Savoirs Techniques pour\nl'Auto-suffisance, sur YouTube) explores this topic by analyzing techniques\nshared on YouTube. We present Agro-STAY, a platform designed for the\ncollection, processing, and visualization of data from YouTube videos and their\ncomments. We use Natural Language Processing (NLP) techniques and language\nmodels, which enable a fine-grained analysis of alternative agricultural\npractice described online.\n  --\n  Face aux crises actuelles (climatiques, sociales, \\'economiques),\nl'auto-suffisance -- ensemble de pratiques combinant sobri\\'et\\'e\n\\'energ\\'etique, autoproduction alimentaire et \\'energ\\'etique et\nautoconstruction - suscite un int\\'er\\^et croissant. Le projet CNRS STAY\n(Savoirs Techniques pour l'Auto-suffisance, sur YouTube) s'inscrit dans ce\ndomaine en analysant les savoirs techniques diffus\\'es sur YouTube. Nous\npr\\'esentons Agro-STAY, une plateforme d\\'edi\\'ee \\`a la collecte, au\ntraitement et \\`a la visualisation de donn\\'ees issues de vid\\'eos YouTube et\nde leurs commentaires. En mobilisant des techniques de traitement automatique\ndes langues (TAL) et des mod\\`eles de langues, ce travail permet une analyse\nfine des pratiques agricoles alternatives d\\'ecrites en ligne.\n","authors":["Laura Maxim","Julien Rabatel","Jean-Marc Douguet","Natalia Grabar","Roberto Interdonato","Sébastien Loustau","Mathieu Roche","Maguelonne Teisseire"],"pdf_url":"https://arxiv.org/pdf/2412.10576v1.pdf","comment":"8 pages, in French language, 3 figures"},{"id":"http://arxiv.org/abs/2412.10543v1","updated":"2024-12-13T20:39:30Z","published":"2024-12-13T20:39:30Z","title":"RAGServe: Fast Quality-Aware RAG Systems with Configuration Adaptation","summary":"  RAG (Retrieval Augmented Generation) allows LLMs (large language models) to\ngenerate better responses with external knowledge, but using more external\nknowledge often improves generation quality at the expense of response delay.\nPrior work either reduces the response delay (through better scheduling of RAG\nqueries) or strives to maximize quality (which involves tuning the RAG\nworkflow), but they fall short in optimizing the tradeoff between the delay and\nquality of RAG responses. This paper presents RAGServe, the first RAG system\nthat jointly schedules queries and adapts the key RAG configurations of each\nquery, such as the number of retrieved text chunks and synthesis methods, in\norder to balance quality optimization and response delay reduction. Using 4\npopular RAG-QA datasets, we show that compared with the state-of-the-art RAG\noptimization schemes, RAGServe reduces the generation latency by\n$1.64-2.54\\times$ without sacrificing generation quality.\n","authors":["Siddhant Ray","Rui Pan","Zhuohan Gu","Kuntai Du","Ganesh Ananthanarayanan","Ravi Netravali","Junchen Jiang"],"pdf_url":"https://arxiv.org/pdf/2412.10543v1.pdf","comment":"17 pages, 18 figures"},{"id":"http://arxiv.org/abs/2412.10514v1","updated":"2024-12-13T19:16:38Z","published":"2024-12-13T19:16:38Z","title":"CRS Arena: Crowdsourced Benchmarking of Conversational Recommender\n  Systems","summary":"  We introduce CRS Arena, a research platform for scalable benchmarking of\nConversational Recommender Systems (CRS) based on human feedback. The platform\ndisplays pairwise battles between anonymous conversational recommender systems,\nwhere users interact with the systems one after the other before declaring\neither a winner or a draw. CRS Arena collects conversations and user feedback,\nproviding a foundation for reliable evaluation and ranking of CRSs. We conduct\nexperiments with CRS Arena on both open and closed crowdsourcing platforms,\nconfirming that both setups produce highly correlated rankings of CRSs and\nconversations with similar characteristics. We release CRSArena-Dial, a dataset\nof 474 conversations and their corresponding user feedback, along with a\npreliminary ranking of the systems based on the Elo rating system. The platform\nis accessible at https://iai-group-crsarena.hf.space/.\n","authors":["Nolwenn Bernard","Hideaki Joko","Faegheh Hasibi","Krisztian Balog"],"pdf_url":"https://arxiv.org/pdf/2412.10514v1.pdf","comment":"Proceedings of the Eighteenth ACM International Conference on Web\n  Search and Data Mining (WSDM '25), March 10--14, 2025, Hannover, Germany"},{"id":"http://arxiv.org/abs/2412.10313v1","updated":"2024-12-13T17:53:29Z","published":"2024-12-13T17:53:29Z","title":"MST-R: Multi-Stage Tuning for Retrieval Systems and Metric Evaluation","summary":"  Regulatory documents are rich in nuanced terminology and specialized\nsemantics. FRAG systems: Frozen retrieval-augmented generators utilizing\npre-trained (or, frozen) components face consequent challenges with both\nretriever and answering performance. We present a system that adapts the\nretriever performance to the target domain using a multi-stage tuning (MST)\nstrategy. Our retrieval approach, called MST-R (a) first fine-tunes encoders\nused in vector stores using hard negative mining, (b) then uses a hybrid\nretriever, combining sparse and dense retrievers using reciprocal rank fusion,\nand then (c) adapts the cross-attention encoder by fine-tuning only the top-k\nretrieved results. We benchmark the system performance on the dataset released\nfor the RIRAG challenge (as part of the RegNLP workshop at COLING 2025). We\nachieve significant performance gains obtaining a top rank on the RegNLP\nchallenge leaderboard. We also show that a trivial answering approach games the\nRePASs metric outscoring all baselines and a pre-trained Llama model. Analyzing\nthis anomaly, we present important takeaways for future research.\n","authors":["Yash Malviya","Karan Dhingra","Maneesh Singh"],"pdf_url":"https://arxiv.org/pdf/2412.10313v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09983v1","updated":"2024-12-13T09:09:20Z","published":"2024-12-13T09:09:20Z","title":"Static Pruning in Dense Retrieval using Matrix Decomposition","summary":"  In the era of dense retrieval, document indexing and retrieval is largely\nbased on encoding models that transform text documents into embeddings. The\nefficiency of retrieval is directly proportional to the number of documents and\nthe size of the embeddings. Recent studies have shown that it is possible to\nreduce embedding size without sacrificing - and in some cases improving - the\nretrieval effectiveness. However, the methods introduced by these studies are\nquery-dependent, so they can't be applied offline and require additional\ncomputations during query processing, thus negatively impacting the retrieval\nefficiency. In this paper, we present a novel static pruning method for\nreducing the dimensionality of embeddings using Principal Components Analysis.\nThis approach is query-independent and can be executed offline, leading to a\nsignificant boost in dense retrieval efficiency with a negligible impact on the\nsystem effectiveness. Our experiments show that our proposed method reduces the\ndimensionality of document representations by over 50% with up to a 5%\nreduction in NDCG@10, for different dense retrieval models.\n","authors":["Federico Siciliano","Francesca Pezzuti","Nicola Tonellotto","Fabrizio Silvestri"],"pdf_url":"https://arxiv.org/pdf/2412.09983v1.pdf","comment":null},{"id":"http://arxiv.org/abs/2412.09950v1","updated":"2024-12-13T08:14:10Z","published":"2024-12-13T08:14:10Z","title":"Hesitation and Tolerance in Recommender Systems","summary":"  User interactions in recommender systems are inherently complex, often\ninvolving behaviors that go beyond simple acceptance or rejection. One\nparticularly common behavior is hesitation, where users deliberate over\nrecommended items, signaling uncertainty. Our large-scale surveys, with 6,644\nand 3,864 responses respectively, confirm that hesitation is not only\nwidespread but also has a profound impact on user experiences. When users spend\nadditional time engaging with content they are ultimately uninterested in, this\ncan lead to negative emotions, a phenomenon we term as tolerance. The surveys\nreveal that such tolerance behaviors often arise after hesitation and can erode\ntrust, satisfaction, and long-term loyalty to the platform. For instance, a\nclick might reflect a need for more information rather than genuine interest,\nand prolonged exposure to unsuitable content amplifies frustration. This\nmisalignment between user intent and system interpretation introduces noise\ninto recommendation training, resulting in suggestions that increase\nuncertainty and disengagement. To address these issues, we identified signals\nindicative of tolerance behavior and analyzed datasets from both e-commerce and\nshort-video platforms. The analysis shows a strong correlation between\nincreased tolerance behavior and decreased user activity. We integrated these\ninsights into the training process of a recommender system for a major\nshort-video platform. Results from four independent online A/B experiments\ndemonstrated significant improvements in user retention, achieved with minimal\nadditional computational costs. These findings underscore the importance of\nrecognizing hesitation as a ubiquitous user behavior and addressing tolerance\nto enhance satisfaction, build trust, and sustain long-term engagement in\nrecommender systems.\n","authors":["Kuan Zou","Aixin Sun","Xuemeng Jiang","Yitong Ji","Hao Zhang","Jing Wang","Ruijie Guo"],"pdf_url":"https://arxiv.org/pdf/2412.09950v1.pdf","comment":"30 pages, 6 figures, 6 tables"},{"id":"http://arxiv.org/abs/2406.00004v3","updated":"2024-12-13T06:41:02Z","published":"2024-05-12T04:15:05Z","title":"Navigating the Future of Federated Recommendation Systems with\n  Foundation Models","summary":"  In recent years, the integration of federated learning (FL) and\nrecommendation systems (RS), known as Federated Recommendation Systems (FRS),\nhas attracted attention for preserving user privacy by keeping private data on\nclient devices. However, FRS faces inherent limitations such as data\nheterogeneity and scarcity, due to the privacy requirements of FL and the\ntypical data sparsity issues of RSs. Models like ChatGPT are empowered by the\nconcept of transfer learning and self-supervised learning, so they can be\neasily applied to the downstream tasks after fine-tuning or prompting. These\nmodels, so-called Foundation Models (FM), fouce on understanding the human's\nintent and perform following their designed roles in the specific tasks, which\nare widely recognized for producing high-quality content in the image and\nlanguage domains. Thus, the achievements of FMs inspire the design of FRS and\nsuggest a promising research direction: integrating foundation models to\naddress the above limitations. In this study, we conduct a comprehensive review\nof FRSs with FMs. Specifically, we: 1) summarise the common approaches of\ncurrent FRSs and FMs; 2) review the challenges posed by FRSs and FMs; 3)\ndiscuss potential future research directions; and 4) introduce some common\nbenchmarks and evaluation metrics in the FRS field. We hope that this position\npaper provides the necessary background and guidance to explore this\ninteresting and emerging topic.\n","authors":["Zhiwei Li","Guodong Long","Chunxu Zhang","Honglei Zhang","Jing Jiang","Chengqi Zhang"],"pdf_url":"https://arxiv.org/pdf/2406.00004v3.pdf","comment":"20 pages, position paper, survey"}]}}